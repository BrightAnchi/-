{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KinSdnGHxufM",
        "outputId": "64ed8cb5-7059-4084-bdf2-70ed93d5bdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 18 11:12:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              42W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CrVFi2A9CJF",
        "outputId": "5fd13b9e-af50-43e4-bdf1-4cce3785feea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HMfBFG4X9MzH"
      },
      "outputs": [],
      "source": [
        "#DATASET\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Normalization parameters for pre-trained PyTorch models\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, hr_shape):\n",
        "        hr_height, hr_width = hr_shape\n",
        "        # Transforms for low resolution images and high resolution images\n",
        "        self.lr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        self.hr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.files = sorted(glob.glob(root + \"/*.*\"))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index % len(self.files)])\n",
        "        img_lr = self.lr_transform(img)\n",
        "        img_hr = self.hr_transform(img)\n",
        "\n",
        "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lv_pBSnY9Q54"
      },
      "outputs": [],
      "source": [
        "#SRGAN MODEL\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchvision.models import vgg19\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        # 使用預訓練的 VGG19 網絡作為特徵提取器\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        # 提取 VGG19 的特定層作為特徵提取器\n",
        "        self.feature_extractor = nn.Sequential(*list(vgg.features.children())[:18])\n",
        "        # 初始化權重\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nn.init.constant_(module.weight, 1)\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                nn.init.normal_(module.weight, 0, 0.01)\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.feature_extractor(img)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(in_features, 0.8),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(in_features, 0.8),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        # First layer\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU())\n",
        "\n",
        "        # Residual blocks\n",
        "        res_blocks = []\n",
        "        for _ in range(n_residual_blocks):\n",
        "            res_blocks.append(ResidualBlock(64))\n",
        "        self.res_blocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "        # Second conv layer post residual blocks\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8))\n",
        "\n",
        "        # Upsampling layers\n",
        "        upsampling = []\n",
        "        for out_features in range(2):\n",
        "            upsampling += [\n",
        "                # nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(64, 256, 3, 1, 1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.PixelShuffle(upscale_factor=2),\n",
        "                nn.PReLU(),\n",
        "            ]\n",
        "        self.upsampling = nn.Sequential(*upsampling)\n",
        "\n",
        "        # Final output layer\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.conv1(x)\n",
        "        out = self.res_blocks(out1)\n",
        "        out2 = self.conv2(out)\n",
        "        out = torch.add(out1, out2)\n",
        "        out = self.upsampling(out)\n",
        "        out = self.conv3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        in_channels, in_height, in_width = self.input_shape\n",
        "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
        "        self.output_shape = (1, patch_h, patch_w)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
        "            layers = []\n",
        "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
        "            if not first_block:\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
        "            layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        layers = []\n",
        "        in_filters = in_channels\n",
        "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
        "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
        "            in_filters = out_filters\n",
        "\n",
        "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "WXU4zVi39d1L",
        "outputId": "8efe4353-0bf1-47b2-ddb4-8965de60edef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'n_epochs': 200, 'batch_size': 4, 'lr': 0.0002, 'b1': 0.5, 'b2': 0.999, 'decay_epoch': 101, 'n_cpu': 8, 'hr_height': 256, 'hr_width': 256, 'channels': 3, 'sample_interval': 100, 'checkpoint_interval': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:02<00:00, 215MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /content/drive/MyDrive/ColabNotebooks/SRGANDataset/DIV2K_train_HR\n",
            "Is dataset path valid? True\n",
            "Batch loaded successfully\n",
            "FeatureExtractor(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#測試路徑是否有路具\\nimport argparse\\nparser = argparse.ArgumentParser()\\nopt = parser.parse_args()\\ndataset_path = \"../../data/%s\" % opt.dataset_name\\nprint(\"dataset_path\")\\n\\n#測試路徑是否正確\\nfor batch in dataloader:\\n    print(\"Batch loaded successfully\")\\n    break\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\"\"\"\n",
        "Super-resolution of CelebA using Generative Adversarial Networks.\n",
        "The dataset can be downloaded from: https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADIKlz8PR9zr6Y20qbkunrba/Img/img_align_celeba.zip?dl=0\n",
        "(if not available there see if options are listed at http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
        "Instrustion on running the script:\n",
        "1. Download the dataset from the provided link\n",
        "2. Save the folder 'img_align_celeba' to '../../data/'\n",
        "4. Run the sript using command 'python3 srgan.py'\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#from models001Test import *\n",
        "#from datasets import *\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "# 初始化生成器和特徵提取器\n",
        "generator = Generator()\n",
        "feature_extractor = FeatureExtractor()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "opt = {\n",
        "    \"epoch\": 0,\n",
        "    \"n_epochs\": 200,  #訓練的總 epoch 數。每個 epoch 是完整遍歷一次訓練數據集的過程\n",
        "    #\"dataset_name\": \"DIV2K_train_HR\",\n",
        "    \"batch_size\": 4,  #每個批次（batch）中處理的圖像數量。批次大小越大，訓練過程中的內存使用量也越大。\n",
        "    \"lr\": 0.0002,   #學習率，控制模型的更新步伐。較小的學習率通常會讓模型更穩定，但收斂速度較慢。\n",
        "    \"b1\": 0.5,     #這是 Adam 優化器的兩個超參數。b1 控制一階矩估計的動量，b2 控制二階矩估計的動量。\n",
        "    \"b2\": 0.999,    #一般來說，這兩個參數的默認值分別為 0.5 和 0.999，這些值通常適合大多數情況。\n",
        "    \"decay_epoch\": 101, #從哪個 epoch 開始，學習率會逐漸衰減。\n",
        "               #這個值設置為 100 意味著從第 100 個 epoch 開始，學習率會開始減少，這有助於穩定模型並防止過度擬合。\n",
        "    \"n_cpu\": 8,\n",
        "    \"hr_height\": 256,  #高解析度圖像的高度。\n",
        "    \"hr_width\": 256,   #高解析度圖像的寬度。\n",
        "    \"channels\": 3,  #圖像的通道數。通常為 3（RGB）或 1（灰度）。\n",
        "    \"sample_interval\": 100, #訓練過程中，用於保存和顯示樣本圖像的間隔（以批次為單位）。每當完成一定數量的批次後，模型會生成一些圖像樣本進行保存和可視化。\n",
        "    \"checkpoint_interval\": 10 #訓練過程中保存模型權重的間隔（以 epoch 為單位）。如果設置為 1，每個 epoch 都會保存一次模型的權重。\n",
        "}\n",
        "\n",
        "# 使用變數 opt 中的值\n",
        "epoch = opt[\"epoch\"]\n",
        "n_epochs = opt[\"n_epochs\"]\n",
        "#dataset_name = opt[\"dataset_name\"]\n",
        "batch_size = opt[\"batch_size\"]\n",
        "lr = opt[\"lr\"]\n",
        "b1 = opt[\"b1\"]\n",
        "b2 = opt[\"b2\"]\n",
        "decay_epoch = opt[\"decay_epoch\"]\n",
        "n_cpu = opt[\"n_cpu\"]\n",
        "hr_height = opt[\"hr_height\"]\n",
        "hr_width = opt[\"hr_width\"]\n",
        "channels = opt[\"channels\"]\n",
        "sample_interval = opt[\"sample_interval\"]\n",
        "checkpoint_interval = opt[\"checkpoint_interval\"]\n",
        "\n",
        "print(opt)\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "hr_shape = (hr_height, hr_width)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = GeneratorResNet()\n",
        "discriminator = Discriminator(input_shape=(channels, *hr_shape))\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "# Set feature extractor to inference mode\n",
        "feature_extractor.eval()\n",
        "\n",
        "# Losses\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_content = torch.nn.L1Loss()\n",
        "\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    feature_extractor = feature_extractor.cuda()\n",
        "    criterion_GAN = criterion_GAN.cuda()\n",
        "    criterion_content = criterion_content.cuda()\n",
        "\n",
        "if epoch != 0:\n",
        "    # Load pretrained models\n",
        "    generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\"))\n",
        "    discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\"))\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/ColabNotebooks/SRGANDataset/DIV2K_train_HR\"\n",
        "print(f\"Dataset path: {os.path.abspath(dataset_path)}\")\n",
        "print(f\"Is dataset path valid? {os.path.exists(dataset_path)}\")\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\"/content/drive/MyDrive/ColabNotebooks/SRGANDataset/DIV2K_train_HR\", hr_shape=hr_shape),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu,\n",
        ")\n",
        "\n",
        "# 打印數據加載器中的一個批次\n",
        "for batch in dataloader:\n",
        "    print(\"Batch loaded successfully\")\n",
        "    break\n",
        "\n",
        "# 測試 FeatureExtractor 類\n",
        "model = FeatureExtractor()\n",
        "print(model)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#測試路徑是否有路具\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "opt = parser.parse_args()\n",
        "dataset_path = \"../../data/%s\" % opt.dataset_name\n",
        "print(\"dataset_path\")\n",
        "\n",
        "#測試路徑是否正確\n",
        "for batch in dataloader:\n",
        "    print(\"Batch loaded successfully\")\n",
        "    break\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5Oq_yx0LXc5",
        "outputId": "7ce59e81-18a0-4ab8-e88a-6172a019e8b6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-8ed2d03d6572>:13: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "[Epoch 175/200] [Batch 1/200] [D loss: 0.000089] [G loss: 0.019117]\n",
            "[Epoch 175/200] [Batch 2/200] [D loss: 0.000223] [G loss: 0.018032]\n",
            "[Epoch 175/200] [Batch 3/200] [D loss: 0.000276] [G loss: 0.014747]\n",
            "[Epoch 175/200] [Batch 4/200] [D loss: 0.000301] [G loss: 0.020845]\n",
            "[Epoch 175/200] [Batch 5/200] [D loss: 0.000154] [G loss: 0.013306]\n",
            "[Epoch 175/200] [Batch 6/200] [D loss: 0.000099] [G loss: 0.021710]\n",
            "[Epoch 175/200] [Batch 7/200] [D loss: 0.000105] [G loss: 0.020298]\n",
            "[Epoch 175/200] [Batch 8/200] [D loss: 0.000082] [G loss: 0.018429]\n",
            "[Epoch 175/200] [Batch 9/200] [D loss: 0.000105] [G loss: 0.019605]\n",
            "[Epoch 175/200] [Batch 10/200] [D loss: 0.000101] [G loss: 0.021966]\n",
            "[Epoch 175/200] [Batch 11/200] [D loss: 0.000133] [G loss: 0.013132]\n",
            "[Epoch 175/200] [Batch 12/200] [D loss: 0.000263] [G loss: 0.020966]\n",
            "[Epoch 175/200] [Batch 13/200] [D loss: 0.000433] [G loss: 0.015889]\n",
            "[Epoch 175/200] [Batch 14/200] [D loss: 0.000169] [G loss: 0.019224]\n",
            "[Epoch 175/200] [Batch 15/200] [D loss: 0.000135] [G loss: 0.015460]\n",
            "[Epoch 175/200] [Batch 16/200] [D loss: 0.000133] [G loss: 0.019575]\n",
            "[Epoch 175/200] [Batch 17/200] [D loss: 0.000135] [G loss: 0.021848]\n",
            "[Epoch 175/200] [Batch 18/200] [D loss: 0.000296] [G loss: 0.018008]\n",
            "[Epoch 175/200] [Batch 19/200] [D loss: 0.000148] [G loss: 0.017561]\n",
            "[Epoch 175/200] [Batch 20/200] [D loss: 0.000277] [G loss: 0.021527]\n",
            "[Epoch 175/200] [Batch 21/200] [D loss: 0.000490] [G loss: 0.020170]\n",
            "[Epoch 175/200] [Batch 22/200] [D loss: 0.000400] [G loss: 0.019676]\n",
            "[Epoch 175/200] [Batch 23/200] [D loss: 0.000387] [G loss: 0.015458]\n",
            "[Epoch 175/200] [Batch 24/200] [D loss: 0.000657] [G loss: 0.023822]\n",
            "[Epoch 175/200] [Batch 25/200] [D loss: 0.000880] [G loss: 0.015395]\n",
            "[Epoch 175/200] [Batch 26/200] [D loss: 0.000754] [G loss: 0.014497]\n",
            "[Epoch 175/200] [Batch 27/200] [D loss: 0.000385] [G loss: 0.017287]\n",
            "[Epoch 175/200] [Batch 28/200] [D loss: 0.000384] [G loss: 0.017761]\n",
            "[Epoch 175/200] [Batch 29/200] [D loss: 0.000401] [G loss: 0.017697]\n",
            "[Epoch 175/200] [Batch 30/200] [D loss: 0.000211] [G loss: 0.018198]\n",
            "[Epoch 175/200] [Batch 31/200] [D loss: 0.000131] [G loss: 0.018317]\n",
            "[Epoch 175/200] [Batch 32/200] [D loss: 0.000237] [G loss: 0.016233]\n",
            "[Epoch 175/200] [Batch 33/200] [D loss: 0.000697] [G loss: 0.017271]\n",
            "[Epoch 175/200] [Batch 34/200] [D loss: 0.001249] [G loss: 0.013804]\n",
            "[Epoch 175/200] [Batch 35/200] [D loss: 0.001010] [G loss: 0.018216]\n",
            "[Epoch 175/200] [Batch 36/200] [D loss: 0.000235] [G loss: 0.016291]\n",
            "[Epoch 175/200] [Batch 37/200] [D loss: 0.000222] [G loss: 0.019689]\n",
            "[Epoch 175/200] [Batch 38/200] [D loss: 0.000131] [G loss: 0.016670]\n",
            "[Epoch 175/200] [Batch 39/200] [D loss: 0.000265] [G loss: 0.019084]\n",
            "[Epoch 175/200] [Batch 40/200] [D loss: 0.000392] [G loss: 0.017424]\n",
            "[Epoch 175/200] [Batch 41/200] [D loss: 0.000395] [G loss: 0.017184]\n",
            "[Epoch 175/200] [Batch 42/200] [D loss: 0.000333] [G loss: 0.018229]\n",
            "[Epoch 175/200] [Batch 43/200] [D loss: 0.000470] [G loss: 0.015660]\n",
            "[Epoch 175/200] [Batch 44/200] [D loss: 0.000386] [G loss: 0.017215]\n",
            "[Epoch 175/200] [Batch 45/200] [D loss: 0.000585] [G loss: 0.019365]\n",
            "[Epoch 175/200] [Batch 46/200] [D loss: 0.000725] [G loss: 0.017484]\n",
            "[Epoch 175/200] [Batch 47/200] [D loss: 0.000389] [G loss: 0.019045]\n",
            "[Epoch 175/200] [Batch 48/200] [D loss: 0.000914] [G loss: 0.018309]\n",
            "[Epoch 175/200] [Batch 49/200] [D loss: 0.002378] [G loss: 0.019542]\n",
            "[Epoch 175/200] [Batch 50/200] [D loss: 0.004179] [G loss: 0.015013]\n",
            "[Epoch 175/200] [Batch 51/200] [D loss: 0.001324] [G loss: 0.016184]\n",
            "[Epoch 175/200] [Batch 52/200] [D loss: 0.001440] [G loss: 0.016598]\n",
            "[Epoch 175/200] [Batch 53/200] [D loss: 0.001352] [G loss: 0.018815]\n",
            "[Epoch 175/200] [Batch 54/200] [D loss: 0.000902] [G loss: 0.019596]\n",
            "[Epoch 175/200] [Batch 55/200] [D loss: 0.000606] [G loss: 0.016210]\n",
            "[Epoch 175/200] [Batch 56/200] [D loss: 0.000334] [G loss: 0.016173]\n",
            "[Epoch 175/200] [Batch 57/200] [D loss: 0.000551] [G loss: 0.016771]\n",
            "[Epoch 175/200] [Batch 58/200] [D loss: 0.000490] [G loss: 0.016753]\n",
            "[Epoch 175/200] [Batch 59/200] [D loss: 0.000637] [G loss: 0.019006]\n",
            "[Epoch 175/200] [Batch 60/200] [D loss: 0.000392] [G loss: 0.019556]\n",
            "[Epoch 175/200] [Batch 61/200] [D loss: 0.000402] [G loss: 0.018680]\n",
            "[Epoch 175/200] [Batch 62/200] [D loss: 0.000543] [G loss: 0.018079]\n",
            "[Epoch 175/200] [Batch 63/200] [D loss: 0.000299] [G loss: 0.015373]\n",
            "[Epoch 175/200] [Batch 64/200] [D loss: 0.000257] [G loss: 0.019731]\n",
            "[Epoch 175/200] [Batch 65/200] [D loss: 0.000429] [G loss: 0.016911]\n",
            "[Epoch 175/200] [Batch 66/200] [D loss: 0.000183] [G loss: 0.013962]\n",
            "[Epoch 175/200] [Batch 67/200] [D loss: 0.000166] [G loss: 0.018095]\n",
            "[Epoch 175/200] [Batch 68/200] [D loss: 0.000154] [G loss: 0.015940]\n",
            "[Epoch 175/200] [Batch 69/200] [D loss: 0.000432] [G loss: 0.018838]\n",
            "[Epoch 175/200] [Batch 70/200] [D loss: 0.000748] [G loss: 0.015355]\n",
            "[Epoch 175/200] [Batch 71/200] [D loss: 0.000378] [G loss: 0.016887]\n",
            "[Epoch 175/200] [Batch 72/200] [D loss: 0.000264] [G loss: 0.016450]\n",
            "[Epoch 175/200] [Batch 73/200] [D loss: 0.000169] [G loss: 0.016433]\n",
            "[Epoch 175/200] [Batch 74/200] [D loss: 0.000369] [G loss: 0.019463]\n",
            "[Epoch 175/200] [Batch 75/200] [D loss: 0.000456] [G loss: 0.021034]\n",
            "[Epoch 175/200] [Batch 76/200] [D loss: 0.000429] [G loss: 0.016932]\n",
            "[Epoch 175/200] [Batch 77/200] [D loss: 0.000273] [G loss: 0.012189]\n",
            "[Epoch 175/200] [Batch 78/200] [D loss: 0.000180] [G loss: 0.013500]\n",
            "[Epoch 175/200] [Batch 79/200] [D loss: 0.000254] [G loss: 0.022493]\n",
            "[Epoch 175/200] [Batch 80/200] [D loss: 0.000282] [G loss: 0.017510]\n",
            "[Epoch 175/200] [Batch 81/200] [D loss: 0.000180] [G loss: 0.016433]\n",
            "[Epoch 175/200] [Batch 82/200] [D loss: 0.000219] [G loss: 0.017187]\n",
            "[Epoch 175/200] [Batch 83/200] [D loss: 0.000300] [G loss: 0.017369]\n",
            "[Epoch 175/200] [Batch 84/200] [D loss: 0.000336] [G loss: 0.022010]\n",
            "[Epoch 175/200] [Batch 85/200] [D loss: 0.000271] [G loss: 0.021402]\n",
            "[Epoch 175/200] [Batch 86/200] [D loss: 0.000110] [G loss: 0.019228]\n",
            "[Epoch 175/200] [Batch 87/200] [D loss: 0.000176] [G loss: 0.018400]\n",
            "[Epoch 175/200] [Batch 88/200] [D loss: 0.000143] [G loss: 0.016191]\n",
            "[Epoch 175/200] [Batch 89/200] [D loss: 0.000186] [G loss: 0.015538]\n",
            "[Epoch 175/200] [Batch 90/200] [D loss: 0.000201] [G loss: 0.017163]\n",
            "[Epoch 175/200] [Batch 91/200] [D loss: 0.000125] [G loss: 0.019219]\n",
            "[Epoch 175/200] [Batch 92/200] [D loss: 0.000077] [G loss: 0.016248]\n",
            "[Epoch 175/200] [Batch 93/200] [D loss: 0.000123] [G loss: 0.021139]\n",
            "[Epoch 175/200] [Batch 94/200] [D loss: 0.000131] [G loss: 0.016355]\n",
            "[Epoch 175/200] [Batch 95/200] [D loss: 0.000075] [G loss: 0.015555]\n",
            "[Epoch 175/200] [Batch 96/200] [D loss: 0.000147] [G loss: 0.020030]\n",
            "[Epoch 175/200] [Batch 97/200] [D loss: 0.000197] [G loss: 0.014369]\n",
            "[Epoch 175/200] [Batch 98/200] [D loss: 0.000118] [G loss: 0.015295]\n",
            "[Epoch 175/200] [Batch 99/200] [D loss: 0.000145] [G loss: 0.018090]\n",
            "[Epoch 175/200] [Batch 100/200] [D loss: 0.000151] [G loss: 0.014340]\n",
            "[Epoch 175/200] [Batch 101/200] [D loss: 0.000134] [G loss: 0.019355]\n",
            "[Epoch 175/200] [Batch 102/200] [D loss: 0.000182] [G loss: 0.016325]\n",
            "[Epoch 175/200] [Batch 103/200] [D loss: 0.000352] [G loss: 0.019639]\n",
            "[Epoch 175/200] [Batch 104/200] [D loss: 0.000644] [G loss: 0.020850]\n",
            "[Epoch 175/200] [Batch 105/200] [D loss: 0.000872] [G loss: 0.017118]\n",
            "[Epoch 175/200] [Batch 106/200] [D loss: 0.000705] [G loss: 0.014754]\n",
            "[Epoch 175/200] [Batch 107/200] [D loss: 0.000267] [G loss: 0.016447]\n",
            "[Epoch 175/200] [Batch 108/200] [D loss: 0.000379] [G loss: 0.016231]\n",
            "[Epoch 175/200] [Batch 109/200] [D loss: 0.000190] [G loss: 0.016612]\n",
            "[Epoch 175/200] [Batch 110/200] [D loss: 0.000241] [G loss: 0.019408]\n",
            "[Epoch 175/200] [Batch 111/200] [D loss: 0.000429] [G loss: 0.016948]\n",
            "[Epoch 175/200] [Batch 112/200] [D loss: 0.000608] [G loss: 0.017406]\n",
            "[Epoch 175/200] [Batch 113/200] [D loss: 0.000358] [G loss: 0.016912]\n",
            "[Epoch 175/200] [Batch 114/200] [D loss: 0.000628] [G loss: 0.017868]\n",
            "[Epoch 175/200] [Batch 115/200] [D loss: 0.001330] [G loss: 0.018074]\n",
            "[Epoch 175/200] [Batch 116/200] [D loss: 0.000985] [G loss: 0.019094]\n",
            "[Epoch 175/200] [Batch 117/200] [D loss: 0.000378] [G loss: 0.018177]\n",
            "[Epoch 175/200] [Batch 118/200] [D loss: 0.000263] [G loss: 0.018977]\n",
            "[Epoch 175/200] [Batch 119/200] [D loss: 0.000282] [G loss: 0.017420]\n",
            "[Epoch 175/200] [Batch 120/200] [D loss: 0.000462] [G loss: 0.022688]\n",
            "[Epoch 175/200] [Batch 121/200] [D loss: 0.000479] [G loss: 0.019901]\n",
            "[Epoch 175/200] [Batch 122/200] [D loss: 0.000455] [G loss: 0.017105]\n",
            "[Epoch 175/200] [Batch 123/200] [D loss: 0.001825] [G loss: 0.015329]\n",
            "[Epoch 175/200] [Batch 124/200] [D loss: 0.000727] [G loss: 0.018169]\n",
            "[Epoch 175/200] [Batch 125/200] [D loss: 0.000686] [G loss: 0.020446]\n",
            "[Epoch 175/200] [Batch 126/200] [D loss: 0.000719] [G loss: 0.017716]\n",
            "[Epoch 175/200] [Batch 127/200] [D loss: 0.000375] [G loss: 0.016573]\n",
            "[Epoch 175/200] [Batch 128/200] [D loss: 0.000290] [G loss: 0.016896]\n",
            "[Epoch 175/200] [Batch 129/200] [D loss: 0.000420] [G loss: 0.020573]\n",
            "[Epoch 175/200] [Batch 130/200] [D loss: 0.000454] [G loss: 0.016266]\n",
            "[Epoch 175/200] [Batch 131/200] [D loss: 0.000344] [G loss: 0.018377]\n",
            "[Epoch 175/200] [Batch 132/200] [D loss: 0.000308] [G loss: 0.015274]\n",
            "[Epoch 175/200] [Batch 133/200] [D loss: 0.000267] [G loss: 0.018361]\n",
            "[Epoch 175/200] [Batch 134/200] [D loss: 0.000236] [G loss: 0.020911]\n",
            "[Epoch 175/200] [Batch 135/200] [D loss: 0.000254] [G loss: 0.019718]\n",
            "[Epoch 175/200] [Batch 136/200] [D loss: 0.000311] [G loss: 0.017093]\n",
            "[Epoch 175/200] [Batch 137/200] [D loss: 0.000315] [G loss: 0.016418]\n",
            "[Epoch 175/200] [Batch 138/200] [D loss: 0.000344] [G loss: 0.016318]\n",
            "[Epoch 175/200] [Batch 139/200] [D loss: 0.000354] [G loss: 0.018360]\n",
            "[Epoch 175/200] [Batch 140/200] [D loss: 0.002416] [G loss: 0.018825]\n",
            "[Epoch 175/200] [Batch 141/200] [D loss: 0.003611] [G loss: 0.016502]\n",
            "[Epoch 175/200] [Batch 142/200] [D loss: 0.001179] [G loss: 0.020486]\n",
            "[Epoch 175/200] [Batch 143/200] [D loss: 0.002846] [G loss: 0.015758]\n",
            "[Epoch 175/200] [Batch 144/200] [D loss: 0.002783] [G loss: 0.016682]\n",
            "[Epoch 175/200] [Batch 145/200] [D loss: 0.000920] [G loss: 0.016717]\n",
            "[Epoch 175/200] [Batch 146/200] [D loss: 0.000941] [G loss: 0.016781]\n",
            "[Epoch 175/200] [Batch 147/200] [D loss: 0.002133] [G loss: 0.014065]\n",
            "[Epoch 175/200] [Batch 148/200] [D loss: 0.000980] [G loss: 0.019660]\n",
            "[Epoch 175/200] [Batch 149/200] [D loss: 0.000451] [G loss: 0.015074]\n",
            "[Epoch 175/200] [Batch 150/200] [D loss: 0.000502] [G loss: 0.014835]\n",
            "[Epoch 175/200] [Batch 151/200] [D loss: 0.000695] [G loss: 0.020428]\n",
            "[Epoch 175/200] [Batch 152/200] [D loss: 0.000570] [G loss: 0.022072]\n",
            "[Epoch 175/200] [Batch 153/200] [D loss: 0.000814] [G loss: 0.017762]\n",
            "[Epoch 175/200] [Batch 154/200] [D loss: 0.000946] [G loss: 0.019516]\n",
            "[Epoch 175/200] [Batch 155/200] [D loss: 0.000980] [G loss: 0.016130]\n",
            "[Epoch 175/200] [Batch 156/200] [D loss: 0.000806] [G loss: 0.021214]\n",
            "[Epoch 175/200] [Batch 157/200] [D loss: 0.000625] [G loss: 0.016561]\n",
            "[Epoch 175/200] [Batch 158/200] [D loss: 0.000221] [G loss: 0.017678]\n",
            "[Epoch 175/200] [Batch 159/200] [D loss: 0.000413] [G loss: 0.016203]\n",
            "[Epoch 175/200] [Batch 160/200] [D loss: 0.000301] [G loss: 0.019259]\n",
            "[Epoch 175/200] [Batch 161/200] [D loss: 0.000280] [G loss: 0.019358]\n",
            "[Epoch 175/200] [Batch 162/200] [D loss: 0.000362] [G loss: 0.016387]\n",
            "[Epoch 175/200] [Batch 163/200] [D loss: 0.000685] [G loss: 0.018571]\n",
            "[Epoch 175/200] [Batch 164/200] [D loss: 0.001239] [G loss: 0.016228]\n",
            "[Epoch 175/200] [Batch 165/200] [D loss: 0.001341] [G loss: 0.019897]\n",
            "[Epoch 175/200] [Batch 166/200] [D loss: 0.003912] [G loss: 0.018137]\n",
            "[Epoch 175/200] [Batch 167/200] [D loss: 0.002517] [G loss: 0.016463]\n",
            "[Epoch 175/200] [Batch 168/200] [D loss: 0.001465] [G loss: 0.019970]\n",
            "[Epoch 175/200] [Batch 169/200] [D loss: 0.000779] [G loss: 0.014294]\n",
            "[Epoch 175/200] [Batch 170/200] [D loss: 0.001015] [G loss: 0.017516]\n",
            "[Epoch 175/200] [Batch 171/200] [D loss: 0.000518] [G loss: 0.017871]\n",
            "[Epoch 175/200] [Batch 172/200] [D loss: 0.000341] [G loss: 0.016648]\n",
            "[Epoch 175/200] [Batch 173/200] [D loss: 0.000447] [G loss: 0.015701]\n",
            "[Epoch 175/200] [Batch 174/200] [D loss: 0.000465] [G loss: 0.017987]\n",
            "[Epoch 175/200] [Batch 175/200] [D loss: 0.000214] [G loss: 0.020454]\n",
            "[Epoch 175/200] [Batch 176/200] [D loss: 0.000202] [G loss: 0.016633]\n",
            "[Epoch 175/200] [Batch 177/200] [D loss: 0.000187] [G loss: 0.017206]\n",
            "[Epoch 175/200] [Batch 178/200] [D loss: 0.000271] [G loss: 0.020199]\n",
            "[Epoch 175/200] [Batch 179/200] [D loss: 0.000278] [G loss: 0.015700]\n",
            "[Epoch 175/200] [Batch 180/200] [D loss: 0.000262] [G loss: 0.017795]\n",
            "[Epoch 175/200] [Batch 181/200] [D loss: 0.000206] [G loss: 0.016646]\n",
            "[Epoch 175/200] [Batch 182/200] [D loss: 0.000295] [G loss: 0.017012]\n",
            "[Epoch 175/200] [Batch 183/200] [D loss: 0.000219] [G loss: 0.018027]\n",
            "[Epoch 175/200] [Batch 184/200] [D loss: 0.000239] [G loss: 0.016462]\n",
            "[Epoch 175/200] [Batch 185/200] [D loss: 0.000294] [G loss: 0.019699]\n",
            "[Epoch 175/200] [Batch 186/200] [D loss: 0.000146] [G loss: 0.018788]\n",
            "[Epoch 175/200] [Batch 187/200] [D loss: 0.000117] [G loss: 0.017307]\n",
            "[Epoch 175/200] [Batch 188/200] [D loss: 0.000209] [G loss: 0.015321]\n",
            "[Epoch 175/200] [Batch 189/200] [D loss: 0.000313] [G loss: 0.015598]\n",
            "[Epoch 175/200] [Batch 190/200] [D loss: 0.000237] [G loss: 0.020456]\n",
            "[Epoch 175/200] [Batch 191/200] [D loss: 0.000283] [G loss: 0.015651]\n",
            "[Epoch 175/200] [Batch 192/200] [D loss: 0.000331] [G loss: 0.013042]\n",
            "[Epoch 175/200] [Batch 193/200] [D loss: 0.000262] [G loss: 0.019897]\n",
            "[Epoch 175/200] [Batch 194/200] [D loss: 0.000252] [G loss: 0.019727]\n",
            "[Epoch 175/200] [Batch 195/200] [D loss: 0.000191] [G loss: 0.013841]\n",
            "[Epoch 175/200] [Batch 196/200] [D loss: 0.000368] [G loss: 0.014556]\n",
            "[Epoch 175/200] [Batch 197/200] [D loss: 0.000398] [G loss: 0.016850]\n",
            "[Epoch 175/200] [Batch 198/200] [D loss: 0.001175] [G loss: 0.017169]\n",
            "[Epoch 175/200] [Batch 199/200] [D loss: 0.003895] [G loss: 0.019496]\n",
            "[Epoch 176/200] [Batch 0/200] [D loss: 0.007841] [G loss: 0.013029]\n",
            "[Epoch 176/200] [Batch 1/200] [D loss: 0.004120] [G loss: 0.021636]\n",
            "[Epoch 176/200] [Batch 2/200] [D loss: 0.003194] [G loss: 0.015793]\n",
            "[Epoch 176/200] [Batch 3/200] [D loss: 0.002392] [G loss: 0.019461]\n",
            "[Epoch 176/200] [Batch 4/200] [D loss: 0.001133] [G loss: 0.022028]\n",
            "[Epoch 176/200] [Batch 5/200] [D loss: 0.000617] [G loss: 0.016002]\n",
            "[Epoch 176/200] [Batch 6/200] [D loss: 0.000467] [G loss: 0.018053]\n",
            "[Epoch 176/200] [Batch 7/200] [D loss: 0.000713] [G loss: 0.016511]\n",
            "[Epoch 176/200] [Batch 8/200] [D loss: 0.000375] [G loss: 0.016290]\n",
            "[Epoch 176/200] [Batch 9/200] [D loss: 0.000368] [G loss: 0.017193]\n",
            "[Epoch 176/200] [Batch 10/200] [D loss: 0.000174] [G loss: 0.023027]\n",
            "[Epoch 176/200] [Batch 11/200] [D loss: 0.000284] [G loss: 0.018371]\n",
            "[Epoch 176/200] [Batch 12/200] [D loss: 0.000234] [G loss: 0.016158]\n",
            "[Epoch 176/200] [Batch 13/200] [D loss: 0.000294] [G loss: 0.016531]\n",
            "[Epoch 176/200] [Batch 14/200] [D loss: 0.000290] [G loss: 0.019720]\n",
            "[Epoch 176/200] [Batch 15/200] [D loss: 0.000191] [G loss: 0.020571]\n",
            "[Epoch 176/200] [Batch 16/200] [D loss: 0.000268] [G loss: 0.017355]\n",
            "[Epoch 176/200] [Batch 17/200] [D loss: 0.000282] [G loss: 0.020450]\n",
            "[Epoch 176/200] [Batch 18/200] [D loss: 0.000178] [G loss: 0.019470]\n",
            "[Epoch 176/200] [Batch 19/200] [D loss: 0.000172] [G loss: 0.017548]\n",
            "[Epoch 176/200] [Batch 20/200] [D loss: 0.000109] [G loss: 0.017840]\n",
            "[Epoch 176/200] [Batch 21/200] [D loss: 0.000088] [G loss: 0.012167]\n",
            "[Epoch 176/200] [Batch 22/200] [D loss: 0.000104] [G loss: 0.016685]\n",
            "[Epoch 176/200] [Batch 23/200] [D loss: 0.000144] [G loss: 0.017613]\n",
            "[Epoch 176/200] [Batch 24/200] [D loss: 0.000125] [G loss: 0.016365]\n",
            "[Epoch 176/200] [Batch 25/200] [D loss: 0.000217] [G loss: 0.014574]\n",
            "[Epoch 176/200] [Batch 26/200] [D loss: 0.000228] [G loss: 0.014131]\n",
            "[Epoch 176/200] [Batch 27/200] [D loss: 0.000214] [G loss: 0.023160]\n",
            "[Epoch 176/200] [Batch 28/200] [D loss: 0.000139] [G loss: 0.019010]\n",
            "[Epoch 176/200] [Batch 29/200] [D loss: 0.000254] [G loss: 0.020296]\n",
            "[Epoch 176/200] [Batch 30/200] [D loss: 0.000200] [G loss: 0.015063]\n",
            "[Epoch 176/200] [Batch 31/200] [D loss: 0.000210] [G loss: 0.017343]\n",
            "[Epoch 176/200] [Batch 32/200] [D loss: 0.000117] [G loss: 0.014646]\n",
            "[Epoch 176/200] [Batch 33/200] [D loss: 0.000161] [G loss: 0.016711]\n",
            "[Epoch 176/200] [Batch 34/200] [D loss: 0.000291] [G loss: 0.018880]\n",
            "[Epoch 176/200] [Batch 35/200] [D loss: 0.000206] [G loss: 0.018778]\n",
            "[Epoch 176/200] [Batch 36/200] [D loss: 0.000234] [G loss: 0.017711]\n",
            "[Epoch 176/200] [Batch 37/200] [D loss: 0.000278] [G loss: 0.018670]\n",
            "[Epoch 176/200] [Batch 38/200] [D loss: 0.000122] [G loss: 0.016515]\n",
            "[Epoch 176/200] [Batch 39/200] [D loss: 0.000146] [G loss: 0.013173]\n",
            "[Epoch 176/200] [Batch 40/200] [D loss: 0.000174] [G loss: 0.020391]\n",
            "[Epoch 176/200] [Batch 41/200] [D loss: 0.000378] [G loss: 0.016517]\n",
            "[Epoch 176/200] [Batch 42/200] [D loss: 0.000252] [G loss: 0.017636]\n",
            "[Epoch 176/200] [Batch 43/200] [D loss: 0.000132] [G loss: 0.021659]\n",
            "[Epoch 176/200] [Batch 44/200] [D loss: 0.000107] [G loss: 0.015419]\n",
            "[Epoch 176/200] [Batch 45/200] [D loss: 0.000076] [G loss: 0.017335]\n",
            "[Epoch 176/200] [Batch 46/200] [D loss: 0.000090] [G loss: 0.019631]\n",
            "[Epoch 176/200] [Batch 47/200] [D loss: 0.000101] [G loss: 0.020970]\n",
            "[Epoch 176/200] [Batch 48/200] [D loss: 0.000104] [G loss: 0.017611]\n",
            "[Epoch 176/200] [Batch 49/200] [D loss: 0.000080] [G loss: 0.019081]\n",
            "[Epoch 176/200] [Batch 50/200] [D loss: 0.000061] [G loss: 0.018872]\n",
            "[Epoch 176/200] [Batch 51/200] [D loss: 0.000089] [G loss: 0.014303]\n",
            "[Epoch 176/200] [Batch 52/200] [D loss: 0.000158] [G loss: 0.017883]\n",
            "[Epoch 176/200] [Batch 53/200] [D loss: 0.000283] [G loss: 0.013742]\n",
            "[Epoch 176/200] [Batch 54/200] [D loss: 0.000253] [G loss: 0.015372]\n",
            "[Epoch 176/200] [Batch 55/200] [D loss: 0.000152] [G loss: 0.014625]\n",
            "[Epoch 176/200] [Batch 56/200] [D loss: 0.000153] [G loss: 0.021633]\n",
            "[Epoch 176/200] [Batch 57/200] [D loss: 0.000199] [G loss: 0.014999]\n",
            "[Epoch 176/200] [Batch 58/200] [D loss: 0.000205] [G loss: 0.017514]\n",
            "[Epoch 176/200] [Batch 59/200] [D loss: 0.000139] [G loss: 0.016605]\n",
            "[Epoch 176/200] [Batch 60/200] [D loss: 0.000116] [G loss: 0.014264]\n",
            "[Epoch 176/200] [Batch 61/200] [D loss: 0.000119] [G loss: 0.018057]\n",
            "[Epoch 176/200] [Batch 62/200] [D loss: 0.000140] [G loss: 0.019600]\n",
            "[Epoch 176/200] [Batch 63/200] [D loss: 0.000100] [G loss: 0.020016]\n",
            "[Epoch 176/200] [Batch 64/200] [D loss: 0.000088] [G loss: 0.014485]\n",
            "[Epoch 176/200] [Batch 65/200] [D loss: 0.000144] [G loss: 0.017558]\n",
            "[Epoch 176/200] [Batch 66/200] [D loss: 0.000222] [G loss: 0.013282]\n",
            "[Epoch 176/200] [Batch 67/200] [D loss: 0.000151] [G loss: 0.017135]\n",
            "[Epoch 176/200] [Batch 68/200] [D loss: 0.000109] [G loss: 0.018488]\n",
            "[Epoch 176/200] [Batch 69/200] [D loss: 0.000125] [G loss: 0.019115]\n",
            "[Epoch 176/200] [Batch 70/200] [D loss: 0.000158] [G loss: 0.020151]\n",
            "[Epoch 176/200] [Batch 71/200] [D loss: 0.000150] [G loss: 0.021446]\n",
            "[Epoch 176/200] [Batch 72/200] [D loss: 0.000067] [G loss: 0.016047]\n",
            "[Epoch 176/200] [Batch 73/200] [D loss: 0.000153] [G loss: 0.020236]\n",
            "[Epoch 176/200] [Batch 74/200] [D loss: 0.000124] [G loss: 0.017924]\n",
            "[Epoch 176/200] [Batch 75/200] [D loss: 0.000094] [G loss: 0.017127]\n",
            "[Epoch 176/200] [Batch 76/200] [D loss: 0.000157] [G loss: 0.015068]\n",
            "[Epoch 176/200] [Batch 77/200] [D loss: 0.000211] [G loss: 0.018551]\n",
            "[Epoch 176/200] [Batch 78/200] [D loss: 0.000195] [G loss: 0.014562]\n",
            "[Epoch 176/200] [Batch 79/200] [D loss: 0.000117] [G loss: 0.017201]\n",
            "[Epoch 176/200] [Batch 80/200] [D loss: 0.000114] [G loss: 0.016026]\n",
            "[Epoch 176/200] [Batch 81/200] [D loss: 0.000376] [G loss: 0.018569]\n",
            "[Epoch 176/200] [Batch 82/200] [D loss: 0.000404] [G loss: 0.018074]\n",
            "[Epoch 176/200] [Batch 83/200] [D loss: 0.000144] [G loss: 0.017734]\n",
            "[Epoch 176/200] [Batch 84/200] [D loss: 0.000270] [G loss: 0.018556]\n",
            "[Epoch 176/200] [Batch 85/200] [D loss: 0.000326] [G loss: 0.018539]\n",
            "[Epoch 176/200] [Batch 86/200] [D loss: 0.000573] [G loss: 0.016092]\n",
            "[Epoch 176/200] [Batch 87/200] [D loss: 0.000499] [G loss: 0.016653]\n",
            "[Epoch 176/200] [Batch 88/200] [D loss: 0.000189] [G loss: 0.017021]\n",
            "[Epoch 176/200] [Batch 89/200] [D loss: 0.000225] [G loss: 0.017528]\n",
            "[Epoch 176/200] [Batch 90/200] [D loss: 0.000377] [G loss: 0.015605]\n",
            "[Epoch 176/200] [Batch 91/200] [D loss: 0.000475] [G loss: 0.016854]\n",
            "[Epoch 176/200] [Batch 92/200] [D loss: 0.000208] [G loss: 0.014466]\n",
            "[Epoch 176/200] [Batch 93/200] [D loss: 0.000228] [G loss: 0.016531]\n",
            "[Epoch 176/200] [Batch 94/200] [D loss: 0.000141] [G loss: 0.015305]\n",
            "[Epoch 176/200] [Batch 95/200] [D loss: 0.000096] [G loss: 0.014989]\n",
            "[Epoch 176/200] [Batch 96/200] [D loss: 0.000107] [G loss: 0.017868]\n",
            "[Epoch 176/200] [Batch 97/200] [D loss: 0.000138] [G loss: 0.017685]\n",
            "[Epoch 176/200] [Batch 98/200] [D loss: 0.000124] [G loss: 0.014826]\n",
            "[Epoch 176/200] [Batch 99/200] [D loss: 0.000189] [G loss: 0.016870]\n",
            "[Epoch 176/200] [Batch 100/200] [D loss: 0.000140] [G loss: 0.018314]\n",
            "[Epoch 176/200] [Batch 101/200] [D loss: 0.000163] [G loss: 0.019507]\n",
            "[Epoch 176/200] [Batch 102/200] [D loss: 0.000329] [G loss: 0.016731]\n",
            "[Epoch 176/200] [Batch 103/200] [D loss: 0.000527] [G loss: 0.017135]\n",
            "[Epoch 176/200] [Batch 104/200] [D loss: 0.000374] [G loss: 0.019019]\n",
            "[Epoch 176/200] [Batch 105/200] [D loss: 0.000258] [G loss: 0.019202]\n",
            "[Epoch 176/200] [Batch 106/200] [D loss: 0.000570] [G loss: 0.017377]\n",
            "[Epoch 176/200] [Batch 107/200] [D loss: 0.000292] [G loss: 0.019759]\n",
            "[Epoch 176/200] [Batch 108/200] [D loss: 0.000165] [G loss: 0.015208]\n",
            "[Epoch 176/200] [Batch 109/200] [D loss: 0.000273] [G loss: 0.022305]\n",
            "[Epoch 176/200] [Batch 110/200] [D loss: 0.000486] [G loss: 0.017464]\n",
            "[Epoch 176/200] [Batch 111/200] [D loss: 0.000559] [G loss: 0.018496]\n",
            "[Epoch 176/200] [Batch 112/200] [D loss: 0.000631] [G loss: 0.020602]\n",
            "[Epoch 176/200] [Batch 113/200] [D loss: 0.000215] [G loss: 0.022476]\n",
            "[Epoch 176/200] [Batch 114/200] [D loss: 0.000339] [G loss: 0.020003]\n",
            "[Epoch 176/200] [Batch 115/200] [D loss: 0.000148] [G loss: 0.020614]\n",
            "[Epoch 176/200] [Batch 116/200] [D loss: 0.000163] [G loss: 0.020521]\n",
            "[Epoch 176/200] [Batch 117/200] [D loss: 0.000128] [G loss: 0.017944]\n",
            "[Epoch 176/200] [Batch 118/200] [D loss: 0.000089] [G loss: 0.015919]\n",
            "[Epoch 176/200] [Batch 119/200] [D loss: 0.000117] [G loss: 0.015175]\n",
            "[Epoch 176/200] [Batch 120/200] [D loss: 0.000160] [G loss: 0.015565]\n",
            "[Epoch 176/200] [Batch 121/200] [D loss: 0.000171] [G loss: 0.016711]\n",
            "[Epoch 176/200] [Batch 122/200] [D loss: 0.000217] [G loss: 0.022213]\n",
            "[Epoch 176/200] [Batch 123/200] [D loss: 0.000235] [G loss: 0.021632]\n",
            "[Epoch 176/200] [Batch 124/200] [D loss: 0.000159] [G loss: 0.017553]\n",
            "[Epoch 176/200] [Batch 125/200] [D loss: 0.000181] [G loss: 0.015897]\n",
            "[Epoch 176/200] [Batch 126/200] [D loss: 0.000169] [G loss: 0.015463]\n",
            "[Epoch 176/200] [Batch 127/200] [D loss: 0.000263] [G loss: 0.016013]\n",
            "[Epoch 176/200] [Batch 128/200] [D loss: 0.000241] [G loss: 0.015323]\n",
            "[Epoch 176/200] [Batch 129/200] [D loss: 0.000370] [G loss: 0.019613]\n",
            "[Epoch 176/200] [Batch 130/200] [D loss: 0.000226] [G loss: 0.014253]\n",
            "[Epoch 176/200] [Batch 131/200] [D loss: 0.000133] [G loss: 0.014172]\n",
            "[Epoch 176/200] [Batch 132/200] [D loss: 0.000183] [G loss: 0.016472]\n",
            "[Epoch 176/200] [Batch 133/200] [D loss: 0.000106] [G loss: 0.015967]\n",
            "[Epoch 176/200] [Batch 134/200] [D loss: 0.000124] [G loss: 0.019428]\n",
            "[Epoch 176/200] [Batch 135/200] [D loss: 0.000102] [G loss: 0.015881]\n",
            "[Epoch 176/200] [Batch 136/200] [D loss: 0.000113] [G loss: 0.017939]\n",
            "[Epoch 176/200] [Batch 137/200] [D loss: 0.000069] [G loss: 0.019000]\n",
            "[Epoch 176/200] [Batch 138/200] [D loss: 0.000083] [G loss: 0.017285]\n",
            "[Epoch 176/200] [Batch 139/200] [D loss: 0.000130] [G loss: 0.018782]\n",
            "[Epoch 176/200] [Batch 140/200] [D loss: 0.000126] [G loss: 0.016310]\n",
            "[Epoch 176/200] [Batch 141/200] [D loss: 0.000153] [G loss: 0.018654]\n",
            "[Epoch 176/200] [Batch 142/200] [D loss: 0.000178] [G loss: 0.018196]\n",
            "[Epoch 176/200] [Batch 143/200] [D loss: 0.000456] [G loss: 0.017003]\n",
            "[Epoch 176/200] [Batch 144/200] [D loss: 0.000433] [G loss: 0.018240]\n",
            "[Epoch 176/200] [Batch 145/200] [D loss: 0.000332] [G loss: 0.016445]\n",
            "[Epoch 176/200] [Batch 146/200] [D loss: 0.000140] [G loss: 0.016902]\n",
            "[Epoch 176/200] [Batch 147/200] [D loss: 0.000195] [G loss: 0.016631]\n",
            "[Epoch 176/200] [Batch 148/200] [D loss: 0.000194] [G loss: 0.015445]\n",
            "[Epoch 176/200] [Batch 149/200] [D loss: 0.000197] [G loss: 0.019481]\n",
            "[Epoch 176/200] [Batch 150/200] [D loss: 0.000144] [G loss: 0.018376]\n",
            "[Epoch 176/200] [Batch 151/200] [D loss: 0.000169] [G loss: 0.012497]\n",
            "[Epoch 176/200] [Batch 152/200] [D loss: 0.000105] [G loss: 0.016896]\n",
            "[Epoch 176/200] [Batch 153/200] [D loss: 0.000107] [G loss: 0.019833]\n",
            "[Epoch 176/200] [Batch 154/200] [D loss: 0.000532] [G loss: 0.020136]\n",
            "[Epoch 176/200] [Batch 155/200] [D loss: 0.001263] [G loss: 0.015810]\n",
            "[Epoch 176/200] [Batch 156/200] [D loss: 0.001208] [G loss: 0.022110]\n",
            "[Epoch 176/200] [Batch 157/200] [D loss: 0.000599] [G loss: 0.019284]\n",
            "[Epoch 176/200] [Batch 158/200] [D loss: 0.000414] [G loss: 0.018522]\n",
            "[Epoch 176/200] [Batch 159/200] [D loss: 0.000475] [G loss: 0.020166]\n",
            "[Epoch 176/200] [Batch 160/200] [D loss: 0.000222] [G loss: 0.014958]\n",
            "[Epoch 176/200] [Batch 161/200] [D loss: 0.000375] [G loss: 0.015949]\n",
            "[Epoch 176/200] [Batch 162/200] [D loss: 0.000389] [G loss: 0.019122]\n",
            "[Epoch 176/200] [Batch 163/200] [D loss: 0.000404] [G loss: 0.019868]\n",
            "[Epoch 176/200] [Batch 164/200] [D loss: 0.000335] [G loss: 0.015889]\n",
            "[Epoch 176/200] [Batch 165/200] [D loss: 0.000197] [G loss: 0.018740]\n",
            "[Epoch 176/200] [Batch 166/200] [D loss: 0.000126] [G loss: 0.013125]\n",
            "[Epoch 176/200] [Batch 167/200] [D loss: 0.000118] [G loss: 0.015661]\n",
            "[Epoch 176/200] [Batch 168/200] [D loss: 0.000178] [G loss: 0.021767]\n",
            "[Epoch 176/200] [Batch 169/200] [D loss: 0.000094] [G loss: 0.017883]\n",
            "[Epoch 176/200] [Batch 170/200] [D loss: 0.000156] [G loss: 0.020858]\n",
            "[Epoch 176/200] [Batch 171/200] [D loss: 0.000229] [G loss: 0.015693]\n",
            "[Epoch 176/200] [Batch 172/200] [D loss: 0.000199] [G loss: 0.015783]\n",
            "[Epoch 176/200] [Batch 173/200] [D loss: 0.000453] [G loss: 0.019289]\n",
            "[Epoch 176/200] [Batch 174/200] [D loss: 0.000120] [G loss: 0.017064]\n",
            "[Epoch 176/200] [Batch 175/200] [D loss: 0.000271] [G loss: 0.020168]\n",
            "[Epoch 176/200] [Batch 176/200] [D loss: 0.000263] [G loss: 0.016842]\n",
            "[Epoch 176/200] [Batch 177/200] [D loss: 0.000142] [G loss: 0.014828]\n",
            "[Epoch 176/200] [Batch 178/200] [D loss: 0.000119] [G loss: 0.017333]\n",
            "[Epoch 176/200] [Batch 179/200] [D loss: 0.000117] [G loss: 0.014069]\n",
            "[Epoch 176/200] [Batch 180/200] [D loss: 0.000094] [G loss: 0.015952]\n",
            "[Epoch 176/200] [Batch 181/200] [D loss: 0.000090] [G loss: 0.019861]\n",
            "[Epoch 176/200] [Batch 182/200] [D loss: 0.000110] [G loss: 0.019081]\n",
            "[Epoch 176/200] [Batch 183/200] [D loss: 0.000060] [G loss: 0.021440]\n",
            "[Epoch 176/200] [Batch 184/200] [D loss: 0.000065] [G loss: 0.017777]\n",
            "[Epoch 176/200] [Batch 185/200] [D loss: 0.000094] [G loss: 0.019464]\n",
            "[Epoch 176/200] [Batch 186/200] [D loss: 0.000083] [G loss: 0.018662]\n",
            "[Epoch 176/200] [Batch 187/200] [D loss: 0.000084] [G loss: 0.016925]\n",
            "[Epoch 176/200] [Batch 188/200] [D loss: 0.000099] [G loss: 0.017403]\n",
            "[Epoch 176/200] [Batch 189/200] [D loss: 0.000157] [G loss: 0.019034]\n",
            "[Epoch 176/200] [Batch 190/200] [D loss: 0.000255] [G loss: 0.017763]\n",
            "[Epoch 176/200] [Batch 191/200] [D loss: 0.000649] [G loss: 0.023616]\n",
            "[Epoch 176/200] [Batch 192/200] [D loss: 0.001473] [G loss: 0.019607]\n",
            "[Epoch 176/200] [Batch 193/200] [D loss: 0.001201] [G loss: 0.015649]\n",
            "[Epoch 176/200] [Batch 194/200] [D loss: 0.000372] [G loss: 0.017640]\n",
            "[Epoch 176/200] [Batch 195/200] [D loss: 0.000548] [G loss: 0.015100]\n",
            "[Epoch 176/200] [Batch 196/200] [D loss: 0.000817] [G loss: 0.017894]\n",
            "[Epoch 176/200] [Batch 197/200] [D loss: 0.001368] [G loss: 0.023294]\n",
            "[Epoch 176/200] [Batch 198/200] [D loss: 0.002896] [G loss: 0.014848]\n",
            "[Epoch 176/200] [Batch 199/200] [D loss: 0.002008] [G loss: 0.017873]\n",
            "[Epoch 177/200] [Batch 0/200] [D loss: 0.000961] [G loss: 0.020668]\n",
            "[Epoch 177/200] [Batch 1/200] [D loss: 0.000382] [G loss: 0.017576]\n",
            "[Epoch 177/200] [Batch 2/200] [D loss: 0.000173] [G loss: 0.013666]\n",
            "[Epoch 177/200] [Batch 3/200] [D loss: 0.000309] [G loss: 0.018066]\n",
            "[Epoch 177/200] [Batch 4/200] [D loss: 0.000159] [G loss: 0.016958]\n",
            "[Epoch 177/200] [Batch 5/200] [D loss: 0.000079] [G loss: 0.015603]\n",
            "[Epoch 177/200] [Batch 6/200] [D loss: 0.000104] [G loss: 0.017222]\n",
            "[Epoch 177/200] [Batch 7/200] [D loss: 0.000230] [G loss: 0.015728]\n",
            "[Epoch 177/200] [Batch 8/200] [D loss: 0.000416] [G loss: 0.017463]\n",
            "[Epoch 177/200] [Batch 9/200] [D loss: 0.000390] [G loss: 0.019400]\n",
            "[Epoch 177/200] [Batch 10/200] [D loss: 0.000389] [G loss: 0.019484]\n",
            "[Epoch 177/200] [Batch 11/200] [D loss: 0.000635] [G loss: 0.017492]\n",
            "[Epoch 177/200] [Batch 12/200] [D loss: 0.000330] [G loss: 0.015267]\n",
            "[Epoch 177/200] [Batch 13/200] [D loss: 0.000225] [G loss: 0.019408]\n",
            "[Epoch 177/200] [Batch 14/200] [D loss: 0.000643] [G loss: 0.017943]\n",
            "[Epoch 177/200] [Batch 15/200] [D loss: 0.000527] [G loss: 0.015164]\n",
            "[Epoch 177/200] [Batch 16/200] [D loss: 0.000279] [G loss: 0.020316]\n",
            "[Epoch 177/200] [Batch 17/200] [D loss: 0.000362] [G loss: 0.018872]\n",
            "[Epoch 177/200] [Batch 18/200] [D loss: 0.000348] [G loss: 0.017226]\n",
            "[Epoch 177/200] [Batch 19/200] [D loss: 0.000124] [G loss: 0.021723]\n",
            "[Epoch 177/200] [Batch 20/200] [D loss: 0.000237] [G loss: 0.015082]\n",
            "[Epoch 177/200] [Batch 21/200] [D loss: 0.000317] [G loss: 0.018002]\n",
            "[Epoch 177/200] [Batch 22/200] [D loss: 0.000292] [G loss: 0.018637]\n",
            "[Epoch 177/200] [Batch 23/200] [D loss: 0.000331] [G loss: 0.016392]\n",
            "[Epoch 177/200] [Batch 24/200] [D loss: 0.000266] [G loss: 0.018226]\n",
            "[Epoch 177/200] [Batch 25/200] [D loss: 0.000154] [G loss: 0.018807]\n",
            "[Epoch 177/200] [Batch 26/200] [D loss: 0.000104] [G loss: 0.019307]\n",
            "[Epoch 177/200] [Batch 27/200] [D loss: 0.000100] [G loss: 0.015307]\n",
            "[Epoch 177/200] [Batch 28/200] [D loss: 0.000078] [G loss: 0.017358]\n",
            "[Epoch 177/200] [Batch 29/200] [D loss: 0.000158] [G loss: 0.017431]\n",
            "[Epoch 177/200] [Batch 30/200] [D loss: 0.000140] [G loss: 0.015613]\n",
            "[Epoch 177/200] [Batch 31/200] [D loss: 0.000293] [G loss: 0.017502]\n",
            "[Epoch 177/200] [Batch 32/200] [D loss: 0.000127] [G loss: 0.017600]\n",
            "[Epoch 177/200] [Batch 33/200] [D loss: 0.000167] [G loss: 0.018648]\n",
            "[Epoch 177/200] [Batch 34/200] [D loss: 0.000169] [G loss: 0.016952]\n",
            "[Epoch 177/200] [Batch 35/200] [D loss: 0.000107] [G loss: 0.019539]\n",
            "[Epoch 177/200] [Batch 36/200] [D loss: 0.000132] [G loss: 0.017525]\n",
            "[Epoch 177/200] [Batch 37/200] [D loss: 0.000086] [G loss: 0.017628]\n",
            "[Epoch 177/200] [Batch 38/200] [D loss: 0.000156] [G loss: 0.016676]\n",
            "[Epoch 177/200] [Batch 39/200] [D loss: 0.000082] [G loss: 0.020941]\n",
            "[Epoch 177/200] [Batch 40/200] [D loss: 0.000081] [G loss: 0.018700]\n",
            "[Epoch 177/200] [Batch 41/200] [D loss: 0.000062] [G loss: 0.015575]\n",
            "[Epoch 177/200] [Batch 42/200] [D loss: 0.000107] [G loss: 0.022382]\n",
            "[Epoch 177/200] [Batch 43/200] [D loss: 0.000176] [G loss: 0.020036]\n",
            "[Epoch 177/200] [Batch 44/200] [D loss: 0.000206] [G loss: 0.022605]\n",
            "[Epoch 177/200] [Batch 45/200] [D loss: 0.000216] [G loss: 0.016518]\n",
            "[Epoch 177/200] [Batch 46/200] [D loss: 0.000581] [G loss: 0.019577]\n",
            "[Epoch 177/200] [Batch 47/200] [D loss: 0.000223] [G loss: 0.018253]\n",
            "[Epoch 177/200] [Batch 48/200] [D loss: 0.000441] [G loss: 0.014528]\n",
            "[Epoch 177/200] [Batch 49/200] [D loss: 0.000200] [G loss: 0.018283]\n",
            "[Epoch 177/200] [Batch 50/200] [D loss: 0.000131] [G loss: 0.012974]\n",
            "[Epoch 177/200] [Batch 51/200] [D loss: 0.000134] [G loss: 0.015623]\n",
            "[Epoch 177/200] [Batch 52/200] [D loss: 0.000087] [G loss: 0.016100]\n",
            "[Epoch 177/200] [Batch 53/200] [D loss: 0.000114] [G loss: 0.017758]\n",
            "[Epoch 177/200] [Batch 54/200] [D loss: 0.000291] [G loss: 0.014571]\n",
            "[Epoch 177/200] [Batch 55/200] [D loss: 0.000478] [G loss: 0.015557]\n",
            "[Epoch 177/200] [Batch 56/200] [D loss: 0.000290] [G loss: 0.016944]\n",
            "[Epoch 177/200] [Batch 57/200] [D loss: 0.000110] [G loss: 0.015205]\n",
            "[Epoch 177/200] [Batch 58/200] [D loss: 0.000270] [G loss: 0.018197]\n",
            "[Epoch 177/200] [Batch 59/200] [D loss: 0.000274] [G loss: 0.021554]\n",
            "[Epoch 177/200] [Batch 60/200] [D loss: 0.000229] [G loss: 0.013481]\n",
            "[Epoch 177/200] [Batch 61/200] [D loss: 0.000340] [G loss: 0.017945]\n",
            "[Epoch 177/200] [Batch 62/200] [D loss: 0.000222] [G loss: 0.016490]\n",
            "[Epoch 177/200] [Batch 63/200] [D loss: 0.000158] [G loss: 0.015386]\n",
            "[Epoch 177/200] [Batch 64/200] [D loss: 0.000270] [G loss: 0.020788]\n",
            "[Epoch 177/200] [Batch 65/200] [D loss: 0.000160] [G loss: 0.016739]\n",
            "[Epoch 177/200] [Batch 66/200] [D loss: 0.000074] [G loss: 0.016412]\n",
            "[Epoch 177/200] [Batch 67/200] [D loss: 0.000136] [G loss: 0.016091]\n",
            "[Epoch 177/200] [Batch 68/200] [D loss: 0.000101] [G loss: 0.017008]\n",
            "[Epoch 177/200] [Batch 69/200] [D loss: 0.000079] [G loss: 0.018325]\n",
            "[Epoch 177/200] [Batch 70/200] [D loss: 0.000093] [G loss: 0.019386]\n",
            "[Epoch 177/200] [Batch 71/200] [D loss: 0.000084] [G loss: 0.018935]\n",
            "[Epoch 177/200] [Batch 72/200] [D loss: 0.000102] [G loss: 0.019620]\n",
            "[Epoch 177/200] [Batch 73/200] [D loss: 0.000153] [G loss: 0.017601]\n",
            "[Epoch 177/200] [Batch 74/200] [D loss: 0.000162] [G loss: 0.017911]\n",
            "[Epoch 177/200] [Batch 75/200] [D loss: 0.000119] [G loss: 0.016440]\n",
            "[Epoch 177/200] [Batch 76/200] [D loss: 0.000200] [G loss: 0.022819]\n",
            "[Epoch 177/200] [Batch 77/200] [D loss: 0.000216] [G loss: 0.017386]\n",
            "[Epoch 177/200] [Batch 78/200] [D loss: 0.000124] [G loss: 0.017286]\n",
            "[Epoch 177/200] [Batch 79/200] [D loss: 0.000128] [G loss: 0.015628]\n",
            "[Epoch 177/200] [Batch 80/200] [D loss: 0.000118] [G loss: 0.017319]\n",
            "[Epoch 177/200] [Batch 81/200] [D loss: 0.000213] [G loss: 0.019893]\n",
            "[Epoch 177/200] [Batch 82/200] [D loss: 0.000218] [G loss: 0.016545]\n",
            "[Epoch 177/200] [Batch 83/200] [D loss: 0.000198] [G loss: 0.014749]\n",
            "[Epoch 177/200] [Batch 84/200] [D loss: 0.000251] [G loss: 0.017306]\n",
            "[Epoch 177/200] [Batch 85/200] [D loss: 0.000296] [G loss: 0.021817]\n",
            "[Epoch 177/200] [Batch 86/200] [D loss: 0.000094] [G loss: 0.020694]\n",
            "[Epoch 177/200] [Batch 87/200] [D loss: 0.000123] [G loss: 0.016154]\n",
            "[Epoch 177/200] [Batch 88/200] [D loss: 0.000091] [G loss: 0.019145]\n",
            "[Epoch 177/200] [Batch 89/200] [D loss: 0.000140] [G loss: 0.014415]\n",
            "[Epoch 177/200] [Batch 90/200] [D loss: 0.000135] [G loss: 0.017871]\n",
            "[Epoch 177/200] [Batch 91/200] [D loss: 0.000121] [G loss: 0.018121]\n",
            "[Epoch 177/200] [Batch 92/200] [D loss: 0.000117] [G loss: 0.018733]\n",
            "[Epoch 177/200] [Batch 93/200] [D loss: 0.000103] [G loss: 0.017301]\n",
            "[Epoch 177/200] [Batch 94/200] [D loss: 0.000101] [G loss: 0.018129]\n",
            "[Epoch 177/200] [Batch 95/200] [D loss: 0.000088] [G loss: 0.015470]\n",
            "[Epoch 177/200] [Batch 96/200] [D loss: 0.000120] [G loss: 0.018745]\n",
            "[Epoch 177/200] [Batch 97/200] [D loss: 0.000209] [G loss: 0.017339]\n",
            "[Epoch 177/200] [Batch 98/200] [D loss: 0.000404] [G loss: 0.016036]\n",
            "[Epoch 177/200] [Batch 99/200] [D loss: 0.000279] [G loss: 0.019542]\n",
            "[Epoch 177/200] [Batch 100/200] [D loss: 0.000224] [G loss: 0.012590]\n",
            "[Epoch 177/200] [Batch 101/200] [D loss: 0.000339] [G loss: 0.015219]\n",
            "[Epoch 177/200] [Batch 102/200] [D loss: 0.000378] [G loss: 0.015078]\n",
            "[Epoch 177/200] [Batch 103/200] [D loss: 0.000666] [G loss: 0.018322]\n",
            "[Epoch 177/200] [Batch 104/200] [D loss: 0.000384] [G loss: 0.020339]\n",
            "[Epoch 177/200] [Batch 105/200] [D loss: 0.000192] [G loss: 0.019151]\n",
            "[Epoch 177/200] [Batch 106/200] [D loss: 0.000130] [G loss: 0.013806]\n",
            "[Epoch 177/200] [Batch 107/200] [D loss: 0.000059] [G loss: 0.017299]\n",
            "[Epoch 177/200] [Batch 108/200] [D loss: 0.000172] [G loss: 0.014865]\n",
            "[Epoch 177/200] [Batch 109/200] [D loss: 0.000340] [G loss: 0.018683]\n",
            "[Epoch 177/200] [Batch 110/200] [D loss: 0.000488] [G loss: 0.016595]\n",
            "[Epoch 177/200] [Batch 111/200] [D loss: 0.000331] [G loss: 0.019230]\n",
            "[Epoch 177/200] [Batch 112/200] [D loss: 0.000127] [G loss: 0.014183]\n",
            "[Epoch 177/200] [Batch 113/200] [D loss: 0.000156] [G loss: 0.018622]\n",
            "[Epoch 177/200] [Batch 114/200] [D loss: 0.000140] [G loss: 0.020677]\n",
            "[Epoch 177/200] [Batch 115/200] [D loss: 0.000307] [G loss: 0.016394]\n",
            "[Epoch 177/200] [Batch 116/200] [D loss: 0.000130] [G loss: 0.022124]\n",
            "[Epoch 177/200] [Batch 117/200] [D loss: 0.000094] [G loss: 0.018348]\n",
            "[Epoch 177/200] [Batch 118/200] [D loss: 0.000136] [G loss: 0.017157]\n",
            "[Epoch 177/200] [Batch 119/200] [D loss: 0.000123] [G loss: 0.018966]\n",
            "[Epoch 177/200] [Batch 120/200] [D loss: 0.000129] [G loss: 0.016734]\n",
            "[Epoch 177/200] [Batch 121/200] [D loss: 0.000096] [G loss: 0.016236]\n",
            "[Epoch 177/200] [Batch 122/200] [D loss: 0.000122] [G loss: 0.015989]\n",
            "[Epoch 177/200] [Batch 123/200] [D loss: 0.000127] [G loss: 0.016409]\n",
            "[Epoch 177/200] [Batch 124/200] [D loss: 0.000121] [G loss: 0.017463]\n",
            "[Epoch 177/200] [Batch 125/200] [D loss: 0.000106] [G loss: 0.020561]\n",
            "[Epoch 177/200] [Batch 126/200] [D loss: 0.000322] [G loss: 0.021643]\n",
            "[Epoch 177/200] [Batch 127/200] [D loss: 0.000456] [G loss: 0.018985]\n",
            "[Epoch 177/200] [Batch 128/200] [D loss: 0.000623] [G loss: 0.017166]\n",
            "[Epoch 177/200] [Batch 129/200] [D loss: 0.000525] [G loss: 0.014135]\n",
            "[Epoch 177/200] [Batch 130/200] [D loss: 0.000422] [G loss: 0.018285]\n",
            "[Epoch 177/200] [Batch 131/200] [D loss: 0.000129] [G loss: 0.019226]\n",
            "[Epoch 177/200] [Batch 132/200] [D loss: 0.000138] [G loss: 0.015911]\n",
            "[Epoch 177/200] [Batch 133/200] [D loss: 0.000141] [G loss: 0.021564]\n",
            "[Epoch 177/200] [Batch 134/200] [D loss: 0.000218] [G loss: 0.017113]\n",
            "[Epoch 177/200] [Batch 135/200] [D loss: 0.000131] [G loss: 0.015521]\n",
            "[Epoch 177/200] [Batch 136/200] [D loss: 0.000111] [G loss: 0.019452]\n",
            "[Epoch 177/200] [Batch 137/200] [D loss: 0.000470] [G loss: 0.016657]\n",
            "[Epoch 177/200] [Batch 138/200] [D loss: 0.000638] [G loss: 0.013650]\n",
            "[Epoch 177/200] [Batch 139/200] [D loss: 0.000226] [G loss: 0.018329]\n",
            "[Epoch 177/200] [Batch 140/200] [D loss: 0.000339] [G loss: 0.017419]\n",
            "[Epoch 177/200] [Batch 141/200] [D loss: 0.000147] [G loss: 0.020055]\n",
            "[Epoch 177/200] [Batch 142/200] [D loss: 0.000123] [G loss: 0.019698]\n",
            "[Epoch 177/200] [Batch 143/200] [D loss: 0.000087] [G loss: 0.019500]\n",
            "[Epoch 177/200] [Batch 144/200] [D loss: 0.000142] [G loss: 0.017929]\n",
            "[Epoch 177/200] [Batch 145/200] [D loss: 0.000138] [G loss: 0.019010]\n",
            "[Epoch 177/200] [Batch 146/200] [D loss: 0.000152] [G loss: 0.017680]\n",
            "[Epoch 177/200] [Batch 147/200] [D loss: 0.000218] [G loss: 0.018985]\n",
            "[Epoch 177/200] [Batch 148/200] [D loss: 0.000099] [G loss: 0.021139]\n",
            "[Epoch 177/200] [Batch 149/200] [D loss: 0.000096] [G loss: 0.015248]\n",
            "[Epoch 177/200] [Batch 150/200] [D loss: 0.000156] [G loss: 0.017617]\n",
            "[Epoch 177/200] [Batch 151/200] [D loss: 0.000203] [G loss: 0.016190]\n",
            "[Epoch 177/200] [Batch 152/200] [D loss: 0.000457] [G loss: 0.020345]\n",
            "[Epoch 177/200] [Batch 153/200] [D loss: 0.000292] [G loss: 0.017175]\n",
            "[Epoch 177/200] [Batch 154/200] [D loss: 0.000214] [G loss: 0.017445]\n",
            "[Epoch 177/200] [Batch 155/200] [D loss: 0.000228] [G loss: 0.018938]\n",
            "[Epoch 177/200] [Batch 156/200] [D loss: 0.000167] [G loss: 0.016089]\n",
            "[Epoch 177/200] [Batch 157/200] [D loss: 0.000167] [G loss: 0.019139]\n",
            "[Epoch 177/200] [Batch 158/200] [D loss: 0.000179] [G loss: 0.020680]\n",
            "[Epoch 177/200] [Batch 159/200] [D loss: 0.000157] [G loss: 0.016021]\n",
            "[Epoch 177/200] [Batch 160/200] [D loss: 0.000276] [G loss: 0.018811]\n",
            "[Epoch 177/200] [Batch 161/200] [D loss: 0.000380] [G loss: 0.021607]\n",
            "[Epoch 177/200] [Batch 162/200] [D loss: 0.000096] [G loss: 0.020282]\n",
            "[Epoch 177/200] [Batch 163/200] [D loss: 0.000223] [G loss: 0.016605]\n",
            "[Epoch 177/200] [Batch 164/200] [D loss: 0.000271] [G loss: 0.020013]\n",
            "[Epoch 177/200] [Batch 165/200] [D loss: 0.000375] [G loss: 0.020161]\n",
            "[Epoch 177/200] [Batch 166/200] [D loss: 0.000393] [G loss: 0.016580]\n",
            "[Epoch 177/200] [Batch 167/200] [D loss: 0.000294] [G loss: 0.017795]\n",
            "[Epoch 177/200] [Batch 168/200] [D loss: 0.000213] [G loss: 0.014899]\n",
            "[Epoch 177/200] [Batch 169/200] [D loss: 0.000176] [G loss: 0.017324]\n",
            "[Epoch 177/200] [Batch 170/200] [D loss: 0.000198] [G loss: 0.016588]\n",
            "[Epoch 177/200] [Batch 171/200] [D loss: 0.000119] [G loss: 0.018678]\n",
            "[Epoch 177/200] [Batch 172/200] [D loss: 0.000137] [G loss: 0.018278]\n",
            "[Epoch 177/200] [Batch 173/200] [D loss: 0.000161] [G loss: 0.019854]\n",
            "[Epoch 177/200] [Batch 174/200] [D loss: 0.000084] [G loss: 0.017304]\n",
            "[Epoch 177/200] [Batch 175/200] [D loss: 0.000099] [G loss: 0.015055]\n",
            "[Epoch 177/200] [Batch 176/200] [D loss: 0.000120] [G loss: 0.019630]\n",
            "[Epoch 177/200] [Batch 177/200] [D loss: 0.000100] [G loss: 0.017903]\n",
            "[Epoch 177/200] [Batch 178/200] [D loss: 0.000094] [G loss: 0.015890]\n",
            "[Epoch 177/200] [Batch 179/200] [D loss: 0.000113] [G loss: 0.015089]\n",
            "[Epoch 177/200] [Batch 180/200] [D loss: 0.000094] [G loss: 0.013233]\n",
            "[Epoch 177/200] [Batch 181/200] [D loss: 0.000081] [G loss: 0.018704]\n",
            "[Epoch 177/200] [Batch 182/200] [D loss: 0.000088] [G loss: 0.018417]\n",
            "[Epoch 177/200] [Batch 183/200] [D loss: 0.000128] [G loss: 0.019796]\n",
            "[Epoch 177/200] [Batch 184/200] [D loss: 0.000135] [G loss: 0.016547]\n",
            "[Epoch 177/200] [Batch 185/200] [D loss: 0.000101] [G loss: 0.015630]\n",
            "[Epoch 177/200] [Batch 186/200] [D loss: 0.000144] [G loss: 0.016128]\n",
            "[Epoch 177/200] [Batch 187/200] [D loss: 0.000154] [G loss: 0.018156]\n",
            "[Epoch 177/200] [Batch 188/200] [D loss: 0.000228] [G loss: 0.017220]\n",
            "[Epoch 177/200] [Batch 189/200] [D loss: 0.000129] [G loss: 0.019337]\n",
            "[Epoch 177/200] [Batch 190/200] [D loss: 0.000254] [G loss: 0.016895]\n",
            "[Epoch 177/200] [Batch 191/200] [D loss: 0.000261] [G loss: 0.014820]\n",
            "[Epoch 177/200] [Batch 192/200] [D loss: 0.000124] [G loss: 0.012783]\n",
            "[Epoch 177/200] [Batch 193/200] [D loss: 0.000161] [G loss: 0.015019]\n",
            "[Epoch 177/200] [Batch 194/200] [D loss: 0.000278] [G loss: 0.019230]\n",
            "[Epoch 177/200] [Batch 195/200] [D loss: 0.000239] [G loss: 0.019899]\n",
            "[Epoch 177/200] [Batch 196/200] [D loss: 0.000228] [G loss: 0.016497]\n",
            "[Epoch 177/200] [Batch 197/200] [D loss: 0.000197] [G loss: 0.017675]\n",
            "[Epoch 177/200] [Batch 198/200] [D loss: 0.000165] [G loss: 0.021032]\n",
            "[Epoch 177/200] [Batch 199/200] [D loss: 0.000153] [G loss: 0.018853]\n",
            "[Epoch 178/200] [Batch 0/200] [D loss: 0.000176] [G loss: 0.018209]\n",
            "[Epoch 178/200] [Batch 1/200] [D loss: 0.000275] [G loss: 0.014772]\n",
            "[Epoch 178/200] [Batch 2/200] [D loss: 0.000150] [G loss: 0.021369]\n",
            "[Epoch 178/200] [Batch 3/200] [D loss: 0.000102] [G loss: 0.018791]\n",
            "[Epoch 178/200] [Batch 4/200] [D loss: 0.000108] [G loss: 0.017231]\n",
            "[Epoch 178/200] [Batch 5/200] [D loss: 0.000074] [G loss: 0.020445]\n",
            "[Epoch 178/200] [Batch 6/200] [D loss: 0.000110] [G loss: 0.018689]\n",
            "[Epoch 178/200] [Batch 7/200] [D loss: 0.000099] [G loss: 0.016766]\n",
            "[Epoch 178/200] [Batch 8/200] [D loss: 0.000394] [G loss: 0.018094]\n",
            "[Epoch 178/200] [Batch 9/200] [D loss: 0.000419] [G loss: 0.015064]\n",
            "[Epoch 178/200] [Batch 10/200] [D loss: 0.000213] [G loss: 0.017269]\n",
            "[Epoch 178/200] [Batch 11/200] [D loss: 0.000526] [G loss: 0.014929]\n",
            "[Epoch 178/200] [Batch 12/200] [D loss: 0.000499] [G loss: 0.017844]\n",
            "[Epoch 178/200] [Batch 13/200] [D loss: 0.000213] [G loss: 0.018801]\n",
            "[Epoch 178/200] [Batch 14/200] [D loss: 0.000302] [G loss: 0.018209]\n",
            "[Epoch 178/200] [Batch 15/200] [D loss: 0.000481] [G loss: 0.018180]\n",
            "[Epoch 178/200] [Batch 16/200] [D loss: 0.000493] [G loss: 0.013455]\n",
            "[Epoch 178/200] [Batch 17/200] [D loss: 0.000145] [G loss: 0.016094]\n",
            "[Epoch 178/200] [Batch 18/200] [D loss: 0.000208] [G loss: 0.024163]\n",
            "[Epoch 178/200] [Batch 19/200] [D loss: 0.000121] [G loss: 0.015918]\n",
            "[Epoch 178/200] [Batch 20/200] [D loss: 0.000153] [G loss: 0.018397]\n",
            "[Epoch 178/200] [Batch 21/200] [D loss: 0.000168] [G loss: 0.016878]\n",
            "[Epoch 178/200] [Batch 22/200] [D loss: 0.000135] [G loss: 0.015812]\n",
            "[Epoch 178/200] [Batch 23/200] [D loss: 0.000093] [G loss: 0.014777]\n",
            "[Epoch 178/200] [Batch 24/200] [D loss: 0.000131] [G loss: 0.019741]\n",
            "[Epoch 178/200] [Batch 25/200] [D loss: 0.000170] [G loss: 0.015311]\n",
            "[Epoch 178/200] [Batch 26/200] [D loss: 0.000087] [G loss: 0.013521]\n",
            "[Epoch 178/200] [Batch 27/200] [D loss: 0.000179] [G loss: 0.020726]\n",
            "[Epoch 178/200] [Batch 28/200] [D loss: 0.000107] [G loss: 0.014995]\n",
            "[Epoch 178/200] [Batch 29/200] [D loss: 0.000108] [G loss: 0.018077]\n",
            "[Epoch 178/200] [Batch 30/200] [D loss: 0.000093] [G loss: 0.018028]\n",
            "[Epoch 178/200] [Batch 31/200] [D loss: 0.000078] [G loss: 0.017507]\n",
            "[Epoch 178/200] [Batch 32/200] [D loss: 0.000097] [G loss: 0.017442]\n",
            "[Epoch 178/200] [Batch 33/200] [D loss: 0.000269] [G loss: 0.018373]\n",
            "[Epoch 178/200] [Batch 34/200] [D loss: 0.000198] [G loss: 0.017842]\n",
            "[Epoch 178/200] [Batch 35/200] [D loss: 0.000149] [G loss: 0.020009]\n",
            "[Epoch 178/200] [Batch 36/200] [D loss: 0.000320] [G loss: 0.021576]\n",
            "[Epoch 178/200] [Batch 37/200] [D loss: 0.000259] [G loss: 0.017742]\n",
            "[Epoch 178/200] [Batch 38/200] [D loss: 0.000461] [G loss: 0.018921]\n",
            "[Epoch 178/200] [Batch 39/200] [D loss: 0.001179] [G loss: 0.016011]\n",
            "[Epoch 178/200] [Batch 40/200] [D loss: 0.000822] [G loss: 0.019013]\n",
            "[Epoch 178/200] [Batch 41/200] [D loss: 0.000309] [G loss: 0.023858]\n",
            "[Epoch 178/200] [Batch 42/200] [D loss: 0.000391] [G loss: 0.013913]\n",
            "[Epoch 178/200] [Batch 43/200] [D loss: 0.000389] [G loss: 0.015629]\n",
            "[Epoch 178/200] [Batch 44/200] [D loss: 0.000138] [G loss: 0.021040]\n",
            "[Epoch 178/200] [Batch 45/200] [D loss: 0.000211] [G loss: 0.017823]\n",
            "[Epoch 178/200] [Batch 46/200] [D loss: 0.000163] [G loss: 0.018437]\n",
            "[Epoch 178/200] [Batch 47/200] [D loss: 0.000126] [G loss: 0.018388]\n",
            "[Epoch 178/200] [Batch 48/200] [D loss: 0.000186] [G loss: 0.020825]\n",
            "[Epoch 178/200] [Batch 49/200] [D loss: 0.000279] [G loss: 0.020413]\n",
            "[Epoch 178/200] [Batch 50/200] [D loss: 0.000232] [G loss: 0.016541]\n",
            "[Epoch 178/200] [Batch 51/200] [D loss: 0.000090] [G loss: 0.015709]\n",
            "[Epoch 178/200] [Batch 52/200] [D loss: 0.000103] [G loss: 0.018434]\n",
            "[Epoch 178/200] [Batch 53/200] [D loss: 0.000072] [G loss: 0.014684]\n",
            "[Epoch 178/200] [Batch 54/200] [D loss: 0.000107] [G loss: 0.017945]\n",
            "[Epoch 178/200] [Batch 55/200] [D loss: 0.000192] [G loss: 0.013138]\n",
            "[Epoch 178/200] [Batch 56/200] [D loss: 0.000135] [G loss: 0.016930]\n",
            "[Epoch 178/200] [Batch 57/200] [D loss: 0.000153] [G loss: 0.018487]\n",
            "[Epoch 178/200] [Batch 58/200] [D loss: 0.000246] [G loss: 0.023886]\n",
            "[Epoch 178/200] [Batch 59/200] [D loss: 0.000179] [G loss: 0.016812]\n",
            "[Epoch 178/200] [Batch 60/200] [D loss: 0.000302] [G loss: 0.020779]\n",
            "[Epoch 178/200] [Batch 61/200] [D loss: 0.000161] [G loss: 0.022099]\n",
            "[Epoch 178/200] [Batch 62/200] [D loss: 0.000102] [G loss: 0.019143]\n",
            "[Epoch 178/200] [Batch 63/200] [D loss: 0.000097] [G loss: 0.016755]\n",
            "[Epoch 178/200] [Batch 64/200] [D loss: 0.000148] [G loss: 0.018438]\n",
            "[Epoch 178/200] [Batch 65/200] [D loss: 0.000126] [G loss: 0.018135]\n",
            "[Epoch 178/200] [Batch 66/200] [D loss: 0.000262] [G loss: 0.018420]\n",
            "[Epoch 178/200] [Batch 67/200] [D loss: 0.000170] [G loss: 0.014109]\n",
            "[Epoch 178/200] [Batch 68/200] [D loss: 0.000223] [G loss: 0.014457]\n",
            "[Epoch 178/200] [Batch 69/200] [D loss: 0.000200] [G loss: 0.021224]\n",
            "[Epoch 178/200] [Batch 70/200] [D loss: 0.000148] [G loss: 0.019233]\n",
            "[Epoch 178/200] [Batch 71/200] [D loss: 0.000318] [G loss: 0.018955]\n",
            "[Epoch 178/200] [Batch 72/200] [D loss: 0.000150] [G loss: 0.015022]\n",
            "[Epoch 178/200] [Batch 73/200] [D loss: 0.000218] [G loss: 0.019776]\n",
            "[Epoch 178/200] [Batch 74/200] [D loss: 0.000394] [G loss: 0.018608]\n",
            "[Epoch 178/200] [Batch 75/200] [D loss: 0.000235] [G loss: 0.018259]\n",
            "[Epoch 178/200] [Batch 76/200] [D loss: 0.000459] [G loss: 0.017368]\n",
            "[Epoch 178/200] [Batch 77/200] [D loss: 0.001821] [G loss: 0.018167]\n",
            "[Epoch 178/200] [Batch 78/200] [D loss: 0.002906] [G loss: 0.018024]\n",
            "[Epoch 178/200] [Batch 79/200] [D loss: 0.001514] [G loss: 0.020307]\n",
            "[Epoch 178/200] [Batch 80/200] [D loss: 0.000562] [G loss: 0.015653]\n",
            "[Epoch 178/200] [Batch 81/200] [D loss: 0.000645] [G loss: 0.021334]\n",
            "[Epoch 178/200] [Batch 82/200] [D loss: 0.000884] [G loss: 0.016289]\n",
            "[Epoch 178/200] [Batch 83/200] [D loss: 0.000156] [G loss: 0.016882]\n",
            "[Epoch 178/200] [Batch 84/200] [D loss: 0.000279] [G loss: 0.019054]\n",
            "[Epoch 178/200] [Batch 85/200] [D loss: 0.000179] [G loss: 0.015332]\n",
            "[Epoch 178/200] [Batch 86/200] [D loss: 0.000184] [G loss: 0.019739]\n",
            "[Epoch 178/200] [Batch 87/200] [D loss: 0.000107] [G loss: 0.016925]\n",
            "[Epoch 178/200] [Batch 88/200] [D loss: 0.000146] [G loss: 0.015396]\n",
            "[Epoch 178/200] [Batch 89/200] [D loss: 0.000219] [G loss: 0.018314]\n",
            "[Epoch 178/200] [Batch 90/200] [D loss: 0.000238] [G loss: 0.016298]\n",
            "[Epoch 178/200] [Batch 91/200] [D loss: 0.000184] [G loss: 0.019647]\n",
            "[Epoch 178/200] [Batch 92/200] [D loss: 0.000213] [G loss: 0.018538]\n",
            "[Epoch 178/200] [Batch 93/200] [D loss: 0.000164] [G loss: 0.016310]\n",
            "[Epoch 178/200] [Batch 94/200] [D loss: 0.000092] [G loss: 0.014995]\n",
            "[Epoch 178/200] [Batch 95/200] [D loss: 0.000189] [G loss: 0.016539]\n",
            "[Epoch 178/200] [Batch 96/200] [D loss: 0.000214] [G loss: 0.016883]\n",
            "[Epoch 178/200] [Batch 97/200] [D loss: 0.000154] [G loss: 0.015217]\n",
            "[Epoch 178/200] [Batch 98/200] [D loss: 0.000069] [G loss: 0.016941]\n",
            "[Epoch 178/200] [Batch 99/200] [D loss: 0.000126] [G loss: 0.019014]\n",
            "[Epoch 178/200] [Batch 100/200] [D loss: 0.000303] [G loss: 0.018590]\n",
            "[Epoch 178/200] [Batch 101/200] [D loss: 0.000470] [G loss: 0.020022]\n",
            "[Epoch 178/200] [Batch 102/200] [D loss: 0.000171] [G loss: 0.019438]\n",
            "[Epoch 178/200] [Batch 103/200] [D loss: 0.000358] [G loss: 0.018732]\n",
            "[Epoch 178/200] [Batch 104/200] [D loss: 0.001329] [G loss: 0.016536]\n",
            "[Epoch 178/200] [Batch 105/200] [D loss: 0.001928] [G loss: 0.015713]\n",
            "[Epoch 178/200] [Batch 106/200] [D loss: 0.001647] [G loss: 0.017124]\n",
            "[Epoch 178/200] [Batch 107/200] [D loss: 0.001367] [G loss: 0.016616]\n",
            "[Epoch 178/200] [Batch 108/200] [D loss: 0.000455] [G loss: 0.016258]\n",
            "[Epoch 178/200] [Batch 109/200] [D loss: 0.001397] [G loss: 0.017288]\n",
            "[Epoch 178/200] [Batch 110/200] [D loss: 0.002620] [G loss: 0.014752]\n",
            "[Epoch 178/200] [Batch 111/200] [D loss: 0.001006] [G loss: 0.016173]\n",
            "[Epoch 178/200] [Batch 112/200] [D loss: 0.000627] [G loss: 0.014209]\n",
            "[Epoch 178/200] [Batch 113/200] [D loss: 0.000280] [G loss: 0.018872]\n",
            "[Epoch 178/200] [Batch 114/200] [D loss: 0.000257] [G loss: 0.017963]\n",
            "[Epoch 178/200] [Batch 115/200] [D loss: 0.000199] [G loss: 0.018115]\n",
            "[Epoch 178/200] [Batch 116/200] [D loss: 0.000173] [G loss: 0.016851]\n",
            "[Epoch 178/200] [Batch 117/200] [D loss: 0.000253] [G loss: 0.017072]\n",
            "[Epoch 178/200] [Batch 118/200] [D loss: 0.000189] [G loss: 0.020829]\n",
            "[Epoch 178/200] [Batch 119/200] [D loss: 0.000311] [G loss: 0.016332]\n",
            "[Epoch 178/200] [Batch 120/200] [D loss: 0.000146] [G loss: 0.014068]\n",
            "[Epoch 178/200] [Batch 121/200] [D loss: 0.000405] [G loss: 0.018050]\n",
            "[Epoch 178/200] [Batch 122/200] [D loss: 0.000266] [G loss: 0.019297]\n",
            "[Epoch 178/200] [Batch 123/200] [D loss: 0.000338] [G loss: 0.014427]\n",
            "[Epoch 178/200] [Batch 124/200] [D loss: 0.000165] [G loss: 0.017609]\n",
            "[Epoch 178/200] [Batch 125/200] [D loss: 0.000230] [G loss: 0.015186]\n",
            "[Epoch 178/200] [Batch 126/200] [D loss: 0.000151] [G loss: 0.015481]\n",
            "[Epoch 178/200] [Batch 127/200] [D loss: 0.000160] [G loss: 0.014763]\n",
            "[Epoch 178/200] [Batch 128/200] [D loss: 0.000330] [G loss: 0.018219]\n",
            "[Epoch 178/200] [Batch 129/200] [D loss: 0.000270] [G loss: 0.016422]\n",
            "[Epoch 178/200] [Batch 130/200] [D loss: 0.000215] [G loss: 0.018244]\n",
            "[Epoch 178/200] [Batch 131/200] [D loss: 0.000608] [G loss: 0.025234]\n",
            "[Epoch 178/200] [Batch 132/200] [D loss: 0.000613] [G loss: 0.015747]\n",
            "[Epoch 178/200] [Batch 133/200] [D loss: 0.000346] [G loss: 0.020407]\n",
            "[Epoch 178/200] [Batch 134/200] [D loss: 0.000999] [G loss: 0.018817]\n",
            "[Epoch 178/200] [Batch 135/200] [D loss: 0.000681] [G loss: 0.017984]\n",
            "[Epoch 178/200] [Batch 136/200] [D loss: 0.000699] [G loss: 0.018772]\n",
            "[Epoch 178/200] [Batch 137/200] [D loss: 0.000295] [G loss: 0.018157]\n",
            "[Epoch 178/200] [Batch 138/200] [D loss: 0.000608] [G loss: 0.016516]\n",
            "[Epoch 178/200] [Batch 139/200] [D loss: 0.000449] [G loss: 0.014204]\n",
            "[Epoch 178/200] [Batch 140/200] [D loss: 0.000333] [G loss: 0.017901]\n",
            "[Epoch 178/200] [Batch 141/200] [D loss: 0.000238] [G loss: 0.019360]\n",
            "[Epoch 178/200] [Batch 142/200] [D loss: 0.000210] [G loss: 0.016017]\n",
            "[Epoch 178/200] [Batch 143/200] [D loss: 0.000176] [G loss: 0.015413]\n",
            "[Epoch 178/200] [Batch 144/200] [D loss: 0.000138] [G loss: 0.021505]\n",
            "[Epoch 178/200] [Batch 145/200] [D loss: 0.000092] [G loss: 0.017613]\n",
            "[Epoch 178/200] [Batch 146/200] [D loss: 0.000160] [G loss: 0.017479]\n",
            "[Epoch 178/200] [Batch 147/200] [D loss: 0.000304] [G loss: 0.019677]\n",
            "[Epoch 178/200] [Batch 148/200] [D loss: 0.001121] [G loss: 0.015649]\n",
            "[Epoch 178/200] [Batch 149/200] [D loss: 0.004388] [G loss: 0.017727]\n",
            "[Epoch 178/200] [Batch 150/200] [D loss: 0.011154] [G loss: 0.021631]\n",
            "[Epoch 178/200] [Batch 151/200] [D loss: 0.010922] [G loss: 0.017295]\n",
            "[Epoch 178/200] [Batch 152/200] [D loss: 0.005897] [G loss: 0.018875]\n",
            "[Epoch 178/200] [Batch 153/200] [D loss: 0.001692] [G loss: 0.015195]\n",
            "[Epoch 178/200] [Batch 154/200] [D loss: 0.003677] [G loss: 0.017655]\n",
            "[Epoch 178/200] [Batch 155/200] [D loss: 0.001791] [G loss: 0.020822]\n",
            "[Epoch 178/200] [Batch 156/200] [D loss: 0.001150] [G loss: 0.015710]\n",
            "[Epoch 178/200] [Batch 157/200] [D loss: 0.001861] [G loss: 0.016508]\n",
            "[Epoch 178/200] [Batch 158/200] [D loss: 0.000586] [G loss: 0.014375]\n",
            "[Epoch 178/200] [Batch 159/200] [D loss: 0.000952] [G loss: 0.015793]\n",
            "[Epoch 178/200] [Batch 160/200] [D loss: 0.001770] [G loss: 0.019417]\n",
            "[Epoch 178/200] [Batch 161/200] [D loss: 0.003197] [G loss: 0.016016]\n",
            "[Epoch 178/200] [Batch 162/200] [D loss: 0.001362] [G loss: 0.018927]\n",
            "[Epoch 178/200] [Batch 163/200] [D loss: 0.001080] [G loss: 0.017457]\n",
            "[Epoch 178/200] [Batch 164/200] [D loss: 0.001322] [G loss: 0.013543]\n",
            "[Epoch 178/200] [Batch 165/200] [D loss: 0.000731] [G loss: 0.021261]\n",
            "[Epoch 178/200] [Batch 166/200] [D loss: 0.000284] [G loss: 0.019188]\n",
            "[Epoch 178/200] [Batch 167/200] [D loss: 0.000285] [G loss: 0.014275]\n",
            "[Epoch 178/200] [Batch 168/200] [D loss: 0.000171] [G loss: 0.020975]\n",
            "[Epoch 178/200] [Batch 169/200] [D loss: 0.000350] [G loss: 0.018192]\n",
            "[Epoch 178/200] [Batch 170/200] [D loss: 0.000217] [G loss: 0.014996]\n",
            "[Epoch 178/200] [Batch 171/200] [D loss: 0.000374] [G loss: 0.016702]\n",
            "[Epoch 178/200] [Batch 172/200] [D loss: 0.000589] [G loss: 0.017391]\n",
            "[Epoch 178/200] [Batch 173/200] [D loss: 0.000343] [G loss: 0.021919]\n",
            "[Epoch 178/200] [Batch 174/200] [D loss: 0.000216] [G loss: 0.017790]\n",
            "[Epoch 178/200] [Batch 175/200] [D loss: 0.000455] [G loss: 0.017155]\n",
            "[Epoch 178/200] [Batch 176/200] [D loss: 0.000242] [G loss: 0.015668]\n",
            "[Epoch 178/200] [Batch 177/200] [D loss: 0.000293] [G loss: 0.021101]\n",
            "[Epoch 178/200] [Batch 178/200] [D loss: 0.000227] [G loss: 0.019703]\n",
            "[Epoch 178/200] [Batch 179/200] [D loss: 0.000262] [G loss: 0.017234]\n",
            "[Epoch 178/200] [Batch 180/200] [D loss: 0.000258] [G loss: 0.016611]\n",
            "[Epoch 178/200] [Batch 181/200] [D loss: 0.000633] [G loss: 0.015318]\n",
            "[Epoch 178/200] [Batch 182/200] [D loss: 0.000784] [G loss: 0.018056]\n",
            "[Epoch 178/200] [Batch 183/200] [D loss: 0.000213] [G loss: 0.018116]\n",
            "[Epoch 178/200] [Batch 184/200] [D loss: 0.000176] [G loss: 0.020687]\n",
            "[Epoch 178/200] [Batch 185/200] [D loss: 0.000309] [G loss: 0.016199]\n",
            "[Epoch 178/200] [Batch 186/200] [D loss: 0.000257] [G loss: 0.019579]\n",
            "[Epoch 178/200] [Batch 187/200] [D loss: 0.000199] [G loss: 0.016186]\n",
            "[Epoch 178/200] [Batch 188/200] [D loss: 0.000173] [G loss: 0.019136]\n",
            "[Epoch 178/200] [Batch 189/200] [D loss: 0.000086] [G loss: 0.018049]\n",
            "[Epoch 178/200] [Batch 190/200] [D loss: 0.000192] [G loss: 0.021285]\n",
            "[Epoch 178/200] [Batch 191/200] [D loss: 0.000078] [G loss: 0.014017]\n",
            "[Epoch 178/200] [Batch 192/200] [D loss: 0.000129] [G loss: 0.017068]\n",
            "[Epoch 178/200] [Batch 193/200] [D loss: 0.000134] [G loss: 0.018660]\n",
            "[Epoch 178/200] [Batch 194/200] [D loss: 0.000188] [G loss: 0.016348]\n",
            "[Epoch 178/200] [Batch 195/200] [D loss: 0.000075] [G loss: 0.016912]\n",
            "[Epoch 178/200] [Batch 196/200] [D loss: 0.000113] [G loss: 0.018785]\n",
            "[Epoch 178/200] [Batch 197/200] [D loss: 0.000101] [G loss: 0.014671]\n",
            "[Epoch 178/200] [Batch 198/200] [D loss: 0.000084] [G loss: 0.019167]\n",
            "[Epoch 178/200] [Batch 199/200] [D loss: 0.000096] [G loss: 0.013564]\n",
            "[Epoch 179/200] [Batch 0/200] [D loss: 0.000111] [G loss: 0.018949]\n",
            "[Epoch 179/200] [Batch 1/200] [D loss: 0.000152] [G loss: 0.017053]\n",
            "[Epoch 179/200] [Batch 2/200] [D loss: 0.000102] [G loss: 0.016963]\n",
            "[Epoch 179/200] [Batch 3/200] [D loss: 0.000136] [G loss: 0.017024]\n",
            "[Epoch 179/200] [Batch 4/200] [D loss: 0.000134] [G loss: 0.019581]\n",
            "[Epoch 179/200] [Batch 5/200] [D loss: 0.000203] [G loss: 0.018323]\n",
            "[Epoch 179/200] [Batch 6/200] [D loss: 0.000119] [G loss: 0.016092]\n",
            "[Epoch 179/200] [Batch 7/200] [D loss: 0.000142] [G loss: 0.018111]\n",
            "[Epoch 179/200] [Batch 8/200] [D loss: 0.000240] [G loss: 0.023600]\n",
            "[Epoch 179/200] [Batch 9/200] [D loss: 0.000093] [G loss: 0.019214]\n",
            "[Epoch 179/200] [Batch 10/200] [D loss: 0.000302] [G loss: 0.020140]\n",
            "[Epoch 179/200] [Batch 11/200] [D loss: 0.000107] [G loss: 0.014792]\n",
            "[Epoch 179/200] [Batch 12/200] [D loss: 0.000271] [G loss: 0.015019]\n",
            "[Epoch 179/200] [Batch 13/200] [D loss: 0.000259] [G loss: 0.018943]\n",
            "[Epoch 179/200] [Batch 14/200] [D loss: 0.000115] [G loss: 0.018458]\n",
            "[Epoch 179/200] [Batch 15/200] [D loss: 0.000219] [G loss: 0.020329]\n",
            "[Epoch 179/200] [Batch 16/200] [D loss: 0.000123] [G loss: 0.016985]\n",
            "[Epoch 179/200] [Batch 17/200] [D loss: 0.000159] [G loss: 0.018767]\n",
            "[Epoch 179/200] [Batch 18/200] [D loss: 0.000231] [G loss: 0.017892]\n",
            "[Epoch 179/200] [Batch 19/200] [D loss: 0.000177] [G loss: 0.020861]\n",
            "[Epoch 179/200] [Batch 20/200] [D loss: 0.000103] [G loss: 0.020906]\n",
            "[Epoch 179/200] [Batch 21/200] [D loss: 0.000172] [G loss: 0.020651]\n",
            "[Epoch 179/200] [Batch 22/200] [D loss: 0.000143] [G loss: 0.016496]\n",
            "[Epoch 179/200] [Batch 23/200] [D loss: 0.000143] [G loss: 0.016996]\n",
            "[Epoch 179/200] [Batch 24/200] [D loss: 0.000233] [G loss: 0.019976]\n",
            "[Epoch 179/200] [Batch 25/200] [D loss: 0.000218] [G loss: 0.022314]\n",
            "[Epoch 179/200] [Batch 26/200] [D loss: 0.000195] [G loss: 0.014975]\n",
            "[Epoch 179/200] [Batch 27/200] [D loss: 0.000103] [G loss: 0.020803]\n",
            "[Epoch 179/200] [Batch 28/200] [D loss: 0.000143] [G loss: 0.014435]\n",
            "[Epoch 179/200] [Batch 29/200] [D loss: 0.000102] [G loss: 0.020094]\n",
            "[Epoch 179/200] [Batch 30/200] [D loss: 0.000066] [G loss: 0.014675]\n",
            "[Epoch 179/200] [Batch 31/200] [D loss: 0.000076] [G loss: 0.017549]\n",
            "[Epoch 179/200] [Batch 32/200] [D loss: 0.000134] [G loss: 0.018207]\n",
            "[Epoch 179/200] [Batch 33/200] [D loss: 0.000160] [G loss: 0.015756]\n",
            "[Epoch 179/200] [Batch 34/200] [D loss: 0.000119] [G loss: 0.016976]\n",
            "[Epoch 179/200] [Batch 35/200] [D loss: 0.000151] [G loss: 0.020823]\n",
            "[Epoch 179/200] [Batch 36/200] [D loss: 0.000102] [G loss: 0.015896]\n",
            "[Epoch 179/200] [Batch 37/200] [D loss: 0.000153] [G loss: 0.015993]\n",
            "[Epoch 179/200] [Batch 38/200] [D loss: 0.000099] [G loss: 0.018692]\n",
            "[Epoch 179/200] [Batch 39/200] [D loss: 0.000133] [G loss: 0.019258]\n",
            "[Epoch 179/200] [Batch 40/200] [D loss: 0.000182] [G loss: 0.019335]\n",
            "[Epoch 179/200] [Batch 41/200] [D loss: 0.000147] [G loss: 0.017744]\n",
            "[Epoch 179/200] [Batch 42/200] [D loss: 0.000173] [G loss: 0.015484]\n",
            "[Epoch 179/200] [Batch 43/200] [D loss: 0.000182] [G loss: 0.017491]\n",
            "[Epoch 179/200] [Batch 44/200] [D loss: 0.000185] [G loss: 0.019725]\n",
            "[Epoch 179/200] [Batch 45/200] [D loss: 0.000299] [G loss: 0.019031]\n",
            "[Epoch 179/200] [Batch 46/200] [D loss: 0.000109] [G loss: 0.014669]\n",
            "[Epoch 179/200] [Batch 47/200] [D loss: 0.000176] [G loss: 0.016097]\n",
            "[Epoch 179/200] [Batch 48/200] [D loss: 0.000102] [G loss: 0.015732]\n",
            "[Epoch 179/200] [Batch 49/200] [D loss: 0.000145] [G loss: 0.020373]\n",
            "[Epoch 179/200] [Batch 50/200] [D loss: 0.000131] [G loss: 0.017268]\n",
            "[Epoch 179/200] [Batch 51/200] [D loss: 0.000212] [G loss: 0.023084]\n",
            "[Epoch 179/200] [Batch 52/200] [D loss: 0.000116] [G loss: 0.019434]\n",
            "[Epoch 179/200] [Batch 53/200] [D loss: 0.000244] [G loss: 0.019682]\n",
            "[Epoch 179/200] [Batch 54/200] [D loss: 0.000295] [G loss: 0.016519]\n",
            "[Epoch 179/200] [Batch 55/200] [D loss: 0.000110] [G loss: 0.018387]\n",
            "[Epoch 179/200] [Batch 56/200] [D loss: 0.000109] [G loss: 0.013563]\n",
            "[Epoch 179/200] [Batch 57/200] [D loss: 0.000123] [G loss: 0.018208]\n",
            "[Epoch 179/200] [Batch 58/200] [D loss: 0.000109] [G loss: 0.019169]\n",
            "[Epoch 179/200] [Batch 59/200] [D loss: 0.000070] [G loss: 0.015829]\n",
            "[Epoch 179/200] [Batch 60/200] [D loss: 0.000119] [G loss: 0.020538]\n",
            "[Epoch 179/200] [Batch 61/200] [D loss: 0.000185] [G loss: 0.017795]\n",
            "[Epoch 179/200] [Batch 62/200] [D loss: 0.000220] [G loss: 0.016378]\n",
            "[Epoch 179/200] [Batch 63/200] [D loss: 0.000238] [G loss: 0.021640]\n",
            "[Epoch 179/200] [Batch 64/200] [D loss: 0.000165] [G loss: 0.019602]\n",
            "[Epoch 179/200] [Batch 65/200] [D loss: 0.000129] [G loss: 0.019666]\n",
            "[Epoch 179/200] [Batch 66/200] [D loss: 0.000074] [G loss: 0.017766]\n",
            "[Epoch 179/200] [Batch 67/200] [D loss: 0.000118] [G loss: 0.019720]\n",
            "[Epoch 179/200] [Batch 68/200] [D loss: 0.000073] [G loss: 0.020478]\n",
            "[Epoch 179/200] [Batch 69/200] [D loss: 0.000076] [G loss: 0.016126]\n",
            "[Epoch 179/200] [Batch 70/200] [D loss: 0.000093] [G loss: 0.012782]\n",
            "[Epoch 179/200] [Batch 71/200] [D loss: 0.000126] [G loss: 0.021325]\n",
            "[Epoch 179/200] [Batch 72/200] [D loss: 0.000062] [G loss: 0.013367]\n",
            "[Epoch 179/200] [Batch 73/200] [D loss: 0.000085] [G loss: 0.015721]\n",
            "[Epoch 179/200] [Batch 74/200] [D loss: 0.000078] [G loss: 0.017706]\n",
            "[Epoch 179/200] [Batch 75/200] [D loss: 0.000091] [G loss: 0.017414]\n",
            "[Epoch 179/200] [Batch 76/200] [D loss: 0.000067] [G loss: 0.017190]\n",
            "[Epoch 179/200] [Batch 77/200] [D loss: 0.000118] [G loss: 0.017198]\n",
            "[Epoch 179/200] [Batch 78/200] [D loss: 0.000104] [G loss: 0.016306]\n",
            "[Epoch 179/200] [Batch 79/200] [D loss: 0.000072] [G loss: 0.019344]\n",
            "[Epoch 179/200] [Batch 80/200] [D loss: 0.000078] [G loss: 0.016258]\n",
            "[Epoch 179/200] [Batch 81/200] [D loss: 0.000077] [G loss: 0.019815]\n",
            "[Epoch 179/200] [Batch 82/200] [D loss: 0.000090] [G loss: 0.013292]\n",
            "[Epoch 179/200] [Batch 83/200] [D loss: 0.000060] [G loss: 0.018680]\n",
            "[Epoch 179/200] [Batch 84/200] [D loss: 0.000076] [G loss: 0.015421]\n",
            "[Epoch 179/200] [Batch 85/200] [D loss: 0.000107] [G loss: 0.014122]\n",
            "[Epoch 179/200] [Batch 86/200] [D loss: 0.000223] [G loss: 0.019846]\n",
            "[Epoch 179/200] [Batch 87/200] [D loss: 0.000156] [G loss: 0.018843]\n",
            "[Epoch 179/200] [Batch 88/200] [D loss: 0.000086] [G loss: 0.016321]\n",
            "[Epoch 179/200] [Batch 89/200] [D loss: 0.000069] [G loss: 0.016916]\n",
            "[Epoch 179/200] [Batch 90/200] [D loss: 0.000036] [G loss: 0.017539]\n",
            "[Epoch 179/200] [Batch 91/200] [D loss: 0.000066] [G loss: 0.015946]\n",
            "[Epoch 179/200] [Batch 92/200] [D loss: 0.000112] [G loss: 0.016103]\n",
            "[Epoch 179/200] [Batch 93/200] [D loss: 0.000072] [G loss: 0.018166]\n",
            "[Epoch 179/200] [Batch 94/200] [D loss: 0.000092] [G loss: 0.017726]\n",
            "[Epoch 179/200] [Batch 95/200] [D loss: 0.000182] [G loss: 0.014493]\n",
            "[Epoch 179/200] [Batch 96/200] [D loss: 0.000090] [G loss: 0.018681]\n",
            "[Epoch 179/200] [Batch 97/200] [D loss: 0.000153] [G loss: 0.019578]\n",
            "[Epoch 179/200] [Batch 98/200] [D loss: 0.000115] [G loss: 0.015326]\n",
            "[Epoch 179/200] [Batch 99/200] [D loss: 0.000175] [G loss: 0.019584]\n",
            "[Epoch 179/200] [Batch 100/200] [D loss: 0.000545] [G loss: 0.016486]\n",
            "[Epoch 179/200] [Batch 101/200] [D loss: 0.000716] [G loss: 0.019038]\n",
            "[Epoch 179/200] [Batch 102/200] [D loss: 0.000140] [G loss: 0.024493]\n",
            "[Epoch 179/200] [Batch 103/200] [D loss: 0.000103] [G loss: 0.019064]\n",
            "[Epoch 179/200] [Batch 104/200] [D loss: 0.000079] [G loss: 0.018433]\n",
            "[Epoch 179/200] [Batch 105/200] [D loss: 0.000112] [G loss: 0.017138]\n",
            "[Epoch 179/200] [Batch 106/200] [D loss: 0.000084] [G loss: 0.016804]\n",
            "[Epoch 179/200] [Batch 107/200] [D loss: 0.000161] [G loss: 0.019304]\n",
            "[Epoch 179/200] [Batch 108/200] [D loss: 0.000121] [G loss: 0.019067]\n",
            "[Epoch 179/200] [Batch 109/200] [D loss: 0.000088] [G loss: 0.016519]\n",
            "[Epoch 179/200] [Batch 110/200] [D loss: 0.000082] [G loss: 0.017600]\n",
            "[Epoch 179/200] [Batch 111/200] [D loss: 0.000158] [G loss: 0.017222]\n",
            "[Epoch 179/200] [Batch 112/200] [D loss: 0.000205] [G loss: 0.013423]\n",
            "[Epoch 179/200] [Batch 113/200] [D loss: 0.000113] [G loss: 0.017006]\n",
            "[Epoch 179/200] [Batch 114/200] [D loss: 0.000192] [G loss: 0.017289]\n",
            "[Epoch 179/200] [Batch 115/200] [D loss: 0.000344] [G loss: 0.016090]\n",
            "[Epoch 179/200] [Batch 116/200] [D loss: 0.000228] [G loss: 0.015586]\n",
            "[Epoch 179/200] [Batch 117/200] [D loss: 0.000419] [G loss: 0.015166]\n",
            "[Epoch 179/200] [Batch 118/200] [D loss: 0.000265] [G loss: 0.019901]\n",
            "[Epoch 179/200] [Batch 119/200] [D loss: 0.000304] [G loss: 0.019011]\n",
            "[Epoch 179/200] [Batch 120/200] [D loss: 0.000459] [G loss: 0.016126]\n",
            "[Epoch 179/200] [Batch 121/200] [D loss: 0.000215] [G loss: 0.017388]\n",
            "[Epoch 179/200] [Batch 122/200] [D loss: 0.000207] [G loss: 0.018071]\n",
            "[Epoch 179/200] [Batch 123/200] [D loss: 0.000147] [G loss: 0.016390]\n",
            "[Epoch 179/200] [Batch 124/200] [D loss: 0.000092] [G loss: 0.019044]\n",
            "[Epoch 179/200] [Batch 125/200] [D loss: 0.000086] [G loss: 0.022399]\n",
            "[Epoch 179/200] [Batch 126/200] [D loss: 0.000107] [G loss: 0.015944]\n",
            "[Epoch 179/200] [Batch 127/200] [D loss: 0.000105] [G loss: 0.016694]\n",
            "[Epoch 179/200] [Batch 128/200] [D loss: 0.000244] [G loss: 0.021549]\n",
            "[Epoch 179/200] [Batch 129/200] [D loss: 0.000169] [G loss: 0.018931]\n",
            "[Epoch 179/200] [Batch 130/200] [D loss: 0.000135] [G loss: 0.019447]\n",
            "[Epoch 179/200] [Batch 131/200] [D loss: 0.000147] [G loss: 0.015581]\n",
            "[Epoch 179/200] [Batch 132/200] [D loss: 0.000100] [G loss: 0.019890]\n",
            "[Epoch 179/200] [Batch 133/200] [D loss: 0.000105] [G loss: 0.023758]\n",
            "[Epoch 179/200] [Batch 134/200] [D loss: 0.000113] [G loss: 0.017712]\n",
            "[Epoch 179/200] [Batch 135/200] [D loss: 0.000082] [G loss: 0.016294]\n",
            "[Epoch 179/200] [Batch 136/200] [D loss: 0.000103] [G loss: 0.019190]\n",
            "[Epoch 179/200] [Batch 137/200] [D loss: 0.000060] [G loss: 0.015284]\n",
            "[Epoch 179/200] [Batch 138/200] [D loss: 0.000163] [G loss: 0.019060]\n",
            "[Epoch 179/200] [Batch 139/200] [D loss: 0.000086] [G loss: 0.017657]\n",
            "[Epoch 179/200] [Batch 140/200] [D loss: 0.000096] [G loss: 0.019960]\n",
            "[Epoch 179/200] [Batch 141/200] [D loss: 0.000089] [G loss: 0.016991]\n",
            "[Epoch 179/200] [Batch 142/200] [D loss: 0.000110] [G loss: 0.017922]\n",
            "[Epoch 179/200] [Batch 143/200] [D loss: 0.000122] [G loss: 0.015607]\n",
            "[Epoch 179/200] [Batch 144/200] [D loss: 0.000071] [G loss: 0.019185]\n",
            "[Epoch 179/200] [Batch 145/200] [D loss: 0.000046] [G loss: 0.018017]\n",
            "[Epoch 179/200] [Batch 146/200] [D loss: 0.000051] [G loss: 0.015731]\n",
            "[Epoch 179/200] [Batch 147/200] [D loss: 0.000043] [G loss: 0.018407]\n",
            "[Epoch 179/200] [Batch 148/200] [D loss: 0.000073] [G loss: 0.018355]\n",
            "[Epoch 179/200] [Batch 149/200] [D loss: 0.000083] [G loss: 0.016545]\n",
            "[Epoch 179/200] [Batch 150/200] [D loss: 0.000292] [G loss: 0.015444]\n",
            "[Epoch 179/200] [Batch 151/200] [D loss: 0.000446] [G loss: 0.016348]\n",
            "[Epoch 179/200] [Batch 152/200] [D loss: 0.000282] [G loss: 0.019651]\n",
            "[Epoch 179/200] [Batch 153/200] [D loss: 0.000119] [G loss: 0.015788]\n",
            "[Epoch 179/200] [Batch 154/200] [D loss: 0.000271] [G loss: 0.020848]\n",
            "[Epoch 179/200] [Batch 155/200] [D loss: 0.000139] [G loss: 0.018646]\n",
            "[Epoch 179/200] [Batch 156/200] [D loss: 0.000140] [G loss: 0.016317]\n",
            "[Epoch 179/200] [Batch 157/200] [D loss: 0.000162] [G loss: 0.019399]\n",
            "[Epoch 179/200] [Batch 158/200] [D loss: 0.000111] [G loss: 0.013667]\n",
            "[Epoch 179/200] [Batch 159/200] [D loss: 0.000170] [G loss: 0.019864]\n",
            "[Epoch 179/200] [Batch 160/200] [D loss: 0.000250] [G loss: 0.020439]\n",
            "[Epoch 179/200] [Batch 161/200] [D loss: 0.000113] [G loss: 0.015819]\n",
            "[Epoch 179/200] [Batch 162/200] [D loss: 0.000111] [G loss: 0.012638]\n",
            "[Epoch 179/200] [Batch 163/200] [D loss: 0.000130] [G loss: 0.018114]\n",
            "[Epoch 179/200] [Batch 164/200] [D loss: 0.000191] [G loss: 0.018864]\n",
            "[Epoch 179/200] [Batch 165/200] [D loss: 0.000282] [G loss: 0.020830]\n",
            "[Epoch 179/200] [Batch 166/200] [D loss: 0.000227] [G loss: 0.014416]\n",
            "[Epoch 179/200] [Batch 167/200] [D loss: 0.000163] [G loss: 0.018706]\n",
            "[Epoch 179/200] [Batch 168/200] [D loss: 0.000118] [G loss: 0.019101]\n",
            "[Epoch 179/200] [Batch 169/200] [D loss: 0.000342] [G loss: 0.015083]\n",
            "[Epoch 179/200] [Batch 170/200] [D loss: 0.000937] [G loss: 0.018533]\n",
            "[Epoch 179/200] [Batch 171/200] [D loss: 0.000799] [G loss: 0.016631]\n",
            "[Epoch 179/200] [Batch 172/200] [D loss: 0.000233] [G loss: 0.016198]\n",
            "[Epoch 179/200] [Batch 173/200] [D loss: 0.000853] [G loss: 0.020146]\n",
            "[Epoch 179/200] [Batch 174/200] [D loss: 0.000759] [G loss: 0.014291]\n",
            "[Epoch 179/200] [Batch 175/200] [D loss: 0.000405] [G loss: 0.017946]\n",
            "[Epoch 179/200] [Batch 176/200] [D loss: 0.000174] [G loss: 0.016155]\n",
            "[Epoch 179/200] [Batch 177/200] [D loss: 0.000165] [G loss: 0.018430]\n",
            "[Epoch 179/200] [Batch 178/200] [D loss: 0.000292] [G loss: 0.018437]\n",
            "[Epoch 179/200] [Batch 179/200] [D loss: 0.000148] [G loss: 0.016177]\n",
            "[Epoch 179/200] [Batch 180/200] [D loss: 0.000138] [G loss: 0.021274]\n",
            "[Epoch 179/200] [Batch 181/200] [D loss: 0.000268] [G loss: 0.015679]\n",
            "[Epoch 179/200] [Batch 182/200] [D loss: 0.000151] [G loss: 0.016980]\n",
            "[Epoch 179/200] [Batch 183/200] [D loss: 0.000197] [G loss: 0.016566]\n",
            "[Epoch 179/200] [Batch 184/200] [D loss: 0.000165] [G loss: 0.020189]\n",
            "[Epoch 179/200] [Batch 185/200] [D loss: 0.000122] [G loss: 0.014839]\n",
            "[Epoch 179/200] [Batch 186/200] [D loss: 0.000116] [G loss: 0.018657]\n",
            "[Epoch 179/200] [Batch 187/200] [D loss: 0.000131] [G loss: 0.018224]\n",
            "[Epoch 179/200] [Batch 188/200] [D loss: 0.000100] [G loss: 0.021323]\n",
            "[Epoch 179/200] [Batch 189/200] [D loss: 0.000042] [G loss: 0.017969]\n",
            "[Epoch 179/200] [Batch 190/200] [D loss: 0.000155] [G loss: 0.021025]\n",
            "[Epoch 179/200] [Batch 191/200] [D loss: 0.000133] [G loss: 0.016406]\n",
            "[Epoch 179/200] [Batch 192/200] [D loss: 0.000068] [G loss: 0.014585]\n",
            "[Epoch 179/200] [Batch 193/200] [D loss: 0.000086] [G loss: 0.017467]\n",
            "[Epoch 179/200] [Batch 194/200] [D loss: 0.000105] [G loss: 0.015992]\n",
            "[Epoch 179/200] [Batch 195/200] [D loss: 0.000080] [G loss: 0.012328]\n",
            "[Epoch 179/200] [Batch 196/200] [D loss: 0.000080] [G loss: 0.015117]\n",
            "[Epoch 179/200] [Batch 197/200] [D loss: 0.000149] [G loss: 0.014097]\n",
            "[Epoch 179/200] [Batch 198/200] [D loss: 0.000205] [G loss: 0.017914]\n",
            "[Epoch 179/200] [Batch 199/200] [D loss: 0.000125] [G loss: 0.012709]\n",
            "[Epoch 180/200] [Batch 0/200] [D loss: 0.000097] [G loss: 0.015377]\n",
            "[Epoch 180/200] [Batch 1/200] [D loss: 0.000058] [G loss: 0.016544]\n",
            "[Epoch 180/200] [Batch 2/200] [D loss: 0.000135] [G loss: 0.019100]\n",
            "[Epoch 180/200] [Batch 3/200] [D loss: 0.000188] [G loss: 0.020344]\n",
            "[Epoch 180/200] [Batch 4/200] [D loss: 0.000124] [G loss: 0.019324]\n",
            "[Epoch 180/200] [Batch 5/200] [D loss: 0.000163] [G loss: 0.017600]\n",
            "[Epoch 180/200] [Batch 6/200] [D loss: 0.000149] [G loss: 0.016262]\n",
            "[Epoch 180/200] [Batch 7/200] [D loss: 0.000434] [G loss: 0.019431]\n",
            "[Epoch 180/200] [Batch 8/200] [D loss: 0.000785] [G loss: 0.019629]\n",
            "[Epoch 180/200] [Batch 9/200] [D loss: 0.000733] [G loss: 0.013382]\n",
            "[Epoch 180/200] [Batch 10/200] [D loss: 0.000346] [G loss: 0.022156]\n",
            "[Epoch 180/200] [Batch 11/200] [D loss: 0.000198] [G loss: 0.017170]\n",
            "[Epoch 180/200] [Batch 12/200] [D loss: 0.000567] [G loss: 0.014440]\n",
            "[Epoch 180/200] [Batch 13/200] [D loss: 0.000647] [G loss: 0.017172]\n",
            "[Epoch 180/200] [Batch 14/200] [D loss: 0.000171] [G loss: 0.016953]\n",
            "[Epoch 180/200] [Batch 15/200] [D loss: 0.000157] [G loss: 0.015881]\n",
            "[Epoch 180/200] [Batch 16/200] [D loss: 0.000253] [G loss: 0.015256]\n",
            "[Epoch 180/200] [Batch 17/200] [D loss: 0.000433] [G loss: 0.017332]\n",
            "[Epoch 180/200] [Batch 18/200] [D loss: 0.000297] [G loss: 0.021401]\n",
            "[Epoch 180/200] [Batch 19/200] [D loss: 0.000213] [G loss: 0.016442]\n",
            "[Epoch 180/200] [Batch 20/200] [D loss: 0.000184] [G loss: 0.019124]\n",
            "[Epoch 180/200] [Batch 21/200] [D loss: 0.000272] [G loss: 0.015841]\n",
            "[Epoch 180/200] [Batch 22/200] [D loss: 0.000109] [G loss: 0.020262]\n",
            "[Epoch 180/200] [Batch 23/200] [D loss: 0.000203] [G loss: 0.014469]\n",
            "[Epoch 180/200] [Batch 24/200] [D loss: 0.000152] [G loss: 0.019478]\n",
            "[Epoch 180/200] [Batch 25/200] [D loss: 0.000128] [G loss: 0.022334]\n",
            "[Epoch 180/200] [Batch 26/200] [D loss: 0.000141] [G loss: 0.016887]\n",
            "[Epoch 180/200] [Batch 27/200] [D loss: 0.000075] [G loss: 0.017579]\n",
            "[Epoch 180/200] [Batch 28/200] [D loss: 0.000107] [G loss: 0.015482]\n",
            "[Epoch 180/200] [Batch 29/200] [D loss: 0.000141] [G loss: 0.019916]\n",
            "[Epoch 180/200] [Batch 30/200] [D loss: 0.000200] [G loss: 0.017149]\n",
            "[Epoch 180/200] [Batch 31/200] [D loss: 0.000175] [G loss: 0.018152]\n",
            "[Epoch 180/200] [Batch 32/200] [D loss: 0.000084] [G loss: 0.023000]\n",
            "[Epoch 180/200] [Batch 33/200] [D loss: 0.000141] [G loss: 0.012912]\n",
            "[Epoch 180/200] [Batch 34/200] [D loss: 0.000132] [G loss: 0.016122]\n",
            "[Epoch 180/200] [Batch 35/200] [D loss: 0.000176] [G loss: 0.023291]\n",
            "[Epoch 180/200] [Batch 36/200] [D loss: 0.000082] [G loss: 0.016101]\n",
            "[Epoch 180/200] [Batch 37/200] [D loss: 0.000079] [G loss: 0.017333]\n",
            "[Epoch 180/200] [Batch 38/200] [D loss: 0.000063] [G loss: 0.016434]\n",
            "[Epoch 180/200] [Batch 39/200] [D loss: 0.000051] [G loss: 0.017148]\n",
            "[Epoch 180/200] [Batch 40/200] [D loss: 0.000063] [G loss: 0.014367]\n",
            "[Epoch 180/200] [Batch 41/200] [D loss: 0.000315] [G loss: 0.018337]\n",
            "[Epoch 180/200] [Batch 42/200] [D loss: 0.000410] [G loss: 0.016555]\n",
            "[Epoch 180/200] [Batch 43/200] [D loss: 0.000160] [G loss: 0.017493]\n",
            "[Epoch 180/200] [Batch 44/200] [D loss: 0.000240] [G loss: 0.018028]\n",
            "[Epoch 180/200] [Batch 45/200] [D loss: 0.000415] [G loss: 0.016471]\n",
            "[Epoch 180/200] [Batch 46/200] [D loss: 0.000574] [G loss: 0.017436]\n",
            "[Epoch 180/200] [Batch 47/200] [D loss: 0.000410] [G loss: 0.017563]\n",
            "[Epoch 180/200] [Batch 48/200] [D loss: 0.000129] [G loss: 0.013752]\n",
            "[Epoch 180/200] [Batch 49/200] [D loss: 0.000240] [G loss: 0.021002]\n",
            "[Epoch 180/200] [Batch 50/200] [D loss: 0.000157] [G loss: 0.017502]\n",
            "[Epoch 180/200] [Batch 51/200] [D loss: 0.000073] [G loss: 0.017602]\n",
            "[Epoch 180/200] [Batch 52/200] [D loss: 0.000120] [G loss: 0.017831]\n",
            "[Epoch 180/200] [Batch 53/200] [D loss: 0.000197] [G loss: 0.018644]\n",
            "[Epoch 180/200] [Batch 54/200] [D loss: 0.000173] [G loss: 0.017461]\n",
            "[Epoch 180/200] [Batch 55/200] [D loss: 0.000150] [G loss: 0.019077]\n",
            "[Epoch 180/200] [Batch 56/200] [D loss: 0.000081] [G loss: 0.017375]\n",
            "[Epoch 180/200] [Batch 57/200] [D loss: 0.000068] [G loss: 0.019458]\n",
            "[Epoch 180/200] [Batch 58/200] [D loss: 0.000066] [G loss: 0.018607]\n",
            "[Epoch 180/200] [Batch 59/200] [D loss: 0.000054] [G loss: 0.014902]\n",
            "[Epoch 180/200] [Batch 60/200] [D loss: 0.000066] [G loss: 0.021348]\n",
            "[Epoch 180/200] [Batch 61/200] [D loss: 0.000057] [G loss: 0.016511]\n",
            "[Epoch 180/200] [Batch 62/200] [D loss: 0.000050] [G loss: 0.020758]\n",
            "[Epoch 180/200] [Batch 63/200] [D loss: 0.000124] [G loss: 0.025687]\n",
            "[Epoch 180/200] [Batch 64/200] [D loss: 0.000208] [G loss: 0.017123]\n",
            "[Epoch 180/200] [Batch 65/200] [D loss: 0.000196] [G loss: 0.013744]\n",
            "[Epoch 180/200] [Batch 66/200] [D loss: 0.000089] [G loss: 0.014562]\n",
            "[Epoch 180/200] [Batch 67/200] [D loss: 0.000194] [G loss: 0.018398]\n",
            "[Epoch 180/200] [Batch 68/200] [D loss: 0.000120] [G loss: 0.014000]\n",
            "[Epoch 180/200] [Batch 69/200] [D loss: 0.000123] [G loss: 0.018480]\n",
            "[Epoch 180/200] [Batch 70/200] [D loss: 0.000077] [G loss: 0.021691]\n",
            "[Epoch 180/200] [Batch 71/200] [D loss: 0.000092] [G loss: 0.015797]\n",
            "[Epoch 180/200] [Batch 72/200] [D loss: 0.000094] [G loss: 0.015938]\n",
            "[Epoch 180/200] [Batch 73/200] [D loss: 0.000128] [G loss: 0.018181]\n",
            "[Epoch 180/200] [Batch 74/200] [D loss: 0.000076] [G loss: 0.019727]\n",
            "[Epoch 180/200] [Batch 75/200] [D loss: 0.000093] [G loss: 0.020404]\n",
            "[Epoch 180/200] [Batch 76/200] [D loss: 0.000081] [G loss: 0.017447]\n",
            "[Epoch 180/200] [Batch 77/200] [D loss: 0.000068] [G loss: 0.014214]\n",
            "[Epoch 180/200] [Batch 78/200] [D loss: 0.000083] [G loss: 0.015287]\n",
            "[Epoch 180/200] [Batch 79/200] [D loss: 0.000191] [G loss: 0.017085]\n",
            "[Epoch 180/200] [Batch 80/200] [D loss: 0.000208] [G loss: 0.015744]\n",
            "[Epoch 180/200] [Batch 81/200] [D loss: 0.000111] [G loss: 0.016558]\n",
            "[Epoch 180/200] [Batch 82/200] [D loss: 0.000085] [G loss: 0.014427]\n",
            "[Epoch 180/200] [Batch 83/200] [D loss: 0.000083] [G loss: 0.015199]\n",
            "[Epoch 180/200] [Batch 84/200] [D loss: 0.000135] [G loss: 0.017899]\n",
            "[Epoch 180/200] [Batch 85/200] [D loss: 0.000093] [G loss: 0.016722]\n",
            "[Epoch 180/200] [Batch 86/200] [D loss: 0.000102] [G loss: 0.017724]\n",
            "[Epoch 180/200] [Batch 87/200] [D loss: 0.000098] [G loss: 0.016386]\n",
            "[Epoch 180/200] [Batch 88/200] [D loss: 0.000142] [G loss: 0.018111]\n",
            "[Epoch 180/200] [Batch 89/200] [D loss: 0.000149] [G loss: 0.020371]\n",
            "[Epoch 180/200] [Batch 90/200] [D loss: 0.000174] [G loss: 0.019484]\n",
            "[Epoch 180/200] [Batch 91/200] [D loss: 0.000227] [G loss: 0.018641]\n",
            "[Epoch 180/200] [Batch 92/200] [D loss: 0.000096] [G loss: 0.021073]\n",
            "[Epoch 180/200] [Batch 93/200] [D loss: 0.000096] [G loss: 0.016879]\n",
            "[Epoch 180/200] [Batch 94/200] [D loss: 0.000108] [G loss: 0.016031]\n",
            "[Epoch 180/200] [Batch 95/200] [D loss: 0.000264] [G loss: 0.020558]\n",
            "[Epoch 180/200] [Batch 96/200] [D loss: 0.000307] [G loss: 0.018579]\n",
            "[Epoch 180/200] [Batch 97/200] [D loss: 0.000178] [G loss: 0.017716]\n",
            "[Epoch 180/200] [Batch 98/200] [D loss: 0.000205] [G loss: 0.016428]\n",
            "[Epoch 180/200] [Batch 99/200] [D loss: 0.000303] [G loss: 0.015630]\n",
            "[Epoch 180/200] [Batch 100/200] [D loss: 0.000115] [G loss: 0.017404]\n",
            "[Epoch 180/200] [Batch 101/200] [D loss: 0.000112] [G loss: 0.015648]\n",
            "[Epoch 180/200] [Batch 102/200] [D loss: 0.000091] [G loss: 0.015349]\n",
            "[Epoch 180/200] [Batch 103/200] [D loss: 0.000043] [G loss: 0.017507]\n",
            "[Epoch 180/200] [Batch 104/200] [D loss: 0.000213] [G loss: 0.014926]\n",
            "[Epoch 180/200] [Batch 105/200] [D loss: 0.000363] [G loss: 0.018724]\n",
            "[Epoch 180/200] [Batch 106/200] [D loss: 0.000194] [G loss: 0.015320]\n",
            "[Epoch 180/200] [Batch 107/200] [D loss: 0.000226] [G loss: 0.019047]\n",
            "[Epoch 180/200] [Batch 108/200] [D loss: 0.000304] [G loss: 0.018004]\n",
            "[Epoch 180/200] [Batch 109/200] [D loss: 0.000291] [G loss: 0.017222]\n",
            "[Epoch 180/200] [Batch 110/200] [D loss: 0.000269] [G loss: 0.015996]\n",
            "[Epoch 180/200] [Batch 111/200] [D loss: 0.000245] [G loss: 0.016567]\n",
            "[Epoch 180/200] [Batch 112/200] [D loss: 0.000124] [G loss: 0.016427]\n",
            "[Epoch 180/200] [Batch 113/200] [D loss: 0.000147] [G loss: 0.019856]\n",
            "[Epoch 180/200] [Batch 114/200] [D loss: 0.000168] [G loss: 0.015306]\n",
            "[Epoch 180/200] [Batch 115/200] [D loss: 0.000160] [G loss: 0.019269]\n",
            "[Epoch 180/200] [Batch 116/200] [D loss: 0.000377] [G loss: 0.016227]\n",
            "[Epoch 180/200] [Batch 117/200] [D loss: 0.000503] [G loss: 0.021072]\n",
            "[Epoch 180/200] [Batch 118/200] [D loss: 0.000297] [G loss: 0.017731]\n",
            "[Epoch 180/200] [Batch 119/200] [D loss: 0.000163] [G loss: 0.019559]\n",
            "[Epoch 180/200] [Batch 120/200] [D loss: 0.000088] [G loss: 0.018727]\n",
            "[Epoch 180/200] [Batch 121/200] [D loss: 0.000207] [G loss: 0.020184]\n",
            "[Epoch 180/200] [Batch 122/200] [D loss: 0.000076] [G loss: 0.019538]\n",
            "[Epoch 180/200] [Batch 123/200] [D loss: 0.000267] [G loss: 0.016613]\n",
            "[Epoch 180/200] [Batch 124/200] [D loss: 0.000246] [G loss: 0.017174]\n",
            "[Epoch 180/200] [Batch 125/200] [D loss: 0.000180] [G loss: 0.016968]\n",
            "[Epoch 180/200] [Batch 126/200] [D loss: 0.000112] [G loss: 0.016772]\n",
            "[Epoch 180/200] [Batch 127/200] [D loss: 0.000074] [G loss: 0.019358]\n",
            "[Epoch 180/200] [Batch 128/200] [D loss: 0.000096] [G loss: 0.014206]\n",
            "[Epoch 180/200] [Batch 129/200] [D loss: 0.000230] [G loss: 0.016716]\n",
            "[Epoch 180/200] [Batch 130/200] [D loss: 0.000264] [G loss: 0.016413]\n",
            "[Epoch 180/200] [Batch 131/200] [D loss: 0.000121] [G loss: 0.018181]\n",
            "[Epoch 180/200] [Batch 132/200] [D loss: 0.000085] [G loss: 0.018955]\n",
            "[Epoch 180/200] [Batch 133/200] [D loss: 0.000194] [G loss: 0.011477]\n",
            "[Epoch 180/200] [Batch 134/200] [D loss: 0.000328] [G loss: 0.018202]\n",
            "[Epoch 180/200] [Batch 135/200] [D loss: 0.000172] [G loss: 0.018380]\n",
            "[Epoch 180/200] [Batch 136/200] [D loss: 0.000079] [G loss: 0.012827]\n",
            "[Epoch 180/200] [Batch 137/200] [D loss: 0.000131] [G loss: 0.017576]\n",
            "[Epoch 180/200] [Batch 138/200] [D loss: 0.000115] [G loss: 0.019413]\n",
            "[Epoch 180/200] [Batch 139/200] [D loss: 0.000130] [G loss: 0.014631]\n",
            "[Epoch 180/200] [Batch 140/200] [D loss: 0.000109] [G loss: 0.020130]\n",
            "[Epoch 180/200] [Batch 141/200] [D loss: 0.000052] [G loss: 0.018656]\n",
            "[Epoch 180/200] [Batch 142/200] [D loss: 0.000074] [G loss: 0.015994]\n",
            "[Epoch 180/200] [Batch 143/200] [D loss: 0.000052] [G loss: 0.022229]\n",
            "[Epoch 180/200] [Batch 144/200] [D loss: 0.000052] [G loss: 0.016515]\n",
            "[Epoch 180/200] [Batch 145/200] [D loss: 0.000059] [G loss: 0.019245]\n",
            "[Epoch 180/200] [Batch 146/200] [D loss: 0.000072] [G loss: 0.013931]\n",
            "[Epoch 180/200] [Batch 147/200] [D loss: 0.000083] [G loss: 0.017754]\n",
            "[Epoch 180/200] [Batch 148/200] [D loss: 0.000056] [G loss: 0.017566]\n",
            "[Epoch 180/200] [Batch 149/200] [D loss: 0.000131] [G loss: 0.018755]\n",
            "[Epoch 180/200] [Batch 150/200] [D loss: 0.000091] [G loss: 0.019748]\n",
            "[Epoch 180/200] [Batch 151/200] [D loss: 0.000125] [G loss: 0.018177]\n",
            "[Epoch 180/200] [Batch 152/200] [D loss: 0.000133] [G loss: 0.017415]\n",
            "[Epoch 180/200] [Batch 153/200] [D loss: 0.000073] [G loss: 0.015217]\n",
            "[Epoch 180/200] [Batch 154/200] [D loss: 0.000152] [G loss: 0.020707]\n",
            "[Epoch 180/200] [Batch 155/200] [D loss: 0.000270] [G loss: 0.018345]\n",
            "[Epoch 180/200] [Batch 156/200] [D loss: 0.000211] [G loss: 0.019435]\n",
            "[Epoch 180/200] [Batch 157/200] [D loss: 0.000117] [G loss: 0.019456]\n",
            "[Epoch 180/200] [Batch 158/200] [D loss: 0.000075] [G loss: 0.014099]\n",
            "[Epoch 180/200] [Batch 159/200] [D loss: 0.000161] [G loss: 0.018603]\n",
            "[Epoch 180/200] [Batch 160/200] [D loss: 0.000214] [G loss: 0.018636]\n",
            "[Epoch 180/200] [Batch 161/200] [D loss: 0.000191] [G loss: 0.016577]\n",
            "[Epoch 180/200] [Batch 162/200] [D loss: 0.000120] [G loss: 0.019012]\n",
            "[Epoch 180/200] [Batch 163/200] [D loss: 0.000086] [G loss: 0.015767]\n",
            "[Epoch 180/200] [Batch 164/200] [D loss: 0.000125] [G loss: 0.021208]\n",
            "[Epoch 180/200] [Batch 165/200] [D loss: 0.000215] [G loss: 0.017072]\n",
            "[Epoch 180/200] [Batch 166/200] [D loss: 0.000142] [G loss: 0.020342]\n",
            "[Epoch 180/200] [Batch 167/200] [D loss: 0.000509] [G loss: 0.019243]\n",
            "[Epoch 180/200] [Batch 168/200] [D loss: 0.000472] [G loss: 0.022177]\n",
            "[Epoch 180/200] [Batch 169/200] [D loss: 0.000537] [G loss: 0.018154]\n",
            "[Epoch 180/200] [Batch 170/200] [D loss: 0.000343] [G loss: 0.016021]\n",
            "[Epoch 180/200] [Batch 171/200] [D loss: 0.000130] [G loss: 0.019296]\n",
            "[Epoch 180/200] [Batch 172/200] [D loss: 0.000121] [G loss: 0.018592]\n",
            "[Epoch 180/200] [Batch 173/200] [D loss: 0.000048] [G loss: 0.015125]\n",
            "[Epoch 180/200] [Batch 174/200] [D loss: 0.000058] [G loss: 0.014726]\n",
            "[Epoch 180/200] [Batch 175/200] [D loss: 0.000120] [G loss: 0.021660]\n",
            "[Epoch 180/200] [Batch 176/200] [D loss: 0.000129] [G loss: 0.019614]\n",
            "[Epoch 180/200] [Batch 177/200] [D loss: 0.000109] [G loss: 0.017341]\n",
            "[Epoch 180/200] [Batch 178/200] [D loss: 0.000129] [G loss: 0.015266]\n",
            "[Epoch 180/200] [Batch 179/200] [D loss: 0.000126] [G loss: 0.016733]\n",
            "[Epoch 180/200] [Batch 180/200] [D loss: 0.000073] [G loss: 0.019696]\n",
            "[Epoch 180/200] [Batch 181/200] [D loss: 0.000062] [G loss: 0.013919]\n",
            "[Epoch 180/200] [Batch 182/200] [D loss: 0.000058] [G loss: 0.017416]\n",
            "[Epoch 180/200] [Batch 183/200] [D loss: 0.000099] [G loss: 0.022757]\n",
            "[Epoch 180/200] [Batch 184/200] [D loss: 0.000077] [G loss: 0.015316]\n",
            "[Epoch 180/200] [Batch 185/200] [D loss: 0.000096] [G loss: 0.012872]\n",
            "[Epoch 180/200] [Batch 186/200] [D loss: 0.000104] [G loss: 0.015829]\n",
            "[Epoch 180/200] [Batch 187/200] [D loss: 0.000108] [G loss: 0.019461]\n",
            "[Epoch 180/200] [Batch 188/200] [D loss: 0.000167] [G loss: 0.018717]\n",
            "[Epoch 180/200] [Batch 189/200] [D loss: 0.000520] [G loss: 0.018986]\n",
            "[Epoch 180/200] [Batch 190/200] [D loss: 0.000247] [G loss: 0.016637]\n",
            "[Epoch 180/200] [Batch 191/200] [D loss: 0.000354] [G loss: 0.015819]\n",
            "[Epoch 180/200] [Batch 192/200] [D loss: 0.000333] [G loss: 0.020502]\n",
            "[Epoch 180/200] [Batch 193/200] [D loss: 0.000139] [G loss: 0.018984]\n",
            "[Epoch 180/200] [Batch 194/200] [D loss: 0.000161] [G loss: 0.016883]\n",
            "[Epoch 180/200] [Batch 195/200] [D loss: 0.000178] [G loss: 0.018008]\n",
            "[Epoch 180/200] [Batch 196/200] [D loss: 0.000111] [G loss: 0.020280]\n",
            "[Epoch 180/200] [Batch 197/200] [D loss: 0.000136] [G loss: 0.019075]\n",
            "[Epoch 180/200] [Batch 198/200] [D loss: 0.000153] [G loss: 0.017700]\n",
            "[Epoch 180/200] [Batch 199/200] [D loss: 0.000100] [G loss: 0.014878]\n",
            "[Epoch 181/200] [Batch 0/200] [D loss: 0.000187] [G loss: 0.018075]\n",
            "[Epoch 181/200] [Batch 1/200] [D loss: 0.000202] [G loss: 0.020192]\n",
            "[Epoch 181/200] [Batch 2/200] [D loss: 0.000221] [G loss: 0.018599]\n",
            "[Epoch 181/200] [Batch 3/200] [D loss: 0.000272] [G loss: 0.018554]\n",
            "[Epoch 181/200] [Batch 4/200] [D loss: 0.000154] [G loss: 0.015914]\n",
            "[Epoch 181/200] [Batch 5/200] [D loss: 0.000089] [G loss: 0.016790]\n",
            "[Epoch 181/200] [Batch 6/200] [D loss: 0.000092] [G loss: 0.017623]\n",
            "[Epoch 181/200] [Batch 7/200] [D loss: 0.000117] [G loss: 0.016653]\n",
            "[Epoch 181/200] [Batch 8/200] [D loss: 0.000160] [G loss: 0.013821]\n",
            "[Epoch 181/200] [Batch 9/200] [D loss: 0.000096] [G loss: 0.019655]\n",
            "[Epoch 181/200] [Batch 10/200] [D loss: 0.000160] [G loss: 0.016831]\n",
            "[Epoch 181/200] [Batch 11/200] [D loss: 0.000249] [G loss: 0.016877]\n",
            "[Epoch 181/200] [Batch 12/200] [D loss: 0.000104] [G loss: 0.016465]\n",
            "[Epoch 181/200] [Batch 13/200] [D loss: 0.000152] [G loss: 0.016119]\n",
            "[Epoch 181/200] [Batch 14/200] [D loss: 0.000072] [G loss: 0.016886]\n",
            "[Epoch 181/200] [Batch 15/200] [D loss: 0.000088] [G loss: 0.017193]\n",
            "[Epoch 181/200] [Batch 16/200] [D loss: 0.000124] [G loss: 0.017404]\n",
            "[Epoch 181/200] [Batch 17/200] [D loss: 0.000079] [G loss: 0.015390]\n",
            "[Epoch 181/200] [Batch 18/200] [D loss: 0.000093] [G loss: 0.018705]\n",
            "[Epoch 181/200] [Batch 19/200] [D loss: 0.000284] [G loss: 0.019637]\n",
            "[Epoch 181/200] [Batch 20/200] [D loss: 0.000620] [G loss: 0.018563]\n",
            "[Epoch 181/200] [Batch 21/200] [D loss: 0.001191] [G loss: 0.013129]\n",
            "[Epoch 181/200] [Batch 22/200] [D loss: 0.001949] [G loss: 0.019590]\n",
            "[Epoch 181/200] [Batch 23/200] [D loss: 0.006918] [G loss: 0.015284]\n",
            "[Epoch 181/200] [Batch 24/200] [D loss: 0.018527] [G loss: 0.021410]\n",
            "[Epoch 181/200] [Batch 25/200] [D loss: 0.017714] [G loss: 0.016292]\n",
            "[Epoch 181/200] [Batch 26/200] [D loss: 0.007513] [G loss: 0.018051]\n",
            "[Epoch 181/200] [Batch 27/200] [D loss: 0.006019] [G loss: 0.012705]\n",
            "[Epoch 181/200] [Batch 28/200] [D loss: 0.006610] [G loss: 0.018771]\n",
            "[Epoch 181/200] [Batch 29/200] [D loss: 0.003116] [G loss: 0.016996]\n",
            "[Epoch 181/200] [Batch 30/200] [D loss: 0.004874] [G loss: 0.021507]\n",
            "[Epoch 181/200] [Batch 31/200] [D loss: 0.004288] [G loss: 0.019985]\n",
            "[Epoch 181/200] [Batch 32/200] [D loss: 0.001849] [G loss: 0.018013]\n",
            "[Epoch 181/200] [Batch 33/200] [D loss: 0.003339] [G loss: 0.016647]\n",
            "[Epoch 181/200] [Batch 34/200] [D loss: 0.004218] [G loss: 0.012289]\n",
            "[Epoch 181/200] [Batch 35/200] [D loss: 0.002659] [G loss: 0.015550]\n",
            "[Epoch 181/200] [Batch 36/200] [D loss: 0.003217] [G loss: 0.017691]\n",
            "[Epoch 181/200] [Batch 37/200] [D loss: 0.001595] [G loss: 0.015871]\n",
            "[Epoch 181/200] [Batch 38/200] [D loss: 0.003180] [G loss: 0.017812]\n",
            "[Epoch 181/200] [Batch 39/200] [D loss: 0.002288] [G loss: 0.018467]\n",
            "[Epoch 181/200] [Batch 40/200] [D loss: 0.002882] [G loss: 0.021319]\n",
            "[Epoch 181/200] [Batch 41/200] [D loss: 0.002440] [G loss: 0.017756]\n",
            "[Epoch 181/200] [Batch 42/200] [D loss: 0.001024] [G loss: 0.018572]\n",
            "[Epoch 181/200] [Batch 43/200] [D loss: 0.001563] [G loss: 0.019296]\n",
            "[Epoch 181/200] [Batch 44/200] [D loss: 0.000566] [G loss: 0.021028]\n",
            "[Epoch 181/200] [Batch 45/200] [D loss: 0.001187] [G loss: 0.017992]\n",
            "[Epoch 181/200] [Batch 46/200] [D loss: 0.001432] [G loss: 0.021196]\n",
            "[Epoch 181/200] [Batch 47/200] [D loss: 0.000303] [G loss: 0.014995]\n",
            "[Epoch 181/200] [Batch 48/200] [D loss: 0.000416] [G loss: 0.018853]\n",
            "[Epoch 181/200] [Batch 49/200] [D loss: 0.000339] [G loss: 0.015963]\n",
            "[Epoch 181/200] [Batch 50/200] [D loss: 0.000255] [G loss: 0.017461]\n",
            "[Epoch 181/200] [Batch 51/200] [D loss: 0.000874] [G loss: 0.016260]\n",
            "[Epoch 181/200] [Batch 52/200] [D loss: 0.002408] [G loss: 0.021810]\n",
            "[Epoch 181/200] [Batch 53/200] [D loss: 0.001179] [G loss: 0.018143]\n",
            "[Epoch 181/200] [Batch 54/200] [D loss: 0.000450] [G loss: 0.017182]\n",
            "[Epoch 181/200] [Batch 55/200] [D loss: 0.000578] [G loss: 0.016803]\n",
            "[Epoch 181/200] [Batch 56/200] [D loss: 0.000328] [G loss: 0.019901]\n",
            "[Epoch 181/200] [Batch 57/200] [D loss: 0.000240] [G loss: 0.019903]\n",
            "[Epoch 181/200] [Batch 58/200] [D loss: 0.000145] [G loss: 0.018429]\n",
            "[Epoch 181/200] [Batch 59/200] [D loss: 0.000303] [G loss: 0.020787]\n",
            "[Epoch 181/200] [Batch 60/200] [D loss: 0.000422] [G loss: 0.016221]\n",
            "[Epoch 181/200] [Batch 61/200] [D loss: 0.000310] [G loss: 0.020618]\n",
            "[Epoch 181/200] [Batch 62/200] [D loss: 0.000208] [G loss: 0.017778]\n",
            "[Epoch 181/200] [Batch 63/200] [D loss: 0.000339] [G loss: 0.016737]\n",
            "[Epoch 181/200] [Batch 64/200] [D loss: 0.000327] [G loss: 0.016613]\n",
            "[Epoch 181/200] [Batch 65/200] [D loss: 0.000123] [G loss: 0.019465]\n",
            "[Epoch 181/200] [Batch 66/200] [D loss: 0.000301] [G loss: 0.015419]\n",
            "[Epoch 181/200] [Batch 67/200] [D loss: 0.000240] [G loss: 0.018413]\n",
            "[Epoch 181/200] [Batch 68/200] [D loss: 0.000193] [G loss: 0.015529]\n",
            "[Epoch 181/200] [Batch 69/200] [D loss: 0.000162] [G loss: 0.016140]\n",
            "[Epoch 181/200] [Batch 70/200] [D loss: 0.000447] [G loss: 0.018228]\n",
            "[Epoch 181/200] [Batch 71/200] [D loss: 0.000467] [G loss: 0.018943]\n",
            "[Epoch 181/200] [Batch 72/200] [D loss: 0.000105] [G loss: 0.015778]\n",
            "[Epoch 181/200] [Batch 73/200] [D loss: 0.000100] [G loss: 0.019145]\n",
            "[Epoch 181/200] [Batch 74/200] [D loss: 0.000072] [G loss: 0.016083]\n",
            "[Epoch 181/200] [Batch 75/200] [D loss: 0.000084] [G loss: 0.018563]\n",
            "[Epoch 181/200] [Batch 76/200] [D loss: 0.000132] [G loss: 0.018425]\n",
            "[Epoch 181/200] [Batch 77/200] [D loss: 0.000095] [G loss: 0.017411]\n",
            "[Epoch 181/200] [Batch 78/200] [D loss: 0.000111] [G loss: 0.018663]\n",
            "[Epoch 181/200] [Batch 79/200] [D loss: 0.000115] [G loss: 0.020508]\n",
            "[Epoch 181/200] [Batch 80/200] [D loss: 0.000229] [G loss: 0.018064]\n",
            "[Epoch 181/200] [Batch 81/200] [D loss: 0.000317] [G loss: 0.018978]\n",
            "[Epoch 181/200] [Batch 82/200] [D loss: 0.000179] [G loss: 0.016153]\n",
            "[Epoch 181/200] [Batch 83/200] [D loss: 0.000234] [G loss: 0.017020]\n",
            "[Epoch 181/200] [Batch 84/200] [D loss: 0.000166] [G loss: 0.020759]\n",
            "[Epoch 181/200] [Batch 85/200] [D loss: 0.000316] [G loss: 0.018659]\n",
            "[Epoch 181/200] [Batch 86/200] [D loss: 0.000721] [G loss: 0.013751]\n",
            "[Epoch 181/200] [Batch 87/200] [D loss: 0.000196] [G loss: 0.021674]\n",
            "[Epoch 181/200] [Batch 88/200] [D loss: 0.000298] [G loss: 0.015214]\n",
            "[Epoch 181/200] [Batch 89/200] [D loss: 0.000159] [G loss: 0.018270]\n",
            "[Epoch 181/200] [Batch 90/200] [D loss: 0.000243] [G loss: 0.014933]\n",
            "[Epoch 181/200] [Batch 91/200] [D loss: 0.000235] [G loss: 0.018713]\n",
            "[Epoch 181/200] [Batch 92/200] [D loss: 0.000137] [G loss: 0.017615]\n",
            "[Epoch 181/200] [Batch 93/200] [D loss: 0.000274] [G loss: 0.017773]\n",
            "[Epoch 181/200] [Batch 94/200] [D loss: 0.000175] [G loss: 0.015293]\n",
            "[Epoch 181/200] [Batch 95/200] [D loss: 0.000261] [G loss: 0.014313]\n",
            "[Epoch 181/200] [Batch 96/200] [D loss: 0.000407] [G loss: 0.017277]\n",
            "[Epoch 181/200] [Batch 97/200] [D loss: 0.000166] [G loss: 0.018622]\n",
            "[Epoch 181/200] [Batch 98/200] [D loss: 0.000097] [G loss: 0.016158]\n",
            "[Epoch 181/200] [Batch 99/200] [D loss: 0.000153] [G loss: 0.017051]\n",
            "[Epoch 181/200] [Batch 100/200] [D loss: 0.000106] [G loss: 0.015616]\n",
            "[Epoch 181/200] [Batch 101/200] [D loss: 0.000142] [G loss: 0.014228]\n",
            "[Epoch 181/200] [Batch 102/200] [D loss: 0.000183] [G loss: 0.018884]\n",
            "[Epoch 181/200] [Batch 103/200] [D loss: 0.000122] [G loss: 0.016936]\n",
            "[Epoch 181/200] [Batch 104/200] [D loss: 0.000144] [G loss: 0.014963]\n",
            "[Epoch 181/200] [Batch 105/200] [D loss: 0.000236] [G loss: 0.015864]\n",
            "[Epoch 181/200] [Batch 106/200] [D loss: 0.000325] [G loss: 0.017268]\n",
            "[Epoch 181/200] [Batch 107/200] [D loss: 0.000288] [G loss: 0.016354]\n",
            "[Epoch 181/200] [Batch 108/200] [D loss: 0.000101] [G loss: 0.016691]\n",
            "[Epoch 181/200] [Batch 109/200] [D loss: 0.000319] [G loss: 0.017861]\n",
            "[Epoch 181/200] [Batch 110/200] [D loss: 0.000466] [G loss: 0.013003]\n",
            "[Epoch 181/200] [Batch 111/200] [D loss: 0.000398] [G loss: 0.016339]\n",
            "[Epoch 181/200] [Batch 112/200] [D loss: 0.000133] [G loss: 0.018360]\n",
            "[Epoch 181/200] [Batch 113/200] [D loss: 0.000241] [G loss: 0.018205]\n",
            "[Epoch 181/200] [Batch 114/200] [D loss: 0.000256] [G loss: 0.019163]\n",
            "[Epoch 181/200] [Batch 115/200] [D loss: 0.000354] [G loss: 0.013996]\n",
            "[Epoch 181/200] [Batch 116/200] [D loss: 0.000294] [G loss: 0.016690]\n",
            "[Epoch 181/200] [Batch 117/200] [D loss: 0.000196] [G loss: 0.019130]\n",
            "[Epoch 181/200] [Batch 118/200] [D loss: 0.000155] [G loss: 0.014181]\n",
            "[Epoch 181/200] [Batch 119/200] [D loss: 0.000175] [G loss: 0.017562]\n",
            "[Epoch 181/200] [Batch 120/200] [D loss: 0.000199] [G loss: 0.016484]\n",
            "[Epoch 181/200] [Batch 121/200] [D loss: 0.000112] [G loss: 0.018820]\n",
            "[Epoch 181/200] [Batch 122/200] [D loss: 0.000170] [G loss: 0.015187]\n",
            "[Epoch 181/200] [Batch 123/200] [D loss: 0.000084] [G loss: 0.018786]\n",
            "[Epoch 181/200] [Batch 124/200] [D loss: 0.000038] [G loss: 0.015433]\n",
            "[Epoch 181/200] [Batch 125/200] [D loss: 0.000054] [G loss: 0.017942]\n",
            "[Epoch 181/200] [Batch 126/200] [D loss: 0.000125] [G loss: 0.017061]\n",
            "[Epoch 181/200] [Batch 127/200] [D loss: 0.000320] [G loss: 0.015565]\n",
            "[Epoch 181/200] [Batch 128/200] [D loss: 0.000230] [G loss: 0.019127]\n",
            "[Epoch 181/200] [Batch 129/200] [D loss: 0.000131] [G loss: 0.018440]\n",
            "[Epoch 181/200] [Batch 130/200] [D loss: 0.000113] [G loss: 0.020009]\n",
            "[Epoch 181/200] [Batch 131/200] [D loss: 0.000076] [G loss: 0.016021]\n",
            "[Epoch 181/200] [Batch 132/200] [D loss: 0.000116] [G loss: 0.019757]\n",
            "[Epoch 181/200] [Batch 133/200] [D loss: 0.000232] [G loss: 0.017217]\n",
            "[Epoch 181/200] [Batch 134/200] [D loss: 0.000238] [G loss: 0.016446]\n",
            "[Epoch 181/200] [Batch 135/200] [D loss: 0.000089] [G loss: 0.015563]\n",
            "[Epoch 181/200] [Batch 136/200] [D loss: 0.000133] [G loss: 0.018610]\n",
            "[Epoch 181/200] [Batch 137/200] [D loss: 0.000178] [G loss: 0.014668]\n",
            "[Epoch 181/200] [Batch 138/200] [D loss: 0.000095] [G loss: 0.016434]\n",
            "[Epoch 181/200] [Batch 139/200] [D loss: 0.000110] [G loss: 0.016795]\n",
            "[Epoch 181/200] [Batch 140/200] [D loss: 0.000204] [G loss: 0.015111]\n",
            "[Epoch 181/200] [Batch 141/200] [D loss: 0.000150] [G loss: 0.021166]\n",
            "[Epoch 181/200] [Batch 142/200] [D loss: 0.000073] [G loss: 0.015470]\n",
            "[Epoch 181/200] [Batch 143/200] [D loss: 0.000161] [G loss: 0.019795]\n",
            "[Epoch 181/200] [Batch 144/200] [D loss: 0.000191] [G loss: 0.017694]\n",
            "[Epoch 181/200] [Batch 145/200] [D loss: 0.000180] [G loss: 0.016711]\n",
            "[Epoch 181/200] [Batch 146/200] [D loss: 0.000107] [G loss: 0.019460]\n",
            "[Epoch 181/200] [Batch 147/200] [D loss: 0.000399] [G loss: 0.025397]\n",
            "[Epoch 181/200] [Batch 148/200] [D loss: 0.000475] [G loss: 0.019760]\n",
            "[Epoch 181/200] [Batch 149/200] [D loss: 0.000062] [G loss: 0.015764]\n",
            "[Epoch 181/200] [Batch 150/200] [D loss: 0.000196] [G loss: 0.017846]\n",
            "[Epoch 181/200] [Batch 151/200] [D loss: 0.000097] [G loss: 0.019334]\n",
            "[Epoch 181/200] [Batch 152/200] [D loss: 0.000105] [G loss: 0.016343]\n",
            "[Epoch 181/200] [Batch 153/200] [D loss: 0.000198] [G loss: 0.015188]\n",
            "[Epoch 181/200] [Batch 154/200] [D loss: 0.000224] [G loss: 0.011483]\n",
            "[Epoch 181/200] [Batch 155/200] [D loss: 0.000077] [G loss: 0.019384]\n",
            "[Epoch 181/200] [Batch 156/200] [D loss: 0.000144] [G loss: 0.022203]\n",
            "[Epoch 181/200] [Batch 157/200] [D loss: 0.000078] [G loss: 0.018946]\n",
            "[Epoch 181/200] [Batch 158/200] [D loss: 0.000097] [G loss: 0.017372]\n",
            "[Epoch 181/200] [Batch 159/200] [D loss: 0.000059] [G loss: 0.013738]\n",
            "[Epoch 181/200] [Batch 160/200] [D loss: 0.000291] [G loss: 0.017782]\n",
            "[Epoch 181/200] [Batch 161/200] [D loss: 0.000743] [G loss: 0.019730]\n",
            "[Epoch 181/200] [Batch 162/200] [D loss: 0.000204] [G loss: 0.019290]\n",
            "[Epoch 181/200] [Batch 163/200] [D loss: 0.000215] [G loss: 0.021306]\n",
            "[Epoch 181/200] [Batch 164/200] [D loss: 0.000195] [G loss: 0.020820]\n",
            "[Epoch 181/200] [Batch 165/200] [D loss: 0.000149] [G loss: 0.021610]\n",
            "[Epoch 181/200] [Batch 166/200] [D loss: 0.000146] [G loss: 0.017195]\n",
            "[Epoch 181/200] [Batch 167/200] [D loss: 0.000078] [G loss: 0.016808]\n",
            "[Epoch 181/200] [Batch 168/200] [D loss: 0.000116] [G loss: 0.019852]\n",
            "[Epoch 181/200] [Batch 169/200] [D loss: 0.000091] [G loss: 0.015007]\n",
            "[Epoch 181/200] [Batch 170/200] [D loss: 0.000048] [G loss: 0.016890]\n",
            "[Epoch 181/200] [Batch 171/200] [D loss: 0.000057] [G loss: 0.017472]\n",
            "[Epoch 181/200] [Batch 172/200] [D loss: 0.000067] [G loss: 0.017522]\n",
            "[Epoch 181/200] [Batch 173/200] [D loss: 0.000095] [G loss: 0.022861]\n",
            "[Epoch 181/200] [Batch 174/200] [D loss: 0.000113] [G loss: 0.015613]\n",
            "[Epoch 181/200] [Batch 175/200] [D loss: 0.000136] [G loss: 0.018962]\n",
            "[Epoch 181/200] [Batch 176/200] [D loss: 0.000074] [G loss: 0.015303]\n",
            "[Epoch 181/200] [Batch 177/200] [D loss: 0.000157] [G loss: 0.014122]\n",
            "[Epoch 181/200] [Batch 178/200] [D loss: 0.000118] [G loss: 0.016686]\n",
            "[Epoch 181/200] [Batch 179/200] [D loss: 0.000101] [G loss: 0.019781]\n",
            "[Epoch 181/200] [Batch 180/200] [D loss: 0.000136] [G loss: 0.016957]\n",
            "[Epoch 181/200] [Batch 181/200] [D loss: 0.000074] [G loss: 0.017443]\n",
            "[Epoch 181/200] [Batch 182/200] [D loss: 0.000048] [G loss: 0.017109]\n",
            "[Epoch 181/200] [Batch 183/200] [D loss: 0.000735] [G loss: 0.016048]\n",
            "[Epoch 181/200] [Batch 184/200] [D loss: 0.000338] [G loss: 0.020486]\n",
            "[Epoch 181/200] [Batch 185/200] [D loss: 0.000496] [G loss: 0.019997]\n",
            "[Epoch 181/200] [Batch 186/200] [D loss: 0.000304] [G loss: 0.016243]\n",
            "[Epoch 181/200] [Batch 187/200] [D loss: 0.000318] [G loss: 0.018226]\n",
            "[Epoch 181/200] [Batch 188/200] [D loss: 0.000216] [G loss: 0.021380]\n",
            "[Epoch 181/200] [Batch 189/200] [D loss: 0.000133] [G loss: 0.015488]\n",
            "[Epoch 181/200] [Batch 190/200] [D loss: 0.000091] [G loss: 0.019900]\n",
            "[Epoch 181/200] [Batch 191/200] [D loss: 0.000163] [G loss: 0.015883]\n",
            "[Epoch 181/200] [Batch 192/200] [D loss: 0.000185] [G loss: 0.015356]\n",
            "[Epoch 181/200] [Batch 193/200] [D loss: 0.000280] [G loss: 0.016268]\n",
            "[Epoch 181/200] [Batch 194/200] [D loss: 0.000198] [G loss: 0.017959]\n",
            "[Epoch 181/200] [Batch 195/200] [D loss: 0.000087] [G loss: 0.019315]\n",
            "[Epoch 181/200] [Batch 196/200] [D loss: 0.000071] [G loss: 0.020637]\n",
            "[Epoch 181/200] [Batch 197/200] [D loss: 0.000243] [G loss: 0.021699]\n",
            "[Epoch 181/200] [Batch 198/200] [D loss: 0.000280] [G loss: 0.019318]\n",
            "[Epoch 181/200] [Batch 199/200] [D loss: 0.000201] [G loss: 0.017740]\n",
            "[Epoch 182/200] [Batch 0/200] [D loss: 0.000352] [G loss: 0.021482]\n",
            "[Epoch 182/200] [Batch 1/200] [D loss: 0.000301] [G loss: 0.018699]\n",
            "[Epoch 182/200] [Batch 2/200] [D loss: 0.000216] [G loss: 0.017518]\n",
            "[Epoch 182/200] [Batch 3/200] [D loss: 0.000198] [G loss: 0.018344]\n",
            "[Epoch 182/200] [Batch 4/200] [D loss: 0.000162] [G loss: 0.016670]\n",
            "[Epoch 182/200] [Batch 5/200] [D loss: 0.000055] [G loss: 0.016402]\n",
            "[Epoch 182/200] [Batch 6/200] [D loss: 0.000248] [G loss: 0.019459]\n",
            "[Epoch 182/200] [Batch 7/200] [D loss: 0.000077] [G loss: 0.019509]\n",
            "[Epoch 182/200] [Batch 8/200] [D loss: 0.000144] [G loss: 0.018449]\n",
            "[Epoch 182/200] [Batch 9/200] [D loss: 0.000150] [G loss: 0.018239]\n",
            "[Epoch 182/200] [Batch 10/200] [D loss: 0.000098] [G loss: 0.017965]\n",
            "[Epoch 182/200] [Batch 11/200] [D loss: 0.000119] [G loss: 0.015259]\n",
            "[Epoch 182/200] [Batch 12/200] [D loss: 0.000111] [G loss: 0.018006]\n",
            "[Epoch 182/200] [Batch 13/200] [D loss: 0.000064] [G loss: 0.019133]\n",
            "[Epoch 182/200] [Batch 14/200] [D loss: 0.000046] [G loss: 0.013889]\n",
            "[Epoch 182/200] [Batch 15/200] [D loss: 0.000102] [G loss: 0.013889]\n",
            "[Epoch 182/200] [Batch 16/200] [D loss: 0.000167] [G loss: 0.023214]\n",
            "[Epoch 182/200] [Batch 17/200] [D loss: 0.000081] [G loss: 0.016299]\n",
            "[Epoch 182/200] [Batch 18/200] [D loss: 0.000115] [G loss: 0.017365]\n",
            "[Epoch 182/200] [Batch 19/200] [D loss: 0.000158] [G loss: 0.015436]\n",
            "[Epoch 182/200] [Batch 20/200] [D loss: 0.000487] [G loss: 0.017417]\n",
            "[Epoch 182/200] [Batch 21/200] [D loss: 0.000271] [G loss: 0.020274]\n",
            "[Epoch 182/200] [Batch 22/200] [D loss: 0.000112] [G loss: 0.016061]\n",
            "[Epoch 182/200] [Batch 23/200] [D loss: 0.000123] [G loss: 0.017242]\n",
            "[Epoch 182/200] [Batch 24/200] [D loss: 0.000161] [G loss: 0.023031]\n",
            "[Epoch 182/200] [Batch 25/200] [D loss: 0.000108] [G loss: 0.018648]\n",
            "[Epoch 182/200] [Batch 26/200] [D loss: 0.000083] [G loss: 0.015140]\n",
            "[Epoch 182/200] [Batch 27/200] [D loss: 0.000101] [G loss: 0.015212]\n",
            "[Epoch 182/200] [Batch 28/200] [D loss: 0.000090] [G loss: 0.014888]\n",
            "[Epoch 182/200] [Batch 29/200] [D loss: 0.000096] [G loss: 0.016443]\n",
            "[Epoch 182/200] [Batch 30/200] [D loss: 0.000112] [G loss: 0.016798]\n",
            "[Epoch 182/200] [Batch 31/200] [D loss: 0.000104] [G loss: 0.014949]\n",
            "[Epoch 182/200] [Batch 32/200] [D loss: 0.000094] [G loss: 0.017435]\n",
            "[Epoch 182/200] [Batch 33/200] [D loss: 0.000064] [G loss: 0.015132]\n",
            "[Epoch 182/200] [Batch 34/200] [D loss: 0.000198] [G loss: 0.015445]\n",
            "[Epoch 182/200] [Batch 35/200] [D loss: 0.000266] [G loss: 0.015922]\n",
            "[Epoch 182/200] [Batch 36/200] [D loss: 0.000099] [G loss: 0.017762]\n",
            "[Epoch 182/200] [Batch 37/200] [D loss: 0.000077] [G loss: 0.018402]\n",
            "[Epoch 182/200] [Batch 38/200] [D loss: 0.000180] [G loss: 0.016363]\n",
            "[Epoch 182/200] [Batch 39/200] [D loss: 0.000131] [G loss: 0.017428]\n",
            "[Epoch 182/200] [Batch 40/200] [D loss: 0.000083] [G loss: 0.013047]\n",
            "[Epoch 182/200] [Batch 41/200] [D loss: 0.000138] [G loss: 0.015843]\n",
            "[Epoch 182/200] [Batch 42/200] [D loss: 0.000296] [G loss: 0.019706]\n",
            "[Epoch 182/200] [Batch 43/200] [D loss: 0.000097] [G loss: 0.020239]\n",
            "[Epoch 182/200] [Batch 44/200] [D loss: 0.000193] [G loss: 0.013832]\n",
            "[Epoch 182/200] [Batch 45/200] [D loss: 0.000099] [G loss: 0.023010]\n",
            "[Epoch 182/200] [Batch 46/200] [D loss: 0.000056] [G loss: 0.017825]\n",
            "[Epoch 182/200] [Batch 47/200] [D loss: 0.000070] [G loss: 0.016037]\n",
            "[Epoch 182/200] [Batch 48/200] [D loss: 0.000050] [G loss: 0.022289]\n",
            "[Epoch 182/200] [Batch 49/200] [D loss: 0.000094] [G loss: 0.016117]\n",
            "[Epoch 182/200] [Batch 50/200] [D loss: 0.000141] [G loss: 0.013566]\n",
            "[Epoch 182/200] [Batch 51/200] [D loss: 0.000166] [G loss: 0.018615]\n",
            "[Epoch 182/200] [Batch 52/200] [D loss: 0.000161] [G loss: 0.020053]\n",
            "[Epoch 182/200] [Batch 53/200] [D loss: 0.000233] [G loss: 0.015811]\n",
            "[Epoch 182/200] [Batch 54/200] [D loss: 0.000494] [G loss: 0.017846]\n",
            "[Epoch 182/200] [Batch 55/200] [D loss: 0.000166] [G loss: 0.018457]\n",
            "[Epoch 182/200] [Batch 56/200] [D loss: 0.000127] [G loss: 0.015083]\n",
            "[Epoch 182/200] [Batch 57/200] [D loss: 0.000085] [G loss: 0.018677]\n",
            "[Epoch 182/200] [Batch 58/200] [D loss: 0.000083] [G loss: 0.018186]\n",
            "[Epoch 182/200] [Batch 59/200] [D loss: 0.000185] [G loss: 0.016189]\n",
            "[Epoch 182/200] [Batch 60/200] [D loss: 0.000134] [G loss: 0.016074]\n",
            "[Epoch 182/200] [Batch 61/200] [D loss: 0.000142] [G loss: 0.015106]\n",
            "[Epoch 182/200] [Batch 62/200] [D loss: 0.000192] [G loss: 0.014892]\n",
            "[Epoch 182/200] [Batch 63/200] [D loss: 0.000238] [G loss: 0.016653]\n",
            "[Epoch 182/200] [Batch 64/200] [D loss: 0.000155] [G loss: 0.016868]\n",
            "[Epoch 182/200] [Batch 65/200] [D loss: 0.000238] [G loss: 0.017605]\n",
            "[Epoch 182/200] [Batch 66/200] [D loss: 0.000168] [G loss: 0.021398]\n",
            "[Epoch 182/200] [Batch 67/200] [D loss: 0.000396] [G loss: 0.018590]\n",
            "[Epoch 182/200] [Batch 68/200] [D loss: 0.000626] [G loss: 0.014283]\n",
            "[Epoch 182/200] [Batch 69/200] [D loss: 0.000404] [G loss: 0.014146]\n",
            "[Epoch 182/200] [Batch 70/200] [D loss: 0.000571] [G loss: 0.018656]\n",
            "[Epoch 182/200] [Batch 71/200] [D loss: 0.000609] [G loss: 0.020052]\n",
            "[Epoch 182/200] [Batch 72/200] [D loss: 0.000346] [G loss: 0.019161]\n",
            "[Epoch 182/200] [Batch 73/200] [D loss: 0.000249] [G loss: 0.015455]\n",
            "[Epoch 182/200] [Batch 74/200] [D loss: 0.000140] [G loss: 0.019534]\n",
            "[Epoch 182/200] [Batch 75/200] [D loss: 0.000244] [G loss: 0.020392]\n",
            "[Epoch 182/200] [Batch 76/200] [D loss: 0.000233] [G loss: 0.016509]\n",
            "[Epoch 182/200] [Batch 77/200] [D loss: 0.000127] [G loss: 0.020594]\n",
            "[Epoch 182/200] [Batch 78/200] [D loss: 0.000169] [G loss: 0.017979]\n",
            "[Epoch 182/200] [Batch 79/200] [D loss: 0.000094] [G loss: 0.016520]\n",
            "[Epoch 182/200] [Batch 80/200] [D loss: 0.000122] [G loss: 0.020752]\n",
            "[Epoch 182/200] [Batch 81/200] [D loss: 0.000494] [G loss: 0.015507]\n",
            "[Epoch 182/200] [Batch 82/200] [D loss: 0.000641] [G loss: 0.019947]\n",
            "[Epoch 182/200] [Batch 83/200] [D loss: 0.000392] [G loss: 0.021496]\n",
            "[Epoch 182/200] [Batch 84/200] [D loss: 0.000358] [G loss: 0.019298]\n",
            "[Epoch 182/200] [Batch 85/200] [D loss: 0.000517] [G loss: 0.020463]\n",
            "[Epoch 182/200] [Batch 86/200] [D loss: 0.000134] [G loss: 0.017317]\n",
            "[Epoch 182/200] [Batch 87/200] [D loss: 0.000217] [G loss: 0.019147]\n",
            "[Epoch 182/200] [Batch 88/200] [D loss: 0.000165] [G loss: 0.016346]\n",
            "[Epoch 182/200] [Batch 89/200] [D loss: 0.000109] [G loss: 0.017878]\n",
            "[Epoch 182/200] [Batch 90/200] [D loss: 0.000087] [G loss: 0.018260]\n",
            "[Epoch 182/200] [Batch 91/200] [D loss: 0.000180] [G loss: 0.017955]\n",
            "[Epoch 182/200] [Batch 92/200] [D loss: 0.000159] [G loss: 0.019415]\n",
            "[Epoch 182/200] [Batch 93/200] [D loss: 0.000166] [G loss: 0.016648]\n",
            "[Epoch 182/200] [Batch 94/200] [D loss: 0.000106] [G loss: 0.020552]\n",
            "[Epoch 182/200] [Batch 95/200] [D loss: 0.000175] [G loss: 0.020082]\n",
            "[Epoch 182/200] [Batch 96/200] [D loss: 0.000069] [G loss: 0.016706]\n",
            "[Epoch 182/200] [Batch 97/200] [D loss: 0.000093] [G loss: 0.017859]\n",
            "[Epoch 182/200] [Batch 98/200] [D loss: 0.000123] [G loss: 0.012181]\n",
            "[Epoch 182/200] [Batch 99/200] [D loss: 0.000135] [G loss: 0.019662]\n",
            "[Epoch 182/200] [Batch 100/200] [D loss: 0.000090] [G loss: 0.022093]\n",
            "[Epoch 182/200] [Batch 101/200] [D loss: 0.000101] [G loss: 0.017246]\n",
            "[Epoch 182/200] [Batch 102/200] [D loss: 0.000047] [G loss: 0.017783]\n",
            "[Epoch 182/200] [Batch 103/200] [D loss: 0.000089] [G loss: 0.021127]\n",
            "[Epoch 182/200] [Batch 104/200] [D loss: 0.000070] [G loss: 0.019153]\n",
            "[Epoch 182/200] [Batch 105/200] [D loss: 0.000066] [G loss: 0.015427]\n",
            "[Epoch 182/200] [Batch 106/200] [D loss: 0.000051] [G loss: 0.022064]\n",
            "[Epoch 182/200] [Batch 107/200] [D loss: 0.000042] [G loss: 0.017114]\n",
            "[Epoch 182/200] [Batch 108/200] [D loss: 0.000081] [G loss: 0.016635]\n",
            "[Epoch 182/200] [Batch 109/200] [D loss: 0.000090] [G loss: 0.017022]\n",
            "[Epoch 182/200] [Batch 110/200] [D loss: 0.000095] [G loss: 0.021939]\n",
            "[Epoch 182/200] [Batch 111/200] [D loss: 0.000096] [G loss: 0.023873]\n",
            "[Epoch 182/200] [Batch 112/200] [D loss: 0.000092] [G loss: 0.018648]\n",
            "[Epoch 182/200] [Batch 113/200] [D loss: 0.000086] [G loss: 0.018508]\n",
            "[Epoch 182/200] [Batch 114/200] [D loss: 0.000221] [G loss: 0.016401]\n",
            "[Epoch 182/200] [Batch 115/200] [D loss: 0.000209] [G loss: 0.015713]\n",
            "[Epoch 182/200] [Batch 116/200] [D loss: 0.000088] [G loss: 0.012912]\n",
            "[Epoch 182/200] [Batch 117/200] [D loss: 0.000080] [G loss: 0.022461]\n",
            "[Epoch 182/200] [Batch 118/200] [D loss: 0.000100] [G loss: 0.017552]\n",
            "[Epoch 182/200] [Batch 119/200] [D loss: 0.000068] [G loss: 0.015611]\n",
            "[Epoch 182/200] [Batch 120/200] [D loss: 0.000075] [G loss: 0.019012]\n",
            "[Epoch 182/200] [Batch 121/200] [D loss: 0.000049] [G loss: 0.017360]\n",
            "[Epoch 182/200] [Batch 122/200] [D loss: 0.000075] [G loss: 0.019656]\n",
            "[Epoch 182/200] [Batch 123/200] [D loss: 0.000128] [G loss: 0.014683]\n",
            "[Epoch 182/200] [Batch 124/200] [D loss: 0.000104] [G loss: 0.017234]\n",
            "[Epoch 182/200] [Batch 125/200] [D loss: 0.000073] [G loss: 0.018531]\n",
            "[Epoch 182/200] [Batch 126/200] [D loss: 0.000132] [G loss: 0.017320]\n",
            "[Epoch 182/200] [Batch 127/200] [D loss: 0.000133] [G loss: 0.018771]\n",
            "[Epoch 182/200] [Batch 128/200] [D loss: 0.000084] [G loss: 0.016534]\n",
            "[Epoch 182/200] [Batch 129/200] [D loss: 0.000080] [G loss: 0.019701]\n",
            "[Epoch 182/200] [Batch 130/200] [D loss: 0.000152] [G loss: 0.016676]\n",
            "[Epoch 182/200] [Batch 131/200] [D loss: 0.000092] [G loss: 0.018030]\n",
            "[Epoch 182/200] [Batch 132/200] [D loss: 0.000076] [G loss: 0.014006]\n",
            "[Epoch 182/200] [Batch 133/200] [D loss: 0.000134] [G loss: 0.015531]\n",
            "[Epoch 182/200] [Batch 134/200] [D loss: 0.000095] [G loss: 0.020837]\n",
            "[Epoch 182/200] [Batch 135/200] [D loss: 0.000091] [G loss: 0.019248]\n",
            "[Epoch 182/200] [Batch 136/200] [D loss: 0.000109] [G loss: 0.018727]\n",
            "[Epoch 182/200] [Batch 137/200] [D loss: 0.000143] [G loss: 0.021383]\n",
            "[Epoch 182/200] [Batch 138/200] [D loss: 0.000128] [G loss: 0.016315]\n",
            "[Epoch 182/200] [Batch 139/200] [D loss: 0.000090] [G loss: 0.021762]\n",
            "[Epoch 182/200] [Batch 140/200] [D loss: 0.000094] [G loss: 0.016357]\n",
            "[Epoch 182/200] [Batch 141/200] [D loss: 0.000220] [G loss: 0.016182]\n",
            "[Epoch 182/200] [Batch 142/200] [D loss: 0.000154] [G loss: 0.014913]\n",
            "[Epoch 182/200] [Batch 143/200] [D loss: 0.000080] [G loss: 0.018605]\n",
            "[Epoch 182/200] [Batch 144/200] [D loss: 0.000087] [G loss: 0.011830]\n",
            "[Epoch 182/200] [Batch 145/200] [D loss: 0.000260] [G loss: 0.015286]\n",
            "[Epoch 182/200] [Batch 146/200] [D loss: 0.000286] [G loss: 0.019059]\n",
            "[Epoch 182/200] [Batch 147/200] [D loss: 0.000209] [G loss: 0.016171]\n",
            "[Epoch 182/200] [Batch 148/200] [D loss: 0.000194] [G loss: 0.018860]\n",
            "[Epoch 182/200] [Batch 149/200] [D loss: 0.000215] [G loss: 0.018400]\n",
            "[Epoch 182/200] [Batch 150/200] [D loss: 0.000303] [G loss: 0.018564]\n",
            "[Epoch 182/200] [Batch 151/200] [D loss: 0.000450] [G loss: 0.015760]\n",
            "[Epoch 182/200] [Batch 152/200] [D loss: 0.000200] [G loss: 0.014878]\n",
            "[Epoch 182/200] [Batch 153/200] [D loss: 0.000293] [G loss: 0.018066]\n",
            "[Epoch 182/200] [Batch 154/200] [D loss: 0.000499] [G loss: 0.020698]\n",
            "[Epoch 182/200] [Batch 155/200] [D loss: 0.000641] [G loss: 0.018247]\n",
            "[Epoch 182/200] [Batch 156/200] [D loss: 0.000433] [G loss: 0.013488]\n",
            "[Epoch 182/200] [Batch 157/200] [D loss: 0.000650] [G loss: 0.016824]\n",
            "[Epoch 182/200] [Batch 158/200] [D loss: 0.000282] [G loss: 0.016631]\n",
            "[Epoch 182/200] [Batch 159/200] [D loss: 0.000190] [G loss: 0.019429]\n",
            "[Epoch 182/200] [Batch 160/200] [D loss: 0.000278] [G loss: 0.016278]\n",
            "[Epoch 182/200] [Batch 161/200] [D loss: 0.001204] [G loss: 0.017770]\n",
            "[Epoch 182/200] [Batch 162/200] [D loss: 0.000513] [G loss: 0.020513]\n",
            "[Epoch 182/200] [Batch 163/200] [D loss: 0.000215] [G loss: 0.020179]\n",
            "[Epoch 182/200] [Batch 164/200] [D loss: 0.000216] [G loss: 0.016049]\n",
            "[Epoch 182/200] [Batch 165/200] [D loss: 0.000364] [G loss: 0.014827]\n",
            "[Epoch 182/200] [Batch 166/200] [D loss: 0.000764] [G loss: 0.018490]\n",
            "[Epoch 182/200] [Batch 167/200] [D loss: 0.000796] [G loss: 0.018135]\n",
            "[Epoch 182/200] [Batch 168/200] [D loss: 0.000266] [G loss: 0.014989]\n",
            "[Epoch 182/200] [Batch 169/200] [D loss: 0.000209] [G loss: 0.015291]\n",
            "[Epoch 182/200] [Batch 170/200] [D loss: 0.000286] [G loss: 0.016018]\n",
            "[Epoch 182/200] [Batch 171/200] [D loss: 0.000091] [G loss: 0.018508]\n",
            "[Epoch 182/200] [Batch 172/200] [D loss: 0.000335] [G loss: 0.017408]\n",
            "[Epoch 182/200] [Batch 173/200] [D loss: 0.000263] [G loss: 0.019746]\n",
            "[Epoch 182/200] [Batch 174/200] [D loss: 0.000208] [G loss: 0.015363]\n",
            "[Epoch 182/200] [Batch 175/200] [D loss: 0.000904] [G loss: 0.023112]\n",
            "[Epoch 182/200] [Batch 176/200] [D loss: 0.000714] [G loss: 0.013805]\n",
            "[Epoch 182/200] [Batch 177/200] [D loss: 0.000424] [G loss: 0.017334]\n",
            "[Epoch 182/200] [Batch 178/200] [D loss: 0.000405] [G loss: 0.020565]\n",
            "[Epoch 182/200] [Batch 179/200] [D loss: 0.000937] [G loss: 0.014888]\n",
            "[Epoch 182/200] [Batch 180/200] [D loss: 0.000209] [G loss: 0.016317]\n",
            "[Epoch 182/200] [Batch 181/200] [D loss: 0.000496] [G loss: 0.017509]\n",
            "[Epoch 182/200] [Batch 182/200] [D loss: 0.000834] [G loss: 0.016024]\n",
            "[Epoch 182/200] [Batch 183/200] [D loss: 0.001189] [G loss: 0.019316]\n",
            "[Epoch 182/200] [Batch 184/200] [D loss: 0.001566] [G loss: 0.019547]\n",
            "[Epoch 182/200] [Batch 185/200] [D loss: 0.000731] [G loss: 0.020122]\n",
            "[Epoch 182/200] [Batch 186/200] [D loss: 0.000372] [G loss: 0.018586]\n",
            "[Epoch 182/200] [Batch 187/200] [D loss: 0.001105] [G loss: 0.019823]\n",
            "[Epoch 182/200] [Batch 188/200] [D loss: 0.000737] [G loss: 0.014251]\n",
            "[Epoch 182/200] [Batch 189/200] [D loss: 0.000227] [G loss: 0.020652]\n",
            "[Epoch 182/200] [Batch 190/200] [D loss: 0.000339] [G loss: 0.018455]\n",
            "[Epoch 182/200] [Batch 191/200] [D loss: 0.000185] [G loss: 0.015098]\n",
            "[Epoch 182/200] [Batch 192/200] [D loss: 0.000324] [G loss: 0.017747]\n",
            "[Epoch 182/200] [Batch 193/200] [D loss: 0.000295] [G loss: 0.013694]\n",
            "[Epoch 182/200] [Batch 194/200] [D loss: 0.000103] [G loss: 0.015458]\n",
            "[Epoch 182/200] [Batch 195/200] [D loss: 0.000119] [G loss: 0.016274]\n",
            "[Epoch 182/200] [Batch 196/200] [D loss: 0.000172] [G loss: 0.020009]\n",
            "[Epoch 182/200] [Batch 197/200] [D loss: 0.000103] [G loss: 0.016802]\n",
            "[Epoch 182/200] [Batch 198/200] [D loss: 0.000158] [G loss: 0.015202]\n",
            "[Epoch 182/200] [Batch 199/200] [D loss: 0.000378] [G loss: 0.012539]\n",
            "[Epoch 183/200] [Batch 0/200] [D loss: 0.000354] [G loss: 0.015564]\n",
            "[Epoch 183/200] [Batch 1/200] [D loss: 0.000147] [G loss: 0.020221]\n",
            "[Epoch 183/200] [Batch 2/200] [D loss: 0.000315] [G loss: 0.015815]\n",
            "[Epoch 183/200] [Batch 3/200] [D loss: 0.000283] [G loss: 0.015190]\n",
            "[Epoch 183/200] [Batch 4/200] [D loss: 0.000291] [G loss: 0.016412]\n",
            "[Epoch 183/200] [Batch 5/200] [D loss: 0.000094] [G loss: 0.016768]\n",
            "[Epoch 183/200] [Batch 6/200] [D loss: 0.000091] [G loss: 0.017262]\n",
            "[Epoch 183/200] [Batch 7/200] [D loss: 0.000125] [G loss: 0.015439]\n",
            "[Epoch 183/200] [Batch 8/200] [D loss: 0.000135] [G loss: 0.017789]\n",
            "[Epoch 183/200] [Batch 9/200] [D loss: 0.000101] [G loss: 0.021895]\n",
            "[Epoch 183/200] [Batch 10/200] [D loss: 0.000084] [G loss: 0.019861]\n",
            "[Epoch 183/200] [Batch 11/200] [D loss: 0.000077] [G loss: 0.015348]\n",
            "[Epoch 183/200] [Batch 12/200] [D loss: 0.000102] [G loss: 0.015816]\n",
            "[Epoch 183/200] [Batch 13/200] [D loss: 0.000269] [G loss: 0.018198]\n",
            "[Epoch 183/200] [Batch 14/200] [D loss: 0.000233] [G loss: 0.017184]\n",
            "[Epoch 183/200] [Batch 15/200] [D loss: 0.000084] [G loss: 0.015612]\n",
            "[Epoch 183/200] [Batch 16/200] [D loss: 0.000222] [G loss: 0.020477]\n",
            "[Epoch 183/200] [Batch 17/200] [D loss: 0.000256] [G loss: 0.017399]\n",
            "[Epoch 183/200] [Batch 18/200] [D loss: 0.000173] [G loss: 0.021338]\n",
            "[Epoch 183/200] [Batch 19/200] [D loss: 0.000184] [G loss: 0.017531]\n",
            "[Epoch 183/200] [Batch 20/200] [D loss: 0.000079] [G loss: 0.018801]\n",
            "[Epoch 183/200] [Batch 21/200] [D loss: 0.000111] [G loss: 0.017457]\n",
            "[Epoch 183/200] [Batch 22/200] [D loss: 0.000140] [G loss: 0.019205]\n",
            "[Epoch 183/200] [Batch 23/200] [D loss: 0.000266] [G loss: 0.015429]\n",
            "[Epoch 183/200] [Batch 24/200] [D loss: 0.000254] [G loss: 0.014690]\n",
            "[Epoch 183/200] [Batch 25/200] [D loss: 0.000068] [G loss: 0.017657]\n",
            "[Epoch 183/200] [Batch 26/200] [D loss: 0.000158] [G loss: 0.018119]\n",
            "[Epoch 183/200] [Batch 27/200] [D loss: 0.000129] [G loss: 0.017266]\n",
            "[Epoch 183/200] [Batch 28/200] [D loss: 0.000061] [G loss: 0.018588]\n",
            "[Epoch 183/200] [Batch 29/200] [D loss: 0.000075] [G loss: 0.018939]\n",
            "[Epoch 183/200] [Batch 30/200] [D loss: 0.000099] [G loss: 0.021839]\n",
            "[Epoch 183/200] [Batch 31/200] [D loss: 0.000191] [G loss: 0.016995]\n",
            "[Epoch 183/200] [Batch 32/200] [D loss: 0.000143] [G loss: 0.021753]\n",
            "[Epoch 183/200] [Batch 33/200] [D loss: 0.000125] [G loss: 0.015673]\n",
            "[Epoch 183/200] [Batch 34/200] [D loss: 0.000102] [G loss: 0.017568]\n",
            "[Epoch 183/200] [Batch 35/200] [D loss: 0.000041] [G loss: 0.018832]\n",
            "[Epoch 183/200] [Batch 36/200] [D loss: 0.000156] [G loss: 0.017273]\n",
            "[Epoch 183/200] [Batch 37/200] [D loss: 0.000168] [G loss: 0.014373]\n",
            "[Epoch 183/200] [Batch 38/200] [D loss: 0.000070] [G loss: 0.016154]\n",
            "[Epoch 183/200] [Batch 39/200] [D loss: 0.000135] [G loss: 0.017939]\n",
            "[Epoch 183/200] [Batch 40/200] [D loss: 0.000097] [G loss: 0.016077]\n",
            "[Epoch 183/200] [Batch 41/200] [D loss: 0.000077] [G loss: 0.015473]\n",
            "[Epoch 183/200] [Batch 42/200] [D loss: 0.000091] [G loss: 0.019623]\n",
            "[Epoch 183/200] [Batch 43/200] [D loss: 0.000104] [G loss: 0.018748]\n",
            "[Epoch 183/200] [Batch 44/200] [D loss: 0.000106] [G loss: 0.018347]\n",
            "[Epoch 183/200] [Batch 45/200] [D loss: 0.000077] [G loss: 0.016782]\n",
            "[Epoch 183/200] [Batch 46/200] [D loss: 0.000096] [G loss: 0.022407]\n",
            "[Epoch 183/200] [Batch 47/200] [D loss: 0.000075] [G loss: 0.013562]\n",
            "[Epoch 183/200] [Batch 48/200] [D loss: 0.000086] [G loss: 0.014973]\n",
            "[Epoch 183/200] [Batch 49/200] [D loss: 0.000076] [G loss: 0.017989]\n",
            "[Epoch 183/200] [Batch 50/200] [D loss: 0.000075] [G loss: 0.018297]\n",
            "[Epoch 183/200] [Batch 51/200] [D loss: 0.000070] [G loss: 0.018964]\n",
            "[Epoch 183/200] [Batch 52/200] [D loss: 0.000293] [G loss: 0.018321]\n",
            "[Epoch 183/200] [Batch 53/200] [D loss: 0.000355] [G loss: 0.017160]\n",
            "[Epoch 183/200] [Batch 54/200] [D loss: 0.000091] [G loss: 0.013739]\n",
            "[Epoch 183/200] [Batch 55/200] [D loss: 0.000172] [G loss: 0.019034]\n",
            "[Epoch 183/200] [Batch 56/200] [D loss: 0.000101] [G loss: 0.018707]\n",
            "[Epoch 183/200] [Batch 57/200] [D loss: 0.000068] [G loss: 0.019634]\n",
            "[Epoch 183/200] [Batch 58/200] [D loss: 0.000068] [G loss: 0.016917]\n",
            "[Epoch 183/200] [Batch 59/200] [D loss: 0.000059] [G loss: 0.015615]\n",
            "[Epoch 183/200] [Batch 60/200] [D loss: 0.000057] [G loss: 0.016249]\n",
            "[Epoch 183/200] [Batch 61/200] [D loss: 0.000091] [G loss: 0.018675]\n",
            "[Epoch 183/200] [Batch 62/200] [D loss: 0.000204] [G loss: 0.019140]\n",
            "[Epoch 183/200] [Batch 63/200] [D loss: 0.000129] [G loss: 0.016093]\n",
            "[Epoch 183/200] [Batch 64/200] [D loss: 0.000087] [G loss: 0.019456]\n",
            "[Epoch 183/200] [Batch 65/200] [D loss: 0.000165] [G loss: 0.014644]\n",
            "[Epoch 183/200] [Batch 66/200] [D loss: 0.000119] [G loss: 0.016266]\n",
            "[Epoch 183/200] [Batch 67/200] [D loss: 0.000060] [G loss: 0.016465]\n",
            "[Epoch 183/200] [Batch 68/200] [D loss: 0.000073] [G loss: 0.016914]\n",
            "[Epoch 183/200] [Batch 69/200] [D loss: 0.000119] [G loss: 0.018636]\n",
            "[Epoch 183/200] [Batch 70/200] [D loss: 0.000089] [G loss: 0.016192]\n",
            "[Epoch 183/200] [Batch 71/200] [D loss: 0.000076] [G loss: 0.019529]\n",
            "[Epoch 183/200] [Batch 72/200] [D loss: 0.000095] [G loss: 0.017071]\n",
            "[Epoch 183/200] [Batch 73/200] [D loss: 0.000053] [G loss: 0.018185]\n",
            "[Epoch 183/200] [Batch 74/200] [D loss: 0.000032] [G loss: 0.018285]\n",
            "[Epoch 183/200] [Batch 75/200] [D loss: 0.000086] [G loss: 0.017442]\n",
            "[Epoch 183/200] [Batch 76/200] [D loss: 0.000169] [G loss: 0.015069]\n",
            "[Epoch 183/200] [Batch 77/200] [D loss: 0.000202] [G loss: 0.018034]\n",
            "[Epoch 183/200] [Batch 78/200] [D loss: 0.000070] [G loss: 0.016664]\n",
            "[Epoch 183/200] [Batch 79/200] [D loss: 0.000063] [G loss: 0.020116]\n",
            "[Epoch 183/200] [Batch 80/200] [D loss: 0.000042] [G loss: 0.015098]\n",
            "[Epoch 183/200] [Batch 81/200] [D loss: 0.000068] [G loss: 0.012646]\n",
            "[Epoch 183/200] [Batch 82/200] [D loss: 0.000091] [G loss: 0.013306]\n",
            "[Epoch 183/200] [Batch 83/200] [D loss: 0.000143] [G loss: 0.017771]\n",
            "[Epoch 183/200] [Batch 84/200] [D loss: 0.000184] [G loss: 0.019296]\n",
            "[Epoch 183/200] [Batch 85/200] [D loss: 0.000247] [G loss: 0.018604]\n",
            "[Epoch 183/200] [Batch 86/200] [D loss: 0.000100] [G loss: 0.016506]\n",
            "[Epoch 183/200] [Batch 87/200] [D loss: 0.000088] [G loss: 0.017380]\n",
            "[Epoch 183/200] [Batch 88/200] [D loss: 0.000143] [G loss: 0.018806]\n",
            "[Epoch 183/200] [Batch 89/200] [D loss: 0.000174] [G loss: 0.017093]\n",
            "[Epoch 183/200] [Batch 90/200] [D loss: 0.000214] [G loss: 0.019633]\n",
            "[Epoch 183/200] [Batch 91/200] [D loss: 0.000186] [G loss: 0.016532]\n",
            "[Epoch 183/200] [Batch 92/200] [D loss: 0.000098] [G loss: 0.014226]\n",
            "[Epoch 183/200] [Batch 93/200] [D loss: 0.000073] [G loss: 0.020700]\n",
            "[Epoch 183/200] [Batch 94/200] [D loss: 0.000091] [G loss: 0.017707]\n",
            "[Epoch 183/200] [Batch 95/200] [D loss: 0.000072] [G loss: 0.018466]\n",
            "[Epoch 183/200] [Batch 96/200] [D loss: 0.000111] [G loss: 0.018414]\n",
            "[Epoch 183/200] [Batch 97/200] [D loss: 0.000093] [G loss: 0.015326]\n",
            "[Epoch 183/200] [Batch 98/200] [D loss: 0.000189] [G loss: 0.021400]\n",
            "[Epoch 183/200] [Batch 99/200] [D loss: 0.000085] [G loss: 0.018631]\n",
            "[Epoch 183/200] [Batch 100/200] [D loss: 0.000183] [G loss: 0.018810]\n",
            "[Epoch 183/200] [Batch 101/200] [D loss: 0.000191] [G loss: 0.018724]\n",
            "[Epoch 183/200] [Batch 102/200] [D loss: 0.000075] [G loss: 0.014840]\n",
            "[Epoch 183/200] [Batch 103/200] [D loss: 0.000080] [G loss: 0.015258]\n",
            "[Epoch 183/200] [Batch 104/200] [D loss: 0.000107] [G loss: 0.019147]\n",
            "[Epoch 183/200] [Batch 105/200] [D loss: 0.000110] [G loss: 0.022158]\n",
            "[Epoch 183/200] [Batch 106/200] [D loss: 0.000146] [G loss: 0.018385]\n",
            "[Epoch 183/200] [Batch 107/200] [D loss: 0.000112] [G loss: 0.018652]\n",
            "[Epoch 183/200] [Batch 108/200] [D loss: 0.000114] [G loss: 0.017525]\n",
            "[Epoch 183/200] [Batch 109/200] [D loss: 0.000111] [G loss: 0.016232]\n",
            "[Epoch 183/200] [Batch 110/200] [D loss: 0.000105] [G loss: 0.016415]\n",
            "[Epoch 183/200] [Batch 111/200] [D loss: 0.000158] [G loss: 0.018625]\n",
            "[Epoch 183/200] [Batch 112/200] [D loss: 0.000161] [G loss: 0.012955]\n",
            "[Epoch 183/200] [Batch 113/200] [D loss: 0.000116] [G loss: 0.018459]\n",
            "[Epoch 183/200] [Batch 114/200] [D loss: 0.000084] [G loss: 0.015631]\n",
            "[Epoch 183/200] [Batch 115/200] [D loss: 0.000072] [G loss: 0.017089]\n",
            "[Epoch 183/200] [Batch 116/200] [D loss: 0.000057] [G loss: 0.016396]\n",
            "[Epoch 183/200] [Batch 117/200] [D loss: 0.000194] [G loss: 0.019747]\n",
            "[Epoch 183/200] [Batch 118/200] [D loss: 0.000143] [G loss: 0.016096]\n",
            "[Epoch 183/200] [Batch 119/200] [D loss: 0.000076] [G loss: 0.020305]\n",
            "[Epoch 183/200] [Batch 120/200] [D loss: 0.000142] [G loss: 0.018701]\n",
            "[Epoch 183/200] [Batch 121/200] [D loss: 0.000176] [G loss: 0.013698]\n",
            "[Epoch 183/200] [Batch 122/200] [D loss: 0.000118] [G loss: 0.017229]\n",
            "[Epoch 183/200] [Batch 123/200] [D loss: 0.000083] [G loss: 0.019165]\n",
            "[Epoch 183/200] [Batch 124/200] [D loss: 0.000247] [G loss: 0.022282]\n",
            "[Epoch 183/200] [Batch 125/200] [D loss: 0.000242] [G loss: 0.021579]\n",
            "[Epoch 183/200] [Batch 126/200] [D loss: 0.000154] [G loss: 0.017283]\n",
            "[Epoch 183/200] [Batch 127/200] [D loss: 0.000093] [G loss: 0.014883]\n",
            "[Epoch 183/200] [Batch 128/200] [D loss: 0.000118] [G loss: 0.018778]\n",
            "[Epoch 183/200] [Batch 129/200] [D loss: 0.000183] [G loss: 0.013379]\n",
            "[Epoch 183/200] [Batch 130/200] [D loss: 0.000122] [G loss: 0.014272]\n",
            "[Epoch 183/200] [Batch 131/200] [D loss: 0.000196] [G loss: 0.019521]\n",
            "[Epoch 183/200] [Batch 132/200] [D loss: 0.000300] [G loss: 0.018987]\n",
            "[Epoch 183/200] [Batch 133/200] [D loss: 0.000572] [G loss: 0.013235]\n",
            "[Epoch 183/200] [Batch 134/200] [D loss: 0.000768] [G loss: 0.019279]\n",
            "[Epoch 183/200] [Batch 135/200] [D loss: 0.000168] [G loss: 0.017209]\n",
            "[Epoch 183/200] [Batch 136/200] [D loss: 0.000540] [G loss: 0.019349]\n",
            "[Epoch 183/200] [Batch 137/200] [D loss: 0.000279] [G loss: 0.016891]\n",
            "[Epoch 183/200] [Batch 138/200] [D loss: 0.000152] [G loss: 0.017293]\n",
            "[Epoch 183/200] [Batch 139/200] [D loss: 0.000159] [G loss: 0.022285]\n",
            "[Epoch 183/200] [Batch 140/200] [D loss: 0.000162] [G loss: 0.016143]\n",
            "[Epoch 183/200] [Batch 141/200] [D loss: 0.000135] [G loss: 0.013298]\n",
            "[Epoch 183/200] [Batch 142/200] [D loss: 0.000106] [G loss: 0.020326]\n",
            "[Epoch 183/200] [Batch 143/200] [D loss: 0.000053] [G loss: 0.016246]\n",
            "[Epoch 183/200] [Batch 144/200] [D loss: 0.000063] [G loss: 0.017332]\n",
            "[Epoch 183/200] [Batch 145/200] [D loss: 0.000060] [G loss: 0.018030]\n",
            "[Epoch 183/200] [Batch 146/200] [D loss: 0.000083] [G loss: 0.017823]\n",
            "[Epoch 183/200] [Batch 147/200] [D loss: 0.000095] [G loss: 0.019093]\n",
            "[Epoch 183/200] [Batch 148/200] [D loss: 0.000112] [G loss: 0.019141]\n",
            "[Epoch 183/200] [Batch 149/200] [D loss: 0.000087] [G loss: 0.018648]\n",
            "[Epoch 183/200] [Batch 150/200] [D loss: 0.000143] [G loss: 0.020022]\n",
            "[Epoch 183/200] [Batch 151/200] [D loss: 0.000302] [G loss: 0.017067]\n",
            "[Epoch 183/200] [Batch 152/200] [D loss: 0.000240] [G loss: 0.018796]\n",
            "[Epoch 183/200] [Batch 153/200] [D loss: 0.000219] [G loss: 0.015173]\n",
            "[Epoch 183/200] [Batch 154/200] [D loss: 0.000190] [G loss: 0.015436]\n",
            "[Epoch 183/200] [Batch 155/200] [D loss: 0.000108] [G loss: 0.019155]\n",
            "[Epoch 183/200] [Batch 156/200] [D loss: 0.000087] [G loss: 0.020152]\n",
            "[Epoch 183/200] [Batch 157/200] [D loss: 0.000073] [G loss: 0.015953]\n",
            "[Epoch 183/200] [Batch 158/200] [D loss: 0.000092] [G loss: 0.019731]\n",
            "[Epoch 183/200] [Batch 159/200] [D loss: 0.000096] [G loss: 0.018102]\n",
            "[Epoch 183/200] [Batch 160/200] [D loss: 0.000160] [G loss: 0.015800]\n",
            "[Epoch 183/200] [Batch 161/200] [D loss: 0.000220] [G loss: 0.018994]\n",
            "[Epoch 183/200] [Batch 162/200] [D loss: 0.000200] [G loss: 0.016225]\n",
            "[Epoch 183/200] [Batch 163/200] [D loss: 0.000222] [G loss: 0.019560]\n",
            "[Epoch 183/200] [Batch 164/200] [D loss: 0.000085] [G loss: 0.019951]\n",
            "[Epoch 183/200] [Batch 165/200] [D loss: 0.000055] [G loss: 0.013874]\n",
            "[Epoch 183/200] [Batch 166/200] [D loss: 0.000082] [G loss: 0.016676]\n",
            "[Epoch 183/200] [Batch 167/200] [D loss: 0.000247] [G loss: 0.016255]\n",
            "[Epoch 183/200] [Batch 168/200] [D loss: 0.000500] [G loss: 0.019719]\n",
            "[Epoch 183/200] [Batch 169/200] [D loss: 0.000482] [G loss: 0.017656]\n",
            "[Epoch 183/200] [Batch 170/200] [D loss: 0.000293] [G loss: 0.014107]\n",
            "[Epoch 183/200] [Batch 171/200] [D loss: 0.000157] [G loss: 0.019150]\n",
            "[Epoch 183/200] [Batch 172/200] [D loss: 0.000085] [G loss: 0.020284]\n",
            "[Epoch 183/200] [Batch 173/200] [D loss: 0.000157] [G loss: 0.019260]\n",
            "[Epoch 183/200] [Batch 174/200] [D loss: 0.000196] [G loss: 0.020245]\n",
            "[Epoch 183/200] [Batch 175/200] [D loss: 0.000111] [G loss: 0.018569]\n",
            "[Epoch 183/200] [Batch 176/200] [D loss: 0.000362] [G loss: 0.016976]\n",
            "[Epoch 183/200] [Batch 177/200] [D loss: 0.000735] [G loss: 0.019910]\n",
            "[Epoch 183/200] [Batch 178/200] [D loss: 0.000280] [G loss: 0.016111]\n",
            "[Epoch 183/200] [Batch 179/200] [D loss: 0.000266] [G loss: 0.018079]\n",
            "[Epoch 183/200] [Batch 180/200] [D loss: 0.000269] [G loss: 0.018568]\n",
            "[Epoch 183/200] [Batch 181/200] [D loss: 0.000168] [G loss: 0.020188]\n",
            "[Epoch 183/200] [Batch 182/200] [D loss: 0.000379] [G loss: 0.016860]\n",
            "[Epoch 183/200] [Batch 183/200] [D loss: 0.000191] [G loss: 0.020228]\n",
            "[Epoch 183/200] [Batch 184/200] [D loss: 0.000136] [G loss: 0.017730]\n",
            "[Epoch 183/200] [Batch 185/200] [D loss: 0.000126] [G loss: 0.018794]\n",
            "[Epoch 183/200] [Batch 186/200] [D loss: 0.000120] [G loss: 0.019826]\n",
            "[Epoch 183/200] [Batch 187/200] [D loss: 0.000158] [G loss: 0.015245]\n",
            "[Epoch 183/200] [Batch 188/200] [D loss: 0.000385] [G loss: 0.016336]\n",
            "[Epoch 183/200] [Batch 189/200] [D loss: 0.000522] [G loss: 0.017758]\n",
            "[Epoch 183/200] [Batch 190/200] [D loss: 0.000318] [G loss: 0.020557]\n",
            "[Epoch 183/200] [Batch 191/200] [D loss: 0.000209] [G loss: 0.017304]\n",
            "[Epoch 183/200] [Batch 192/200] [D loss: 0.000253] [G loss: 0.015352]\n",
            "[Epoch 183/200] [Batch 193/200] [D loss: 0.000308] [G loss: 0.015678]\n",
            "[Epoch 183/200] [Batch 194/200] [D loss: 0.000138] [G loss: 0.017475]\n",
            "[Epoch 183/200] [Batch 195/200] [D loss: 0.000344] [G loss: 0.015328]\n",
            "[Epoch 183/200] [Batch 196/200] [D loss: 0.000129] [G loss: 0.021102]\n",
            "[Epoch 183/200] [Batch 197/200] [D loss: 0.000232] [G loss: 0.018144]\n",
            "[Epoch 183/200] [Batch 198/200] [D loss: 0.000195] [G loss: 0.014995]\n",
            "[Epoch 183/200] [Batch 199/200] [D loss: 0.000136] [G loss: 0.021558]\n",
            "[Epoch 184/200] [Batch 0/200] [D loss: 0.000118] [G loss: 0.016807]\n",
            "[Epoch 184/200] [Batch 1/200] [D loss: 0.000154] [G loss: 0.017388]\n",
            "[Epoch 184/200] [Batch 2/200] [D loss: 0.000107] [G loss: 0.019579]\n",
            "[Epoch 184/200] [Batch 3/200] [D loss: 0.000067] [G loss: 0.020810]\n",
            "[Epoch 184/200] [Batch 4/200] [D loss: 0.000277] [G loss: 0.019479]\n",
            "[Epoch 184/200] [Batch 5/200] [D loss: 0.000609] [G loss: 0.020656]\n",
            "[Epoch 184/200] [Batch 6/200] [D loss: 0.000519] [G loss: 0.018384]\n",
            "[Epoch 184/200] [Batch 7/200] [D loss: 0.000394] [G loss: 0.015343]\n",
            "[Epoch 184/200] [Batch 8/200] [D loss: 0.000162] [G loss: 0.017004]\n",
            "[Epoch 184/200] [Batch 9/200] [D loss: 0.000086] [G loss: 0.016257]\n",
            "[Epoch 184/200] [Batch 10/200] [D loss: 0.000161] [G loss: 0.017406]\n",
            "[Epoch 184/200] [Batch 11/200] [D loss: 0.000219] [G loss: 0.017440]\n",
            "[Epoch 184/200] [Batch 12/200] [D loss: 0.000096] [G loss: 0.018739]\n",
            "[Epoch 184/200] [Batch 13/200] [D loss: 0.000158] [G loss: 0.018137]\n",
            "[Epoch 184/200] [Batch 14/200] [D loss: 0.000638] [G loss: 0.019335]\n",
            "[Epoch 184/200] [Batch 15/200] [D loss: 0.000408] [G loss: 0.020099]\n",
            "[Epoch 184/200] [Batch 16/200] [D loss: 0.000093] [G loss: 0.018866]\n",
            "[Epoch 184/200] [Batch 17/200] [D loss: 0.000199] [G loss: 0.019204]\n",
            "[Epoch 184/200] [Batch 18/200] [D loss: 0.000135] [G loss: 0.016670]\n",
            "[Epoch 184/200] [Batch 19/200] [D loss: 0.000117] [G loss: 0.019653]\n",
            "[Epoch 184/200] [Batch 20/200] [D loss: 0.000125] [G loss: 0.021199]\n",
            "[Epoch 184/200] [Batch 21/200] [D loss: 0.000137] [G loss: 0.019004]\n",
            "[Epoch 184/200] [Batch 22/200] [D loss: 0.000116] [G loss: 0.013333]\n",
            "[Epoch 184/200] [Batch 23/200] [D loss: 0.000083] [G loss: 0.016354]\n",
            "[Epoch 184/200] [Batch 24/200] [D loss: 0.000118] [G loss: 0.020809]\n",
            "[Epoch 184/200] [Batch 25/200] [D loss: 0.000220] [G loss: 0.015619]\n",
            "[Epoch 184/200] [Batch 26/200] [D loss: 0.000175] [G loss: 0.016294]\n",
            "[Epoch 184/200] [Batch 27/200] [D loss: 0.000114] [G loss: 0.016558]\n",
            "[Epoch 184/200] [Batch 28/200] [D loss: 0.000106] [G loss: 0.016130]\n",
            "[Epoch 184/200] [Batch 29/200] [D loss: 0.000166] [G loss: 0.014711]\n",
            "[Epoch 184/200] [Batch 30/200] [D loss: 0.000171] [G loss: 0.018471]\n",
            "[Epoch 184/200] [Batch 31/200] [D loss: 0.000142] [G loss: 0.015867]\n",
            "[Epoch 184/200] [Batch 32/200] [D loss: 0.000162] [G loss: 0.021224]\n",
            "[Epoch 184/200] [Batch 33/200] [D loss: 0.000064] [G loss: 0.017164]\n",
            "[Epoch 184/200] [Batch 34/200] [D loss: 0.000084] [G loss: 0.020322]\n",
            "[Epoch 184/200] [Batch 35/200] [D loss: 0.000101] [G loss: 0.016590]\n",
            "[Epoch 184/200] [Batch 36/200] [D loss: 0.000098] [G loss: 0.018366]\n",
            "[Epoch 184/200] [Batch 37/200] [D loss: 0.000199] [G loss: 0.012692]\n",
            "[Epoch 184/200] [Batch 38/200] [D loss: 0.000307] [G loss: 0.020693]\n",
            "[Epoch 184/200] [Batch 39/200] [D loss: 0.000418] [G loss: 0.012780]\n",
            "[Epoch 184/200] [Batch 40/200] [D loss: 0.000412] [G loss: 0.015419]\n",
            "[Epoch 184/200] [Batch 41/200] [D loss: 0.000214] [G loss: 0.018573]\n",
            "[Epoch 184/200] [Batch 42/200] [D loss: 0.000142] [G loss: 0.016447]\n",
            "[Epoch 184/200] [Batch 43/200] [D loss: 0.000127] [G loss: 0.018600]\n",
            "[Epoch 184/200] [Batch 44/200] [D loss: 0.000104] [G loss: 0.019499]\n",
            "[Epoch 184/200] [Batch 45/200] [D loss: 0.000157] [G loss: 0.019400]\n",
            "[Epoch 184/200] [Batch 46/200] [D loss: 0.000254] [G loss: 0.017482]\n",
            "[Epoch 184/200] [Batch 47/200] [D loss: 0.000436] [G loss: 0.017119]\n",
            "[Epoch 184/200] [Batch 48/200] [D loss: 0.000255] [G loss: 0.016408]\n",
            "[Epoch 184/200] [Batch 49/200] [D loss: 0.000104] [G loss: 0.019741]\n",
            "[Epoch 184/200] [Batch 50/200] [D loss: 0.000097] [G loss: 0.016806]\n",
            "[Epoch 184/200] [Batch 51/200] [D loss: 0.000112] [G loss: 0.018341]\n",
            "[Epoch 184/200] [Batch 52/200] [D loss: 0.000072] [G loss: 0.018473]\n",
            "[Epoch 184/200] [Batch 53/200] [D loss: 0.000114] [G loss: 0.017624]\n",
            "[Epoch 184/200] [Batch 54/200] [D loss: 0.000071] [G loss: 0.017464]\n",
            "[Epoch 184/200] [Batch 55/200] [D loss: 0.000086] [G loss: 0.015000]\n",
            "[Epoch 184/200] [Batch 56/200] [D loss: 0.000153] [G loss: 0.021032]\n",
            "[Epoch 184/200] [Batch 57/200] [D loss: 0.000161] [G loss: 0.014793]\n",
            "[Epoch 184/200] [Batch 58/200] [D loss: 0.000204] [G loss: 0.017511]\n",
            "[Epoch 184/200] [Batch 59/200] [D loss: 0.000265] [G loss: 0.016042]\n",
            "[Epoch 184/200] [Batch 60/200] [D loss: 0.000139] [G loss: 0.018417]\n",
            "[Epoch 184/200] [Batch 61/200] [D loss: 0.000145] [G loss: 0.019962]\n",
            "[Epoch 184/200] [Batch 62/200] [D loss: 0.000189] [G loss: 0.017220]\n",
            "[Epoch 184/200] [Batch 63/200] [D loss: 0.000086] [G loss: 0.016453]\n",
            "[Epoch 184/200] [Batch 64/200] [D loss: 0.000075] [G loss: 0.020442]\n",
            "[Epoch 184/200] [Batch 65/200] [D loss: 0.000159] [G loss: 0.019673]\n",
            "[Epoch 184/200] [Batch 66/200] [D loss: 0.000138] [G loss: 0.016364]\n",
            "[Epoch 184/200] [Batch 67/200] [D loss: 0.000058] [G loss: 0.018519]\n",
            "[Epoch 184/200] [Batch 68/200] [D loss: 0.000103] [G loss: 0.019729]\n",
            "[Epoch 184/200] [Batch 69/200] [D loss: 0.000174] [G loss: 0.018609]\n",
            "[Epoch 184/200] [Batch 70/200] [D loss: 0.000217] [G loss: 0.019634]\n",
            "[Epoch 184/200] [Batch 71/200] [D loss: 0.000237] [G loss: 0.014162]\n",
            "[Epoch 184/200] [Batch 72/200] [D loss: 0.000169] [G loss: 0.022578]\n",
            "[Epoch 184/200] [Batch 73/200] [D loss: 0.000137] [G loss: 0.017517]\n",
            "[Epoch 184/200] [Batch 74/200] [D loss: 0.000113] [G loss: 0.019163]\n",
            "[Epoch 184/200] [Batch 75/200] [D loss: 0.000077] [G loss: 0.016498]\n",
            "[Epoch 184/200] [Batch 76/200] [D loss: 0.000077] [G loss: 0.016707]\n",
            "[Epoch 184/200] [Batch 77/200] [D loss: 0.000115] [G loss: 0.015482]\n",
            "[Epoch 184/200] [Batch 78/200] [D loss: 0.000612] [G loss: 0.014314]\n",
            "[Epoch 184/200] [Batch 79/200] [D loss: 0.001544] [G loss: 0.017782]\n",
            "[Epoch 184/200] [Batch 80/200] [D loss: 0.002088] [G loss: 0.012328]\n",
            "[Epoch 184/200] [Batch 81/200] [D loss: 0.000988] [G loss: 0.020835]\n",
            "[Epoch 184/200] [Batch 82/200] [D loss: 0.000958] [G loss: 0.014612]\n",
            "[Epoch 184/200] [Batch 83/200] [D loss: 0.000999] [G loss: 0.018049]\n",
            "[Epoch 184/200] [Batch 84/200] [D loss: 0.000610] [G loss: 0.017264]\n",
            "[Epoch 184/200] [Batch 85/200] [D loss: 0.000433] [G loss: 0.019779]\n",
            "[Epoch 184/200] [Batch 86/200] [D loss: 0.000293] [G loss: 0.020489]\n",
            "[Epoch 184/200] [Batch 87/200] [D loss: 0.000206] [G loss: 0.021899]\n",
            "[Epoch 184/200] [Batch 88/200] [D loss: 0.000174] [G loss: 0.019050]\n",
            "[Epoch 184/200] [Batch 89/200] [D loss: 0.000310] [G loss: 0.019672]\n",
            "[Epoch 184/200] [Batch 90/200] [D loss: 0.000143] [G loss: 0.021473]\n",
            "[Epoch 184/200] [Batch 91/200] [D loss: 0.000101] [G loss: 0.015463]\n",
            "[Epoch 184/200] [Batch 92/200] [D loss: 0.000104] [G loss: 0.015811]\n",
            "[Epoch 184/200] [Batch 93/200] [D loss: 0.000346] [G loss: 0.017200]\n",
            "[Epoch 184/200] [Batch 94/200] [D loss: 0.000766] [G loss: 0.020932]\n",
            "[Epoch 184/200] [Batch 95/200] [D loss: 0.000242] [G loss: 0.018243]\n",
            "[Epoch 184/200] [Batch 96/200] [D loss: 0.000327] [G loss: 0.014028]\n",
            "[Epoch 184/200] [Batch 97/200] [D loss: 0.000610] [G loss: 0.014575]\n",
            "[Epoch 184/200] [Batch 98/200] [D loss: 0.000202] [G loss: 0.016266]\n",
            "[Epoch 184/200] [Batch 99/200] [D loss: 0.000145] [G loss: 0.015354]\n",
            "[Epoch 184/200] [Batch 100/200] [D loss: 0.000696] [G loss: 0.017719]\n",
            "[Epoch 184/200] [Batch 101/200] [D loss: 0.001087] [G loss: 0.015525]\n",
            "[Epoch 184/200] [Batch 102/200] [D loss: 0.000605] [G loss: 0.019586]\n",
            "[Epoch 184/200] [Batch 103/200] [D loss: 0.000917] [G loss: 0.018641]\n",
            "[Epoch 184/200] [Batch 104/200] [D loss: 0.002108] [G loss: 0.019674]\n",
            "[Epoch 184/200] [Batch 105/200] [D loss: 0.000816] [G loss: 0.017670]\n",
            "[Epoch 184/200] [Batch 106/200] [D loss: 0.000839] [G loss: 0.020582]\n",
            "[Epoch 184/200] [Batch 107/200] [D loss: 0.000670] [G loss: 0.017686]\n",
            "[Epoch 184/200] [Batch 108/200] [D loss: 0.000312] [G loss: 0.019046]\n",
            "[Epoch 184/200] [Batch 109/200] [D loss: 0.000409] [G loss: 0.019219]\n",
            "[Epoch 184/200] [Batch 110/200] [D loss: 0.000454] [G loss: 0.016980]\n",
            "[Epoch 184/200] [Batch 111/200] [D loss: 0.000218] [G loss: 0.014944]\n",
            "[Epoch 184/200] [Batch 112/200] [D loss: 0.000174] [G loss: 0.015186]\n",
            "[Epoch 184/200] [Batch 113/200] [D loss: 0.000164] [G loss: 0.022858]\n",
            "[Epoch 184/200] [Batch 114/200] [D loss: 0.000147] [G loss: 0.019240]\n",
            "[Epoch 184/200] [Batch 115/200] [D loss: 0.000179] [G loss: 0.020233]\n",
            "[Epoch 184/200] [Batch 116/200] [D loss: 0.000103] [G loss: 0.017199]\n",
            "[Epoch 184/200] [Batch 117/200] [D loss: 0.000177] [G loss: 0.016262]\n",
            "[Epoch 184/200] [Batch 118/200] [D loss: 0.000099] [G loss: 0.014926]\n",
            "[Epoch 184/200] [Batch 119/200] [D loss: 0.000052] [G loss: 0.016369]\n",
            "[Epoch 184/200] [Batch 120/200] [D loss: 0.000066] [G loss: 0.017352]\n",
            "[Epoch 184/200] [Batch 121/200] [D loss: 0.000114] [G loss: 0.018515]\n",
            "[Epoch 184/200] [Batch 122/200] [D loss: 0.000249] [G loss: 0.016172]\n",
            "[Epoch 184/200] [Batch 123/200] [D loss: 0.000313] [G loss: 0.018144]\n",
            "[Epoch 184/200] [Batch 124/200] [D loss: 0.000250] [G loss: 0.017475]\n",
            "[Epoch 184/200] [Batch 125/200] [D loss: 0.000222] [G loss: 0.019434]\n",
            "[Epoch 184/200] [Batch 126/200] [D loss: 0.000220] [G loss: 0.017131]\n",
            "[Epoch 184/200] [Batch 127/200] [D loss: 0.000239] [G loss: 0.011994]\n",
            "[Epoch 184/200] [Batch 128/200] [D loss: 0.000341] [G loss: 0.014273]\n",
            "[Epoch 184/200] [Batch 129/200] [D loss: 0.000778] [G loss: 0.014801]\n",
            "[Epoch 184/200] [Batch 130/200] [D loss: 0.000391] [G loss: 0.019107]\n",
            "[Epoch 184/200] [Batch 131/200] [D loss: 0.000935] [G loss: 0.016572]\n",
            "[Epoch 184/200] [Batch 132/200] [D loss: 0.000658] [G loss: 0.018520]\n",
            "[Epoch 184/200] [Batch 133/200] [D loss: 0.000571] [G loss: 0.016578]\n",
            "[Epoch 184/200] [Batch 134/200] [D loss: 0.000621] [G loss: 0.013023]\n",
            "[Epoch 184/200] [Batch 135/200] [D loss: 0.000294] [G loss: 0.015373]\n",
            "[Epoch 184/200] [Batch 136/200] [D loss: 0.000364] [G loss: 0.020481]\n",
            "[Epoch 184/200] [Batch 137/200] [D loss: 0.000215] [G loss: 0.020408]\n",
            "[Epoch 184/200] [Batch 138/200] [D loss: 0.000132] [G loss: 0.019350]\n",
            "[Epoch 184/200] [Batch 139/200] [D loss: 0.000102] [G loss: 0.016799]\n",
            "[Epoch 184/200] [Batch 140/200] [D loss: 0.000264] [G loss: 0.017516]\n",
            "[Epoch 184/200] [Batch 141/200] [D loss: 0.000265] [G loss: 0.018479]\n",
            "[Epoch 184/200] [Batch 142/200] [D loss: 0.000169] [G loss: 0.022460]\n",
            "[Epoch 184/200] [Batch 143/200] [D loss: 0.000106] [G loss: 0.013522]\n",
            "[Epoch 184/200] [Batch 144/200] [D loss: 0.000088] [G loss: 0.017044]\n",
            "[Epoch 184/200] [Batch 145/200] [D loss: 0.000044] [G loss: 0.018651]\n",
            "[Epoch 184/200] [Batch 146/200] [D loss: 0.000071] [G loss: 0.018453]\n",
            "[Epoch 184/200] [Batch 147/200] [D loss: 0.000055] [G loss: 0.016762]\n",
            "[Epoch 184/200] [Batch 148/200] [D loss: 0.000063] [G loss: 0.016487]\n",
            "[Epoch 184/200] [Batch 149/200] [D loss: 0.000082] [G loss: 0.017071]\n",
            "[Epoch 184/200] [Batch 150/200] [D loss: 0.000083] [G loss: 0.015739]\n",
            "[Epoch 184/200] [Batch 151/200] [D loss: 0.000086] [G loss: 0.016110]\n",
            "[Epoch 184/200] [Batch 152/200] [D loss: 0.000084] [G loss: 0.015238]\n",
            "[Epoch 184/200] [Batch 153/200] [D loss: 0.000147] [G loss: 0.017928]\n",
            "[Epoch 184/200] [Batch 154/200] [D loss: 0.000119] [G loss: 0.016610]\n",
            "[Epoch 184/200] [Batch 155/200] [D loss: 0.000078] [G loss: 0.019712]\n",
            "[Epoch 184/200] [Batch 156/200] [D loss: 0.000056] [G loss: 0.017969]\n",
            "[Epoch 184/200] [Batch 157/200] [D loss: 0.000040] [G loss: 0.018936]\n",
            "[Epoch 184/200] [Batch 158/200] [D loss: 0.000061] [G loss: 0.016896]\n",
            "[Epoch 184/200] [Batch 159/200] [D loss: 0.000080] [G loss: 0.016216]\n",
            "[Epoch 184/200] [Batch 160/200] [D loss: 0.000052] [G loss: 0.017992]\n",
            "[Epoch 184/200] [Batch 161/200] [D loss: 0.000075] [G loss: 0.019118]\n",
            "[Epoch 184/200] [Batch 162/200] [D loss: 0.000051] [G loss: 0.012692]\n",
            "[Epoch 184/200] [Batch 163/200] [D loss: 0.000077] [G loss: 0.017613]\n",
            "[Epoch 184/200] [Batch 164/200] [D loss: 0.000070] [G loss: 0.015543]\n",
            "[Epoch 184/200] [Batch 165/200] [D loss: 0.000049] [G loss: 0.015621]\n",
            "[Epoch 184/200] [Batch 166/200] [D loss: 0.000082] [G loss: 0.019763]\n",
            "[Epoch 184/200] [Batch 167/200] [D loss: 0.000119] [G loss: 0.017068]\n",
            "[Epoch 184/200] [Batch 168/200] [D loss: 0.000142] [G loss: 0.019182]\n",
            "[Epoch 184/200] [Batch 169/200] [D loss: 0.000152] [G loss: 0.018561]\n",
            "[Epoch 184/200] [Batch 170/200] [D loss: 0.000165] [G loss: 0.015506]\n",
            "[Epoch 184/200] [Batch 171/200] [D loss: 0.000206] [G loss: 0.021204]\n",
            "[Epoch 184/200] [Batch 172/200] [D loss: 0.000179] [G loss: 0.018919]\n",
            "[Epoch 184/200] [Batch 173/200] [D loss: 0.000161] [G loss: 0.016024]\n",
            "[Epoch 184/200] [Batch 174/200] [D loss: 0.000161] [G loss: 0.018556]\n",
            "[Epoch 184/200] [Batch 175/200] [D loss: 0.000112] [G loss: 0.018658]\n",
            "[Epoch 184/200] [Batch 176/200] [D loss: 0.000104] [G loss: 0.014603]\n",
            "[Epoch 184/200] [Batch 177/200] [D loss: 0.000141] [G loss: 0.014823]\n",
            "[Epoch 184/200] [Batch 178/200] [D loss: 0.000364] [G loss: 0.021421]\n",
            "[Epoch 184/200] [Batch 179/200] [D loss: 0.000295] [G loss: 0.014186]\n",
            "[Epoch 184/200] [Batch 180/200] [D loss: 0.000182] [G loss: 0.013233]\n",
            "[Epoch 184/200] [Batch 181/200] [D loss: 0.000109] [G loss: 0.020139]\n",
            "[Epoch 184/200] [Batch 182/200] [D loss: 0.000108] [G loss: 0.016984]\n",
            "[Epoch 184/200] [Batch 183/200] [D loss: 0.000088] [G loss: 0.016924]\n",
            "[Epoch 184/200] [Batch 184/200] [D loss: 0.000152] [G loss: 0.017761]\n",
            "[Epoch 184/200] [Batch 185/200] [D loss: 0.000084] [G loss: 0.014222]\n",
            "[Epoch 184/200] [Batch 186/200] [D loss: 0.000138] [G loss: 0.022456]\n",
            "[Epoch 184/200] [Batch 187/200] [D loss: 0.000191] [G loss: 0.017447]\n",
            "[Epoch 184/200] [Batch 188/200] [D loss: 0.000135] [G loss: 0.022554]\n",
            "[Epoch 184/200] [Batch 189/200] [D loss: 0.000495] [G loss: 0.017766]\n",
            "[Epoch 184/200] [Batch 190/200] [D loss: 0.001445] [G loss: 0.016712]\n",
            "[Epoch 184/200] [Batch 191/200] [D loss: 0.002053] [G loss: 0.022307]\n",
            "[Epoch 184/200] [Batch 192/200] [D loss: 0.000692] [G loss: 0.015462]\n",
            "[Epoch 184/200] [Batch 193/200] [D loss: 0.000456] [G loss: 0.018501]\n",
            "[Epoch 184/200] [Batch 194/200] [D loss: 0.000264] [G loss: 0.017984]\n",
            "[Epoch 184/200] [Batch 195/200] [D loss: 0.000143] [G loss: 0.016208]\n",
            "[Epoch 184/200] [Batch 196/200] [D loss: 0.000380] [G loss: 0.016870]\n",
            "[Epoch 184/200] [Batch 197/200] [D loss: 0.000146] [G loss: 0.016607]\n",
            "[Epoch 184/200] [Batch 198/200] [D loss: 0.000122] [G loss: 0.019538]\n",
            "[Epoch 184/200] [Batch 199/200] [D loss: 0.000100] [G loss: 0.018366]\n",
            "[Epoch 185/200] [Batch 0/200] [D loss: 0.000145] [G loss: 0.019163]\n",
            "[Epoch 185/200] [Batch 1/200] [D loss: 0.000182] [G loss: 0.016870]\n",
            "[Epoch 185/200] [Batch 2/200] [D loss: 0.000153] [G loss: 0.016701]\n",
            "[Epoch 185/200] [Batch 3/200] [D loss: 0.000189] [G loss: 0.013738]\n",
            "[Epoch 185/200] [Batch 4/200] [D loss: 0.000274] [G loss: 0.013329]\n",
            "[Epoch 185/200] [Batch 5/200] [D loss: 0.000114] [G loss: 0.014239]\n",
            "[Epoch 185/200] [Batch 6/200] [D loss: 0.000175] [G loss: 0.018743]\n",
            "[Epoch 185/200] [Batch 7/200] [D loss: 0.000428] [G loss: 0.019557]\n",
            "[Epoch 185/200] [Batch 8/200] [D loss: 0.000403] [G loss: 0.017957]\n",
            "[Epoch 185/200] [Batch 9/200] [D loss: 0.000224] [G loss: 0.019604]\n",
            "[Epoch 185/200] [Batch 10/200] [D loss: 0.000136] [G loss: 0.018122]\n",
            "[Epoch 185/200] [Batch 11/200] [D loss: 0.000152] [G loss: 0.018167]\n",
            "[Epoch 185/200] [Batch 12/200] [D loss: 0.000111] [G loss: 0.014629]\n",
            "[Epoch 185/200] [Batch 13/200] [D loss: 0.000168] [G loss: 0.016631]\n",
            "[Epoch 185/200] [Batch 14/200] [D loss: 0.000177] [G loss: 0.019058]\n",
            "[Epoch 185/200] [Batch 15/200] [D loss: 0.000190] [G loss: 0.016620]\n",
            "[Epoch 185/200] [Batch 16/200] [D loss: 0.000352] [G loss: 0.016868]\n",
            "[Epoch 185/200] [Batch 17/200] [D loss: 0.000600] [G loss: 0.014610]\n",
            "[Epoch 185/200] [Batch 18/200] [D loss: 0.000479] [G loss: 0.014411]\n",
            "[Epoch 185/200] [Batch 19/200] [D loss: 0.000540] [G loss: 0.020122]\n",
            "[Epoch 185/200] [Batch 20/200] [D loss: 0.000500] [G loss: 0.019781]\n",
            "[Epoch 185/200] [Batch 21/200] [D loss: 0.000262] [G loss: 0.013947]\n",
            "[Epoch 185/200] [Batch 22/200] [D loss: 0.000285] [G loss: 0.017004]\n",
            "[Epoch 185/200] [Batch 23/200] [D loss: 0.000128] [G loss: 0.016486]\n",
            "[Epoch 185/200] [Batch 24/200] [D loss: 0.000256] [G loss: 0.021475]\n",
            "[Epoch 185/200] [Batch 25/200] [D loss: 0.000359] [G loss: 0.014216]\n",
            "[Epoch 185/200] [Batch 26/200] [D loss: 0.000226] [G loss: 0.015776]\n",
            "[Epoch 185/200] [Batch 27/200] [D loss: 0.000309] [G loss: 0.014533]\n",
            "[Epoch 185/200] [Batch 28/200] [D loss: 0.000523] [G loss: 0.016664]\n",
            "[Epoch 185/200] [Batch 29/200] [D loss: 0.001010] [G loss: 0.016005]\n",
            "[Epoch 185/200] [Batch 30/200] [D loss: 0.000954] [G loss: 0.019571]\n",
            "[Epoch 185/200] [Batch 31/200] [D loss: 0.000220] [G loss: 0.019169]\n",
            "[Epoch 185/200] [Batch 32/200] [D loss: 0.000167] [G loss: 0.020923]\n",
            "[Epoch 185/200] [Batch 33/200] [D loss: 0.000167] [G loss: 0.017126]\n",
            "[Epoch 185/200] [Batch 34/200] [D loss: 0.000214] [G loss: 0.017753]\n",
            "[Epoch 185/200] [Batch 35/200] [D loss: 0.000281] [G loss: 0.015913]\n",
            "[Epoch 185/200] [Batch 36/200] [D loss: 0.000256] [G loss: 0.019458]\n",
            "[Epoch 185/200] [Batch 37/200] [D loss: 0.000876] [G loss: 0.015576]\n",
            "[Epoch 185/200] [Batch 38/200] [D loss: 0.000941] [G loss: 0.017980]\n",
            "[Epoch 185/200] [Batch 39/200] [D loss: 0.000328] [G loss: 0.017303]\n",
            "[Epoch 185/200] [Batch 40/200] [D loss: 0.000283] [G loss: 0.016881]\n",
            "[Epoch 185/200] [Batch 41/200] [D loss: 0.000490] [G loss: 0.019036]\n",
            "[Epoch 185/200] [Batch 42/200] [D loss: 0.000435] [G loss: 0.019576]\n",
            "[Epoch 185/200] [Batch 43/200] [D loss: 0.000905] [G loss: 0.018870]\n",
            "[Epoch 185/200] [Batch 44/200] [D loss: 0.001382] [G loss: 0.018004]\n",
            "[Epoch 185/200] [Batch 45/200] [D loss: 0.000732] [G loss: 0.016093]\n",
            "[Epoch 185/200] [Batch 46/200] [D loss: 0.000414] [G loss: 0.018141]\n",
            "[Epoch 185/200] [Batch 47/200] [D loss: 0.000927] [G loss: 0.020448]\n",
            "[Epoch 185/200] [Batch 48/200] [D loss: 0.000617] [G loss: 0.017081]\n",
            "[Epoch 185/200] [Batch 49/200] [D loss: 0.000190] [G loss: 0.014470]\n",
            "[Epoch 185/200] [Batch 50/200] [D loss: 0.000287] [G loss: 0.017612]\n",
            "[Epoch 185/200] [Batch 51/200] [D loss: 0.000393] [G loss: 0.016745]\n",
            "[Epoch 185/200] [Batch 52/200] [D loss: 0.000216] [G loss: 0.017461]\n",
            "[Epoch 185/200] [Batch 53/200] [D loss: 0.000083] [G loss: 0.019238]\n",
            "[Epoch 185/200] [Batch 54/200] [D loss: 0.000143] [G loss: 0.019826]\n",
            "[Epoch 185/200] [Batch 55/200] [D loss: 0.000217] [G loss: 0.017781]\n",
            "[Epoch 185/200] [Batch 56/200] [D loss: 0.000279] [G loss: 0.017410]\n",
            "[Epoch 185/200] [Batch 57/200] [D loss: 0.000212] [G loss: 0.016591]\n",
            "[Epoch 185/200] [Batch 58/200] [D loss: 0.000274] [G loss: 0.015732]\n",
            "[Epoch 185/200] [Batch 59/200] [D loss: 0.000234] [G loss: 0.017251]\n",
            "[Epoch 185/200] [Batch 60/200] [D loss: 0.000164] [G loss: 0.019731]\n",
            "[Epoch 185/200] [Batch 61/200] [D loss: 0.000231] [G loss: 0.017852]\n",
            "[Epoch 185/200] [Batch 62/200] [D loss: 0.000371] [G loss: 0.021507]\n",
            "[Epoch 185/200] [Batch 63/200] [D loss: 0.000127] [G loss: 0.019658]\n",
            "[Epoch 185/200] [Batch 64/200] [D loss: 0.000160] [G loss: 0.015609]\n",
            "[Epoch 185/200] [Batch 65/200] [D loss: 0.000165] [G loss: 0.018298]\n",
            "[Epoch 185/200] [Batch 66/200] [D loss: 0.000112] [G loss: 0.017824]\n",
            "[Epoch 185/200] [Batch 67/200] [D loss: 0.000085] [G loss: 0.015707]\n",
            "[Epoch 185/200] [Batch 68/200] [D loss: 0.000111] [G loss: 0.019560]\n",
            "[Epoch 185/200] [Batch 69/200] [D loss: 0.000345] [G loss: 0.022727]\n",
            "[Epoch 185/200] [Batch 70/200] [D loss: 0.000280] [G loss: 0.018599]\n",
            "[Epoch 185/200] [Batch 71/200] [D loss: 0.000129] [G loss: 0.021451]\n",
            "[Epoch 185/200] [Batch 72/200] [D loss: 0.000141] [G loss: 0.019570]\n",
            "[Epoch 185/200] [Batch 73/200] [D loss: 0.000325] [G loss: 0.017538]\n",
            "[Epoch 185/200] [Batch 74/200] [D loss: 0.000181] [G loss: 0.016830]\n",
            "[Epoch 185/200] [Batch 75/200] [D loss: 0.000231] [G loss: 0.017699]\n",
            "[Epoch 185/200] [Batch 76/200] [D loss: 0.000190] [G loss: 0.018599]\n",
            "[Epoch 185/200] [Batch 77/200] [D loss: 0.000098] [G loss: 0.014528]\n",
            "[Epoch 185/200] [Batch 78/200] [D loss: 0.000560] [G loss: 0.019148]\n",
            "[Epoch 185/200] [Batch 79/200] [D loss: 0.000979] [G loss: 0.014550]\n",
            "[Epoch 185/200] [Batch 80/200] [D loss: 0.000734] [G loss: 0.020371]\n",
            "[Epoch 185/200] [Batch 81/200] [D loss: 0.000553] [G loss: 0.023037]\n",
            "[Epoch 185/200] [Batch 82/200] [D loss: 0.000288] [G loss: 0.021896]\n",
            "[Epoch 185/200] [Batch 83/200] [D loss: 0.000114] [G loss: 0.016172]\n",
            "[Epoch 185/200] [Batch 84/200] [D loss: 0.000127] [G loss: 0.014955]\n",
            "[Epoch 185/200] [Batch 85/200] [D loss: 0.000174] [G loss: 0.020313]\n",
            "[Epoch 185/200] [Batch 86/200] [D loss: 0.000127] [G loss: 0.018071]\n",
            "[Epoch 185/200] [Batch 87/200] [D loss: 0.000090] [G loss: 0.018854]\n",
            "[Epoch 185/200] [Batch 88/200] [D loss: 0.000173] [G loss: 0.017287]\n",
            "[Epoch 185/200] [Batch 89/200] [D loss: 0.000241] [G loss: 0.014316]\n",
            "[Epoch 185/200] [Batch 90/200] [D loss: 0.000089] [G loss: 0.018428]\n",
            "[Epoch 185/200] [Batch 91/200] [D loss: 0.000154] [G loss: 0.014618]\n",
            "[Epoch 185/200] [Batch 92/200] [D loss: 0.000266] [G loss: 0.020400]\n",
            "[Epoch 185/200] [Batch 93/200] [D loss: 0.000245] [G loss: 0.016687]\n",
            "[Epoch 185/200] [Batch 94/200] [D loss: 0.000171] [G loss: 0.018148]\n",
            "[Epoch 185/200] [Batch 95/200] [D loss: 0.000130] [G loss: 0.017881]\n",
            "[Epoch 185/200] [Batch 96/200] [D loss: 0.000091] [G loss: 0.017605]\n",
            "[Epoch 185/200] [Batch 97/200] [D loss: 0.000141] [G loss: 0.018117]\n",
            "[Epoch 185/200] [Batch 98/200] [D loss: 0.000161] [G loss: 0.016437]\n",
            "[Epoch 185/200] [Batch 99/200] [D loss: 0.000071] [G loss: 0.013205]\n",
            "[Epoch 185/200] [Batch 100/200] [D loss: 0.000108] [G loss: 0.016775]\n",
            "[Epoch 185/200] [Batch 101/200] [D loss: 0.000072] [G loss: 0.016391]\n",
            "[Epoch 185/200] [Batch 102/200] [D loss: 0.000078] [G loss: 0.015152]\n",
            "[Epoch 185/200] [Batch 103/200] [D loss: 0.000061] [G loss: 0.016795]\n",
            "[Epoch 185/200] [Batch 104/200] [D loss: 0.000097] [G loss: 0.016262]\n",
            "[Epoch 185/200] [Batch 105/200] [D loss: 0.000314] [G loss: 0.015523]\n",
            "[Epoch 185/200] [Batch 106/200] [D loss: 0.000345] [G loss: 0.017140]\n",
            "[Epoch 185/200] [Batch 107/200] [D loss: 0.000323] [G loss: 0.017006]\n",
            "[Epoch 185/200] [Batch 108/200] [D loss: 0.000140] [G loss: 0.015159]\n",
            "[Epoch 185/200] [Batch 109/200] [D loss: 0.000126] [G loss: 0.019466]\n",
            "[Epoch 185/200] [Batch 110/200] [D loss: 0.000117] [G loss: 0.017583]\n",
            "[Epoch 185/200] [Batch 111/200] [D loss: 0.000136] [G loss: 0.013322]\n",
            "[Epoch 185/200] [Batch 112/200] [D loss: 0.000303] [G loss: 0.016432]\n",
            "[Epoch 185/200] [Batch 113/200] [D loss: 0.000311] [G loss: 0.017522]\n",
            "[Epoch 185/200] [Batch 114/200] [D loss: 0.000237] [G loss: 0.021433]\n",
            "[Epoch 185/200] [Batch 115/200] [D loss: 0.000081] [G loss: 0.018183]\n",
            "[Epoch 185/200] [Batch 116/200] [D loss: 0.000137] [G loss: 0.018014]\n",
            "[Epoch 185/200] [Batch 117/200] [D loss: 0.000198] [G loss: 0.018006]\n",
            "[Epoch 185/200] [Batch 118/200] [D loss: 0.000240] [G loss: 0.016937]\n",
            "[Epoch 185/200] [Batch 119/200] [D loss: 0.000274] [G loss: 0.017895]\n",
            "[Epoch 185/200] [Batch 120/200] [D loss: 0.000214] [G loss: 0.013885]\n",
            "[Epoch 185/200] [Batch 121/200] [D loss: 0.000122] [G loss: 0.017345]\n",
            "[Epoch 185/200] [Batch 122/200] [D loss: 0.000220] [G loss: 0.020086]\n",
            "[Epoch 185/200] [Batch 123/200] [D loss: 0.000460] [G loss: 0.016487]\n",
            "[Epoch 185/200] [Batch 124/200] [D loss: 0.000208] [G loss: 0.015110]\n",
            "[Epoch 185/200] [Batch 125/200] [D loss: 0.000184] [G loss: 0.019269]\n",
            "[Epoch 185/200] [Batch 126/200] [D loss: 0.000187] [G loss: 0.019181]\n",
            "[Epoch 185/200] [Batch 127/200] [D loss: 0.000067] [G loss: 0.018212]\n",
            "[Epoch 185/200] [Batch 128/200] [D loss: 0.000194] [G loss: 0.018313]\n",
            "[Epoch 185/200] [Batch 129/200] [D loss: 0.000157] [G loss: 0.019322]\n",
            "[Epoch 185/200] [Batch 130/200] [D loss: 0.000270] [G loss: 0.019456]\n",
            "[Epoch 185/200] [Batch 131/200] [D loss: 0.000194] [G loss: 0.018607]\n",
            "[Epoch 185/200] [Batch 132/200] [D loss: 0.000323] [G loss: 0.018699]\n",
            "[Epoch 185/200] [Batch 133/200] [D loss: 0.000145] [G loss: 0.016937]\n",
            "[Epoch 185/200] [Batch 134/200] [D loss: 0.000213] [G loss: 0.017400]\n",
            "[Epoch 185/200] [Batch 135/200] [D loss: 0.000509] [G loss: 0.016773]\n",
            "[Epoch 185/200] [Batch 136/200] [D loss: 0.000535] [G loss: 0.015240]\n",
            "[Epoch 185/200] [Batch 137/200] [D loss: 0.000529] [G loss: 0.020584]\n",
            "[Epoch 185/200] [Batch 138/200] [D loss: 0.000453] [G loss: 0.017203]\n",
            "[Epoch 185/200] [Batch 139/200] [D loss: 0.000184] [G loss: 0.019798]\n",
            "[Epoch 185/200] [Batch 140/200] [D loss: 0.000130] [G loss: 0.018195]\n",
            "[Epoch 185/200] [Batch 141/200] [D loss: 0.000107] [G loss: 0.017382]\n",
            "[Epoch 185/200] [Batch 142/200] [D loss: 0.000107] [G loss: 0.014486]\n",
            "[Epoch 185/200] [Batch 143/200] [D loss: 0.000130] [G loss: 0.020465]\n",
            "[Epoch 185/200] [Batch 144/200] [D loss: 0.000084] [G loss: 0.015739]\n",
            "[Epoch 185/200] [Batch 145/200] [D loss: 0.000095] [G loss: 0.013204]\n",
            "[Epoch 185/200] [Batch 146/200] [D loss: 0.000183] [G loss: 0.020345]\n",
            "[Epoch 185/200] [Batch 147/200] [D loss: 0.000100] [G loss: 0.016400]\n",
            "[Epoch 185/200] [Batch 148/200] [D loss: 0.000091] [G loss: 0.015113]\n",
            "[Epoch 185/200] [Batch 149/200] [D loss: 0.000160] [G loss: 0.019344]\n",
            "[Epoch 185/200] [Batch 150/200] [D loss: 0.000172] [G loss: 0.020018]\n",
            "[Epoch 185/200] [Batch 151/200] [D loss: 0.000110] [G loss: 0.017902]\n",
            "[Epoch 185/200] [Batch 152/200] [D loss: 0.000087] [G loss: 0.020767]\n",
            "[Epoch 185/200] [Batch 153/200] [D loss: 0.000166] [G loss: 0.018461]\n",
            "[Epoch 185/200] [Batch 154/200] [D loss: 0.000119] [G loss: 0.015285]\n",
            "[Epoch 185/200] [Batch 155/200] [D loss: 0.000117] [G loss: 0.016466]\n",
            "[Epoch 185/200] [Batch 156/200] [D loss: 0.000065] [G loss: 0.022148]\n",
            "[Epoch 185/200] [Batch 157/200] [D loss: 0.000072] [G loss: 0.016479]\n",
            "[Epoch 185/200] [Batch 158/200] [D loss: 0.000090] [G loss: 0.017871]\n",
            "[Epoch 185/200] [Batch 159/200] [D loss: 0.000141] [G loss: 0.018670]\n",
            "[Epoch 185/200] [Batch 160/200] [D loss: 0.000088] [G loss: 0.020739]\n",
            "[Epoch 185/200] [Batch 161/200] [D loss: 0.000139] [G loss: 0.017781]\n",
            "[Epoch 185/200] [Batch 162/200] [D loss: 0.000228] [G loss: 0.018486]\n",
            "[Epoch 185/200] [Batch 163/200] [D loss: 0.000179] [G loss: 0.019001]\n",
            "[Epoch 185/200] [Batch 164/200] [D loss: 0.000157] [G loss: 0.018496]\n",
            "[Epoch 185/200] [Batch 165/200] [D loss: 0.000250] [G loss: 0.016415]\n",
            "[Epoch 185/200] [Batch 166/200] [D loss: 0.000164] [G loss: 0.014840]\n",
            "[Epoch 185/200] [Batch 167/200] [D loss: 0.000221] [G loss: 0.016908]\n",
            "[Epoch 185/200] [Batch 168/200] [D loss: 0.000209] [G loss: 0.019693]\n",
            "[Epoch 185/200] [Batch 169/200] [D loss: 0.000123] [G loss: 0.017526]\n",
            "[Epoch 185/200] [Batch 170/200] [D loss: 0.000095] [G loss: 0.015470]\n",
            "[Epoch 185/200] [Batch 171/200] [D loss: 0.000119] [G loss: 0.020837]\n",
            "[Epoch 185/200] [Batch 172/200] [D loss: 0.000079] [G loss: 0.014854]\n",
            "[Epoch 185/200] [Batch 173/200] [D loss: 0.000074] [G loss: 0.017547]\n",
            "[Epoch 185/200] [Batch 174/200] [D loss: 0.000084] [G loss: 0.015040]\n",
            "[Epoch 185/200] [Batch 175/200] [D loss: 0.000215] [G loss: 0.016710]\n",
            "[Epoch 185/200] [Batch 176/200] [D loss: 0.000342] [G loss: 0.015565]\n",
            "[Epoch 185/200] [Batch 177/200] [D loss: 0.000404] [G loss: 0.015228]\n",
            "[Epoch 185/200] [Batch 178/200] [D loss: 0.000741] [G loss: 0.018883]\n",
            "[Epoch 185/200] [Batch 179/200] [D loss: 0.000666] [G loss: 0.025749]\n",
            "[Epoch 185/200] [Batch 180/200] [D loss: 0.000538] [G loss: 0.016792]\n",
            "[Epoch 185/200] [Batch 181/200] [D loss: 0.000397] [G loss: 0.017631]\n",
            "[Epoch 185/200] [Batch 182/200] [D loss: 0.000528] [G loss: 0.020230]\n",
            "[Epoch 185/200] [Batch 183/200] [D loss: 0.000341] [G loss: 0.016062]\n",
            "[Epoch 185/200] [Batch 184/200] [D loss: 0.000308] [G loss: 0.021731]\n",
            "[Epoch 185/200] [Batch 185/200] [D loss: 0.000351] [G loss: 0.017630]\n",
            "[Epoch 185/200] [Batch 186/200] [D loss: 0.000198] [G loss: 0.017372]\n",
            "[Epoch 185/200] [Batch 187/200] [D loss: 0.000199] [G loss: 0.019111]\n",
            "[Epoch 185/200] [Batch 188/200] [D loss: 0.000214] [G loss: 0.020039]\n",
            "[Epoch 185/200] [Batch 189/200] [D loss: 0.000421] [G loss: 0.015738]\n",
            "[Epoch 185/200] [Batch 190/200] [D loss: 0.000838] [G loss: 0.016426]\n",
            "[Epoch 185/200] [Batch 191/200] [D loss: 0.000635] [G loss: 0.017648]\n",
            "[Epoch 185/200] [Batch 192/200] [D loss: 0.000760] [G loss: 0.018927]\n",
            "[Epoch 185/200] [Batch 193/200] [D loss: 0.000249] [G loss: 0.016694]\n",
            "[Epoch 185/200] [Batch 194/200] [D loss: 0.000234] [G loss: 0.017959]\n",
            "[Epoch 185/200] [Batch 195/200] [D loss: 0.000143] [G loss: 0.019150]\n",
            "[Epoch 185/200] [Batch 196/200] [D loss: 0.000120] [G loss: 0.013719]\n",
            "[Epoch 185/200] [Batch 197/200] [D loss: 0.000246] [G loss: 0.017604]\n",
            "[Epoch 185/200] [Batch 198/200] [D loss: 0.000116] [G loss: 0.015841]\n",
            "[Epoch 185/200] [Batch 199/200] [D loss: 0.000276] [G loss: 0.021885]\n",
            "[Epoch 186/200] [Batch 0/200] [D loss: 0.000314] [G loss: 0.019599]\n",
            "[Epoch 186/200] [Batch 1/200] [D loss: 0.000176] [G loss: 0.017093]\n",
            "[Epoch 186/200] [Batch 2/200] [D loss: 0.000206] [G loss: 0.020277]\n",
            "[Epoch 186/200] [Batch 3/200] [D loss: 0.000190] [G loss: 0.016674]\n",
            "[Epoch 186/200] [Batch 4/200] [D loss: 0.000107] [G loss: 0.017438]\n",
            "[Epoch 186/200] [Batch 5/200] [D loss: 0.000147] [G loss: 0.023027]\n",
            "[Epoch 186/200] [Batch 6/200] [D loss: 0.000203] [G loss: 0.014389]\n",
            "[Epoch 186/200] [Batch 7/200] [D loss: 0.000181] [G loss: 0.019768]\n",
            "[Epoch 186/200] [Batch 8/200] [D loss: 0.000134] [G loss: 0.020331]\n",
            "[Epoch 186/200] [Batch 9/200] [D loss: 0.000246] [G loss: 0.014926]\n",
            "[Epoch 186/200] [Batch 10/200] [D loss: 0.000211] [G loss: 0.015001]\n",
            "[Epoch 186/200] [Batch 11/200] [D loss: 0.000220] [G loss: 0.018004]\n",
            "[Epoch 186/200] [Batch 12/200] [D loss: 0.000106] [G loss: 0.015610]\n",
            "[Epoch 186/200] [Batch 13/200] [D loss: 0.000136] [G loss: 0.018836]\n",
            "[Epoch 186/200] [Batch 14/200] [D loss: 0.000246] [G loss: 0.018985]\n",
            "[Epoch 186/200] [Batch 15/200] [D loss: 0.000250] [G loss: 0.018709]\n",
            "[Epoch 186/200] [Batch 16/200] [D loss: 0.000119] [G loss: 0.018792]\n",
            "[Epoch 186/200] [Batch 17/200] [D loss: 0.000086] [G loss: 0.017801]\n",
            "[Epoch 186/200] [Batch 18/200] [D loss: 0.000235] [G loss: 0.017134]\n",
            "[Epoch 186/200] [Batch 19/200] [D loss: 0.000249] [G loss: 0.019645]\n",
            "[Epoch 186/200] [Batch 20/200] [D loss: 0.000387] [G loss: 0.020022]\n",
            "[Epoch 186/200] [Batch 21/200] [D loss: 0.000581] [G loss: 0.015928]\n",
            "[Epoch 186/200] [Batch 22/200] [D loss: 0.000855] [G loss: 0.019956]\n",
            "[Epoch 186/200] [Batch 23/200] [D loss: 0.000473] [G loss: 0.019319]\n",
            "[Epoch 186/200] [Batch 24/200] [D loss: 0.000394] [G loss: 0.020123]\n",
            "[Epoch 186/200] [Batch 25/200] [D loss: 0.000482] [G loss: 0.014953]\n",
            "[Epoch 186/200] [Batch 26/200] [D loss: 0.000628] [G loss: 0.018395]\n",
            "[Epoch 186/200] [Batch 27/200] [D loss: 0.000352] [G loss: 0.016019]\n",
            "[Epoch 186/200] [Batch 28/200] [D loss: 0.000193] [G loss: 0.013493]\n",
            "[Epoch 186/200] [Batch 29/200] [D loss: 0.000243] [G loss: 0.018350]\n",
            "[Epoch 186/200] [Batch 30/200] [D loss: 0.000143] [G loss: 0.015973]\n",
            "[Epoch 186/200] [Batch 31/200] [D loss: 0.000136] [G loss: 0.019276]\n",
            "[Epoch 186/200] [Batch 32/200] [D loss: 0.000206] [G loss: 0.015580]\n",
            "[Epoch 186/200] [Batch 33/200] [D loss: 0.000339] [G loss: 0.015076]\n",
            "[Epoch 186/200] [Batch 34/200] [D loss: 0.000643] [G loss: 0.019473]\n",
            "[Epoch 186/200] [Batch 35/200] [D loss: 0.000846] [G loss: 0.015656]\n",
            "[Epoch 186/200] [Batch 36/200] [D loss: 0.000260] [G loss: 0.017997]\n",
            "[Epoch 186/200] [Batch 37/200] [D loss: 0.000497] [G loss: 0.017564]\n",
            "[Epoch 186/200] [Batch 38/200] [D loss: 0.000401] [G loss: 0.020464]\n",
            "[Epoch 186/200] [Batch 39/200] [D loss: 0.000436] [G loss: 0.013363]\n",
            "[Epoch 186/200] [Batch 40/200] [D loss: 0.000990] [G loss: 0.020674]\n",
            "[Epoch 186/200] [Batch 41/200] [D loss: 0.000509] [G loss: 0.017961]\n",
            "[Epoch 186/200] [Batch 42/200] [D loss: 0.000302] [G loss: 0.016158]\n",
            "[Epoch 186/200] [Batch 43/200] [D loss: 0.000342] [G loss: 0.016165]\n",
            "[Epoch 186/200] [Batch 44/200] [D loss: 0.000161] [G loss: 0.017115]\n",
            "[Epoch 186/200] [Batch 45/200] [D loss: 0.000461] [G loss: 0.019260]\n",
            "[Epoch 186/200] [Batch 46/200] [D loss: 0.000722] [G loss: 0.018907]\n",
            "[Epoch 186/200] [Batch 47/200] [D loss: 0.000634] [G loss: 0.017063]\n",
            "[Epoch 186/200] [Batch 48/200] [D loss: 0.000435] [G loss: 0.015982]\n",
            "[Epoch 186/200] [Batch 49/200] [D loss: 0.000574] [G loss: 0.016556]\n",
            "[Epoch 186/200] [Batch 50/200] [D loss: 0.000165] [G loss: 0.019566]\n",
            "[Epoch 186/200] [Batch 51/200] [D loss: 0.000373] [G loss: 0.016364]\n",
            "[Epoch 186/200] [Batch 52/200] [D loss: 0.000358] [G loss: 0.017318]\n",
            "[Epoch 186/200] [Batch 53/200] [D loss: 0.000119] [G loss: 0.016341]\n",
            "[Epoch 186/200] [Batch 54/200] [D loss: 0.000243] [G loss: 0.022569]\n",
            "[Epoch 186/200] [Batch 55/200] [D loss: 0.000365] [G loss: 0.016603]\n",
            "[Epoch 186/200] [Batch 56/200] [D loss: 0.000119] [G loss: 0.016028]\n",
            "[Epoch 186/200] [Batch 57/200] [D loss: 0.000354] [G loss: 0.017355]\n",
            "[Epoch 186/200] [Batch 58/200] [D loss: 0.000272] [G loss: 0.016506]\n",
            "[Epoch 186/200] [Batch 59/200] [D loss: 0.000104] [G loss: 0.013920]\n",
            "[Epoch 186/200] [Batch 60/200] [D loss: 0.000119] [G loss: 0.016234]\n",
            "[Epoch 186/200] [Batch 61/200] [D loss: 0.000166] [G loss: 0.017818]\n",
            "[Epoch 186/200] [Batch 62/200] [D loss: 0.000379] [G loss: 0.017289]\n",
            "[Epoch 186/200] [Batch 63/200] [D loss: 0.000344] [G loss: 0.019120]\n",
            "[Epoch 186/200] [Batch 64/200] [D loss: 0.000210] [G loss: 0.022923]\n",
            "[Epoch 186/200] [Batch 65/200] [D loss: 0.000097] [G loss: 0.015002]\n",
            "[Epoch 186/200] [Batch 66/200] [D loss: 0.000176] [G loss: 0.016967]\n",
            "[Epoch 186/200] [Batch 67/200] [D loss: 0.000083] [G loss: 0.020145]\n",
            "[Epoch 186/200] [Batch 68/200] [D loss: 0.000078] [G loss: 0.022628]\n",
            "[Epoch 186/200] [Batch 69/200] [D loss: 0.000092] [G loss: 0.017270]\n",
            "[Epoch 186/200] [Batch 70/200] [D loss: 0.000082] [G loss: 0.016822]\n",
            "[Epoch 186/200] [Batch 71/200] [D loss: 0.000126] [G loss: 0.017086]\n",
            "[Epoch 186/200] [Batch 72/200] [D loss: 0.000082] [G loss: 0.012409]\n",
            "[Epoch 186/200] [Batch 73/200] [D loss: 0.000074] [G loss: 0.017588]\n",
            "[Epoch 186/200] [Batch 74/200] [D loss: 0.000123] [G loss: 0.017701]\n",
            "[Epoch 186/200] [Batch 75/200] [D loss: 0.000144] [G loss: 0.016450]\n",
            "[Epoch 186/200] [Batch 76/200] [D loss: 0.000114] [G loss: 0.017917]\n",
            "[Epoch 186/200] [Batch 77/200] [D loss: 0.000054] [G loss: 0.016894]\n",
            "[Epoch 186/200] [Batch 78/200] [D loss: 0.000100] [G loss: 0.019683]\n",
            "[Epoch 186/200] [Batch 79/200] [D loss: 0.000135] [G loss: 0.015904]\n",
            "[Epoch 186/200] [Batch 80/200] [D loss: 0.000147] [G loss: 0.021011]\n",
            "[Epoch 186/200] [Batch 81/200] [D loss: 0.000226] [G loss: 0.015834]\n",
            "[Epoch 186/200] [Batch 82/200] [D loss: 0.000173] [G loss: 0.017113]\n",
            "[Epoch 186/200] [Batch 83/200] [D loss: 0.000207] [G loss: 0.018194]\n",
            "[Epoch 186/200] [Batch 84/200] [D loss: 0.000406] [G loss: 0.018753]\n",
            "[Epoch 186/200] [Batch 85/200] [D loss: 0.000445] [G loss: 0.018881]\n",
            "[Epoch 186/200] [Batch 86/200] [D loss: 0.000352] [G loss: 0.016938]\n",
            "[Epoch 186/200] [Batch 87/200] [D loss: 0.000166] [G loss: 0.017764]\n",
            "[Epoch 186/200] [Batch 88/200] [D loss: 0.000217] [G loss: 0.015786]\n",
            "[Epoch 186/200] [Batch 89/200] [D loss: 0.000159] [G loss: 0.018723]\n",
            "[Epoch 186/200] [Batch 90/200] [D loss: 0.000279] [G loss: 0.016131]\n",
            "[Epoch 186/200] [Batch 91/200] [D loss: 0.000176] [G loss: 0.016546]\n",
            "[Epoch 186/200] [Batch 92/200] [D loss: 0.000225] [G loss: 0.017336]\n",
            "[Epoch 186/200] [Batch 93/200] [D loss: 0.000091] [G loss: 0.013892]\n",
            "[Epoch 186/200] [Batch 94/200] [D loss: 0.000082] [G loss: 0.018644]\n",
            "[Epoch 186/200] [Batch 95/200] [D loss: 0.000190] [G loss: 0.018491]\n",
            "[Epoch 186/200] [Batch 96/200] [D loss: 0.000247] [G loss: 0.018180]\n",
            "[Epoch 186/200] [Batch 97/200] [D loss: 0.000117] [G loss: 0.018220]\n",
            "[Epoch 186/200] [Batch 98/200] [D loss: 0.000125] [G loss: 0.018318]\n",
            "[Epoch 186/200] [Batch 99/200] [D loss: 0.000221] [G loss: 0.018590]\n",
            "[Epoch 186/200] [Batch 100/200] [D loss: 0.000120] [G loss: 0.018815]\n",
            "[Epoch 186/200] [Batch 101/200] [D loss: 0.000271] [G loss: 0.013123]\n",
            "[Epoch 186/200] [Batch 102/200] [D loss: 0.000403] [G loss: 0.013325]\n",
            "[Epoch 186/200] [Batch 103/200] [D loss: 0.000212] [G loss: 0.018911]\n",
            "[Epoch 186/200] [Batch 104/200] [D loss: 0.000162] [G loss: 0.016754]\n",
            "[Epoch 186/200] [Batch 105/200] [D loss: 0.000261] [G loss: 0.017320]\n",
            "[Epoch 186/200] [Batch 106/200] [D loss: 0.000101] [G loss: 0.021356]\n",
            "[Epoch 186/200] [Batch 107/200] [D loss: 0.000134] [G loss: 0.017542]\n",
            "[Epoch 186/200] [Batch 108/200] [D loss: 0.000100] [G loss: 0.017623]\n",
            "[Epoch 186/200] [Batch 109/200] [D loss: 0.000094] [G loss: 0.019365]\n",
            "[Epoch 186/200] [Batch 110/200] [D loss: 0.000083] [G loss: 0.015266]\n",
            "[Epoch 186/200] [Batch 111/200] [D loss: 0.000109] [G loss: 0.019697]\n",
            "[Epoch 186/200] [Batch 112/200] [D loss: 0.000165] [G loss: 0.021291]\n",
            "[Epoch 186/200] [Batch 113/200] [D loss: 0.000413] [G loss: 0.021246]\n",
            "[Epoch 186/200] [Batch 114/200] [D loss: 0.000783] [G loss: 0.019043]\n",
            "[Epoch 186/200] [Batch 115/200] [D loss: 0.000418] [G loss: 0.021763]\n",
            "[Epoch 186/200] [Batch 116/200] [D loss: 0.000226] [G loss: 0.015723]\n",
            "[Epoch 186/200] [Batch 117/200] [D loss: 0.000208] [G loss: 0.016540]\n",
            "[Epoch 186/200] [Batch 118/200] [D loss: 0.000118] [G loss: 0.017184]\n",
            "[Epoch 186/200] [Batch 119/200] [D loss: 0.000166] [G loss: 0.017538]\n",
            "[Epoch 186/200] [Batch 120/200] [D loss: 0.000269] [G loss: 0.013785]\n",
            "[Epoch 186/200] [Batch 121/200] [D loss: 0.000169] [G loss: 0.021039]\n",
            "[Epoch 186/200] [Batch 122/200] [D loss: 0.000384] [G loss: 0.016305]\n",
            "[Epoch 186/200] [Batch 123/200] [D loss: 0.000300] [G loss: 0.021961]\n",
            "[Epoch 186/200] [Batch 124/200] [D loss: 0.000459] [G loss: 0.022000]\n",
            "[Epoch 186/200] [Batch 125/200] [D loss: 0.000563] [G loss: 0.017323]\n",
            "[Epoch 186/200] [Batch 126/200] [D loss: 0.000185] [G loss: 0.015323]\n",
            "[Epoch 186/200] [Batch 127/200] [D loss: 0.000226] [G loss: 0.022686]\n",
            "[Epoch 186/200] [Batch 128/200] [D loss: 0.000282] [G loss: 0.016876]\n",
            "[Epoch 186/200] [Batch 129/200] [D loss: 0.000444] [G loss: 0.018768]\n",
            "[Epoch 186/200] [Batch 130/200] [D loss: 0.000338] [G loss: 0.014635]\n",
            "[Epoch 186/200] [Batch 131/200] [D loss: 0.000290] [G loss: 0.017282]\n",
            "[Epoch 186/200] [Batch 132/200] [D loss: 0.000228] [G loss: 0.017799]\n",
            "[Epoch 186/200] [Batch 133/200] [D loss: 0.000115] [G loss: 0.020400]\n",
            "[Epoch 186/200] [Batch 134/200] [D loss: 0.000155] [G loss: 0.015125]\n",
            "[Epoch 186/200] [Batch 135/200] [D loss: 0.000292] [G loss: 0.017006]\n",
            "[Epoch 186/200] [Batch 136/200] [D loss: 0.000272] [G loss: 0.014518]\n",
            "[Epoch 186/200] [Batch 137/200] [D loss: 0.000281] [G loss: 0.013055]\n",
            "[Epoch 186/200] [Batch 138/200] [D loss: 0.000166] [G loss: 0.016721]\n",
            "[Epoch 186/200] [Batch 139/200] [D loss: 0.000319] [G loss: 0.018403]\n",
            "[Epoch 186/200] [Batch 140/200] [D loss: 0.000476] [G loss: 0.017402]\n",
            "[Epoch 186/200] [Batch 141/200] [D loss: 0.000235] [G loss: 0.019788]\n",
            "[Epoch 186/200] [Batch 142/200] [D loss: 0.000184] [G loss: 0.023153]\n",
            "[Epoch 186/200] [Batch 143/200] [D loss: 0.000365] [G loss: 0.015193]\n",
            "[Epoch 186/200] [Batch 144/200] [D loss: 0.000217] [G loss: 0.017095]\n",
            "[Epoch 186/200] [Batch 145/200] [D loss: 0.000326] [G loss: 0.017881]\n",
            "[Epoch 186/200] [Batch 146/200] [D loss: 0.000547] [G loss: 0.017102]\n",
            "[Epoch 186/200] [Batch 147/200] [D loss: 0.000214] [G loss: 0.018367]\n",
            "[Epoch 186/200] [Batch 148/200] [D loss: 0.000255] [G loss: 0.017276]\n",
            "[Epoch 186/200] [Batch 149/200] [D loss: 0.000409] [G loss: 0.016312]\n",
            "[Epoch 186/200] [Batch 150/200] [D loss: 0.000261] [G loss: 0.017255]\n",
            "[Epoch 186/200] [Batch 151/200] [D loss: 0.000135] [G loss: 0.016553]\n",
            "[Epoch 186/200] [Batch 152/200] [D loss: 0.000089] [G loss: 0.016219]\n",
            "[Epoch 186/200] [Batch 153/200] [D loss: 0.000224] [G loss: 0.019003]\n",
            "[Epoch 186/200] [Batch 154/200] [D loss: 0.000118] [G loss: 0.015085]\n",
            "[Epoch 186/200] [Batch 155/200] [D loss: 0.000069] [G loss: 0.020625]\n",
            "[Epoch 186/200] [Batch 156/200] [D loss: 0.000086] [G loss: 0.017192]\n",
            "[Epoch 186/200] [Batch 157/200] [D loss: 0.000051] [G loss: 0.019912]\n",
            "[Epoch 186/200] [Batch 158/200] [D loss: 0.000091] [G loss: 0.017947]\n",
            "[Epoch 186/200] [Batch 159/200] [D loss: 0.000166] [G loss: 0.020200]\n",
            "[Epoch 186/200] [Batch 160/200] [D loss: 0.000168] [G loss: 0.013326]\n",
            "[Epoch 186/200] [Batch 161/200] [D loss: 0.000087] [G loss: 0.016500]\n",
            "[Epoch 186/200] [Batch 162/200] [D loss: 0.000174] [G loss: 0.013989]\n",
            "[Epoch 186/200] [Batch 163/200] [D loss: 0.000244] [G loss: 0.018720]\n",
            "[Epoch 186/200] [Batch 164/200] [D loss: 0.000429] [G loss: 0.017799]\n",
            "[Epoch 186/200] [Batch 165/200] [D loss: 0.000853] [G loss: 0.015207]\n",
            "[Epoch 186/200] [Batch 166/200] [D loss: 0.001372] [G loss: 0.018419]\n",
            "[Epoch 186/200] [Batch 167/200] [D loss: 0.001083] [G loss: 0.015696]\n",
            "[Epoch 186/200] [Batch 168/200] [D loss: 0.000452] [G loss: 0.017871]\n",
            "[Epoch 186/200] [Batch 169/200] [D loss: 0.000705] [G loss: 0.018480]\n",
            "[Epoch 186/200] [Batch 170/200] [D loss: 0.001225] [G loss: 0.020353]\n",
            "[Epoch 186/200] [Batch 171/200] [D loss: 0.001019] [G loss: 0.017248]\n",
            "[Epoch 186/200] [Batch 172/200] [D loss: 0.000632] [G loss: 0.021431]\n",
            "[Epoch 186/200] [Batch 173/200] [D loss: 0.000509] [G loss: 0.015169]\n",
            "[Epoch 186/200] [Batch 174/200] [D loss: 0.000408] [G loss: 0.022963]\n",
            "[Epoch 186/200] [Batch 175/200] [D loss: 0.000464] [G loss: 0.014405]\n",
            "[Epoch 186/200] [Batch 176/200] [D loss: 0.000275] [G loss: 0.020438]\n",
            "[Epoch 186/200] [Batch 177/200] [D loss: 0.000491] [G loss: 0.015638]\n",
            "[Epoch 186/200] [Batch 178/200] [D loss: 0.000664] [G loss: 0.018317]\n",
            "[Epoch 186/200] [Batch 179/200] [D loss: 0.000665] [G loss: 0.020084]\n",
            "[Epoch 186/200] [Batch 180/200] [D loss: 0.000962] [G loss: 0.016681]\n",
            "[Epoch 186/200] [Batch 181/200] [D loss: 0.001627] [G loss: 0.013740]\n",
            "[Epoch 186/200] [Batch 182/200] [D loss: 0.000636] [G loss: 0.017351]\n",
            "[Epoch 186/200] [Batch 183/200] [D loss: 0.000860] [G loss: 0.016803]\n",
            "[Epoch 186/200] [Batch 184/200] [D loss: 0.002471] [G loss: 0.016167]\n",
            "[Epoch 186/200] [Batch 185/200] [D loss: 0.004664] [G loss: 0.016199]\n",
            "[Epoch 186/200] [Batch 186/200] [D loss: 0.000934] [G loss: 0.017439]\n",
            "[Epoch 186/200] [Batch 187/200] [D loss: 0.001235] [G loss: 0.014434]\n",
            "[Epoch 186/200] [Batch 188/200] [D loss: 0.000604] [G loss: 0.018455]\n",
            "[Epoch 186/200] [Batch 189/200] [D loss: 0.000456] [G loss: 0.019163]\n",
            "[Epoch 186/200] [Batch 190/200] [D loss: 0.000413] [G loss: 0.017379]\n",
            "[Epoch 186/200] [Batch 191/200] [D loss: 0.000355] [G loss: 0.016766]\n",
            "[Epoch 186/200] [Batch 192/200] [D loss: 0.000202] [G loss: 0.019128]\n",
            "[Epoch 186/200] [Batch 193/200] [D loss: 0.000209] [G loss: 0.018329]\n",
            "[Epoch 186/200] [Batch 194/200] [D loss: 0.000160] [G loss: 0.016768]\n",
            "[Epoch 186/200] [Batch 195/200] [D loss: 0.000174] [G loss: 0.020923]\n",
            "[Epoch 186/200] [Batch 196/200] [D loss: 0.000378] [G loss: 0.020425]\n",
            "[Epoch 186/200] [Batch 197/200] [D loss: 0.000156] [G loss: 0.016997]\n",
            "[Epoch 186/200] [Batch 198/200] [D loss: 0.000208] [G loss: 0.015673]\n",
            "[Epoch 186/200] [Batch 199/200] [D loss: 0.000181] [G loss: 0.014630]\n",
            "[Epoch 187/200] [Batch 0/200] [D loss: 0.000269] [G loss: 0.017341]\n",
            "[Epoch 187/200] [Batch 1/200] [D loss: 0.000187] [G loss: 0.020835]\n",
            "[Epoch 187/200] [Batch 2/200] [D loss: 0.000128] [G loss: 0.019621]\n",
            "[Epoch 187/200] [Batch 3/200] [D loss: 0.000343] [G loss: 0.018582]\n",
            "[Epoch 187/200] [Batch 4/200] [D loss: 0.001106] [G loss: 0.016051]\n",
            "[Epoch 187/200] [Batch 5/200] [D loss: 0.000312] [G loss: 0.020053]\n",
            "[Epoch 187/200] [Batch 6/200] [D loss: 0.000413] [G loss: 0.014518]\n",
            "[Epoch 187/200] [Batch 7/200] [D loss: 0.000181] [G loss: 0.018374]\n",
            "[Epoch 187/200] [Batch 8/200] [D loss: 0.000648] [G loss: 0.015544]\n",
            "[Epoch 187/200] [Batch 9/200] [D loss: 0.001505] [G loss: 0.017772]\n",
            "[Epoch 187/200] [Batch 10/200] [D loss: 0.000377] [G loss: 0.012074]\n",
            "[Epoch 187/200] [Batch 11/200] [D loss: 0.001103] [G loss: 0.018985]\n",
            "[Epoch 187/200] [Batch 12/200] [D loss: 0.002280] [G loss: 0.016668]\n",
            "[Epoch 187/200] [Batch 13/200] [D loss: 0.001017] [G loss: 0.017979]\n",
            "[Epoch 187/200] [Batch 14/200] [D loss: 0.000679] [G loss: 0.013683]\n",
            "[Epoch 187/200] [Batch 15/200] [D loss: 0.000416] [G loss: 0.012544]\n",
            "[Epoch 187/200] [Batch 16/200] [D loss: 0.000369] [G loss: 0.022954]\n",
            "[Epoch 187/200] [Batch 17/200] [D loss: 0.000777] [G loss: 0.018967]\n",
            "[Epoch 187/200] [Batch 18/200] [D loss: 0.000647] [G loss: 0.014138]\n",
            "[Epoch 187/200] [Batch 19/200] [D loss: 0.000568] [G loss: 0.020297]\n",
            "[Epoch 187/200] [Batch 20/200] [D loss: 0.001134] [G loss: 0.012520]\n",
            "[Epoch 187/200] [Batch 21/200] [D loss: 0.000664] [G loss: 0.014353]\n",
            "[Epoch 187/200] [Batch 22/200] [D loss: 0.000414] [G loss: 0.017377]\n",
            "[Epoch 187/200] [Batch 23/200] [D loss: 0.000295] [G loss: 0.020489]\n",
            "[Epoch 187/200] [Batch 24/200] [D loss: 0.000196] [G loss: 0.018947]\n",
            "[Epoch 187/200] [Batch 25/200] [D loss: 0.000159] [G loss: 0.018129]\n",
            "[Epoch 187/200] [Batch 26/200] [D loss: 0.000078] [G loss: 0.016903]\n",
            "[Epoch 187/200] [Batch 27/200] [D loss: 0.000806] [G loss: 0.016885]\n",
            "[Epoch 187/200] [Batch 28/200] [D loss: 0.001101] [G loss: 0.018491]\n",
            "[Epoch 187/200] [Batch 29/200] [D loss: 0.000653] [G loss: 0.021273]\n",
            "[Epoch 187/200] [Batch 30/200] [D loss: 0.000467] [G loss: 0.020981]\n",
            "[Epoch 187/200] [Batch 31/200] [D loss: 0.000339] [G loss: 0.016718]\n",
            "[Epoch 187/200] [Batch 32/200] [D loss: 0.000221] [G loss: 0.020852]\n",
            "[Epoch 187/200] [Batch 33/200] [D loss: 0.000136] [G loss: 0.016535]\n",
            "[Epoch 187/200] [Batch 34/200] [D loss: 0.000356] [G loss: 0.018258]\n",
            "[Epoch 187/200] [Batch 35/200] [D loss: 0.000610] [G loss: 0.019770]\n",
            "[Epoch 187/200] [Batch 36/200] [D loss: 0.000412] [G loss: 0.018462]\n",
            "[Epoch 187/200] [Batch 37/200] [D loss: 0.000130] [G loss: 0.017771]\n",
            "[Epoch 187/200] [Batch 38/200] [D loss: 0.000093] [G loss: 0.016779]\n",
            "[Epoch 187/200] [Batch 39/200] [D loss: 0.000113] [G loss: 0.018917]\n",
            "[Epoch 187/200] [Batch 40/200] [D loss: 0.000108] [G loss: 0.016410]\n",
            "[Epoch 187/200] [Batch 41/200] [D loss: 0.000187] [G loss: 0.020224]\n",
            "[Epoch 187/200] [Batch 42/200] [D loss: 0.000392] [G loss: 0.017108]\n",
            "[Epoch 187/200] [Batch 43/200] [D loss: 0.000203] [G loss: 0.015442]\n",
            "[Epoch 187/200] [Batch 44/200] [D loss: 0.000223] [G loss: 0.015784]\n",
            "[Epoch 187/200] [Batch 45/200] [D loss: 0.000168] [G loss: 0.017081]\n",
            "[Epoch 187/200] [Batch 46/200] [D loss: 0.000162] [G loss: 0.018303]\n",
            "[Epoch 187/200] [Batch 47/200] [D loss: 0.000271] [G loss: 0.013258]\n",
            "[Epoch 187/200] [Batch 48/200] [D loss: 0.000511] [G loss: 0.022219]\n",
            "[Epoch 187/200] [Batch 49/200] [D loss: 0.000282] [G loss: 0.024572]\n",
            "[Epoch 187/200] [Batch 50/200] [D loss: 0.000480] [G loss: 0.021343]\n",
            "[Epoch 187/200] [Batch 51/200] [D loss: 0.000086] [G loss: 0.017737]\n",
            "[Epoch 187/200] [Batch 52/200] [D loss: 0.000176] [G loss: 0.021725]\n",
            "[Epoch 187/200] [Batch 53/200] [D loss: 0.000259] [G loss: 0.019300]\n",
            "[Epoch 187/200] [Batch 54/200] [D loss: 0.000206] [G loss: 0.016601]\n",
            "[Epoch 187/200] [Batch 55/200] [D loss: 0.000120] [G loss: 0.017103]\n",
            "[Epoch 187/200] [Batch 56/200] [D loss: 0.000099] [G loss: 0.018561]\n",
            "[Epoch 187/200] [Batch 57/200] [D loss: 0.000142] [G loss: 0.019161]\n",
            "[Epoch 187/200] [Batch 58/200] [D loss: 0.000203] [G loss: 0.017967]\n",
            "[Epoch 187/200] [Batch 59/200] [D loss: 0.000589] [G loss: 0.018812]\n",
            "[Epoch 187/200] [Batch 60/200] [D loss: 0.001653] [G loss: 0.017065]\n",
            "[Epoch 187/200] [Batch 61/200] [D loss: 0.002233] [G loss: 0.023682]\n",
            "[Epoch 187/200] [Batch 62/200] [D loss: 0.000591] [G loss: 0.021174]\n",
            "[Epoch 187/200] [Batch 63/200] [D loss: 0.000188] [G loss: 0.018254]\n",
            "[Epoch 187/200] [Batch 64/200] [D loss: 0.000289] [G loss: 0.015955]\n",
            "[Epoch 187/200] [Batch 65/200] [D loss: 0.000175] [G loss: 0.018767]\n",
            "[Epoch 187/200] [Batch 66/200] [D loss: 0.000136] [G loss: 0.017198]\n",
            "[Epoch 187/200] [Batch 67/200] [D loss: 0.000208] [G loss: 0.016529]\n",
            "[Epoch 187/200] [Batch 68/200] [D loss: 0.000417] [G loss: 0.015789]\n",
            "[Epoch 187/200] [Batch 69/200] [D loss: 0.000146] [G loss: 0.017428]\n",
            "[Epoch 187/200] [Batch 70/200] [D loss: 0.000218] [G loss: 0.020561]\n",
            "[Epoch 187/200] [Batch 71/200] [D loss: 0.000080] [G loss: 0.017577]\n",
            "[Epoch 187/200] [Batch 72/200] [D loss: 0.000154] [G loss: 0.018151]\n",
            "[Epoch 187/200] [Batch 73/200] [D loss: 0.000069] [G loss: 0.018201]\n",
            "[Epoch 187/200] [Batch 74/200] [D loss: 0.000096] [G loss: 0.014760]\n",
            "[Epoch 187/200] [Batch 75/200] [D loss: 0.000147] [G loss: 0.017942]\n",
            "[Epoch 187/200] [Batch 76/200] [D loss: 0.000279] [G loss: 0.018998]\n",
            "[Epoch 187/200] [Batch 77/200] [D loss: 0.000224] [G loss: 0.018830]\n",
            "[Epoch 187/200] [Batch 78/200] [D loss: 0.000208] [G loss: 0.015438]\n",
            "[Epoch 187/200] [Batch 79/200] [D loss: 0.000329] [G loss: 0.015100]\n",
            "[Epoch 187/200] [Batch 80/200] [D loss: 0.000114] [G loss: 0.018377]\n",
            "[Epoch 187/200] [Batch 81/200] [D loss: 0.000131] [G loss: 0.019348]\n",
            "[Epoch 187/200] [Batch 82/200] [D loss: 0.000137] [G loss: 0.016138]\n",
            "[Epoch 187/200] [Batch 83/200] [D loss: 0.000106] [G loss: 0.016862]\n",
            "[Epoch 187/200] [Batch 84/200] [D loss: 0.000076] [G loss: 0.016191]\n",
            "[Epoch 187/200] [Batch 85/200] [D loss: 0.000259] [G loss: 0.018267]\n",
            "[Epoch 187/200] [Batch 86/200] [D loss: 0.001614] [G loss: 0.020275]\n",
            "[Epoch 187/200] [Batch 87/200] [D loss: 0.002165] [G loss: 0.013860]\n",
            "[Epoch 187/200] [Batch 88/200] [D loss: 0.001176] [G loss: 0.015205]\n",
            "[Epoch 187/200] [Batch 89/200] [D loss: 0.002083] [G loss: 0.017212]\n",
            "[Epoch 187/200] [Batch 90/200] [D loss: 0.000702] [G loss: 0.017636]\n",
            "[Epoch 187/200] [Batch 91/200] [D loss: 0.001359] [G loss: 0.017811]\n",
            "[Epoch 187/200] [Batch 92/200] [D loss: 0.001449] [G loss: 0.020867]\n",
            "[Epoch 187/200] [Batch 93/200] [D loss: 0.000988] [G loss: 0.019149]\n",
            "[Epoch 187/200] [Batch 94/200] [D loss: 0.001176] [G loss: 0.014567]\n",
            "[Epoch 187/200] [Batch 95/200] [D loss: 0.001044] [G loss: 0.020724]\n",
            "[Epoch 187/200] [Batch 96/200] [D loss: 0.001464] [G loss: 0.020748]\n",
            "[Epoch 187/200] [Batch 97/200] [D loss: 0.002924] [G loss: 0.015403]\n",
            "[Epoch 187/200] [Batch 98/200] [D loss: 0.006488] [G loss: 0.020990]\n",
            "[Epoch 187/200] [Batch 99/200] [D loss: 0.005187] [G loss: 0.021314]\n",
            "[Epoch 187/200] [Batch 100/200] [D loss: 0.001569] [G loss: 0.019871]\n",
            "[Epoch 187/200] [Batch 101/200] [D loss: 0.002240] [G loss: 0.016619]\n",
            "[Epoch 187/200] [Batch 102/200] [D loss: 0.001962] [G loss: 0.012361]\n",
            "[Epoch 187/200] [Batch 103/200] [D loss: 0.002793] [G loss: 0.019217]\n",
            "[Epoch 187/200] [Batch 104/200] [D loss: 0.002544] [G loss: 0.019545]\n",
            "[Epoch 187/200] [Batch 105/200] [D loss: 0.002431] [G loss: 0.014103]\n",
            "[Epoch 187/200] [Batch 106/200] [D loss: 0.002450] [G loss: 0.016009]\n",
            "[Epoch 187/200] [Batch 107/200] [D loss: 0.001574] [G loss: 0.016728]\n",
            "[Epoch 187/200] [Batch 108/200] [D loss: 0.001356] [G loss: 0.018156]\n",
            "[Epoch 187/200] [Batch 109/200] [D loss: 0.000709] [G loss: 0.014196]\n",
            "[Epoch 187/200] [Batch 110/200] [D loss: 0.000775] [G loss: 0.016146]\n",
            "[Epoch 187/200] [Batch 111/200] [D loss: 0.000529] [G loss: 0.017538]\n",
            "[Epoch 187/200] [Batch 112/200] [D loss: 0.000579] [G loss: 0.019486]\n",
            "[Epoch 187/200] [Batch 113/200] [D loss: 0.000667] [G loss: 0.013049]\n",
            "[Epoch 187/200] [Batch 114/200] [D loss: 0.000742] [G loss: 0.016993]\n",
            "[Epoch 187/200] [Batch 115/200] [D loss: 0.001379] [G loss: 0.018703]\n",
            "[Epoch 187/200] [Batch 116/200] [D loss: 0.001264] [G loss: 0.018395]\n",
            "[Epoch 187/200] [Batch 117/200] [D loss: 0.001627] [G loss: 0.019051]\n",
            "[Epoch 187/200] [Batch 118/200] [D loss: 0.003956] [G loss: 0.016388]\n",
            "[Epoch 187/200] [Batch 119/200] [D loss: 0.003886] [G loss: 0.020335]\n",
            "[Epoch 187/200] [Batch 120/200] [D loss: 0.004291] [G loss: 0.016278]\n",
            "[Epoch 187/200] [Batch 121/200] [D loss: 0.005019] [G loss: 0.017552]\n",
            "[Epoch 187/200] [Batch 122/200] [D loss: 0.002719] [G loss: 0.015565]\n",
            "[Epoch 187/200] [Batch 123/200] [D loss: 0.000505] [G loss: 0.018707]\n",
            "[Epoch 187/200] [Batch 124/200] [D loss: 0.001346] [G loss: 0.017807]\n",
            "[Epoch 187/200] [Batch 125/200] [D loss: 0.001046] [G loss: 0.015272]\n",
            "[Epoch 187/200] [Batch 126/200] [D loss: 0.000542] [G loss: 0.014835]\n",
            "[Epoch 187/200] [Batch 127/200] [D loss: 0.000220] [G loss: 0.020037]\n",
            "[Epoch 187/200] [Batch 128/200] [D loss: 0.000429] [G loss: 0.012013]\n",
            "[Epoch 187/200] [Batch 129/200] [D loss: 0.000654] [G loss: 0.018001]\n",
            "[Epoch 187/200] [Batch 130/200] [D loss: 0.000473] [G loss: 0.013123]\n",
            "[Epoch 187/200] [Batch 131/200] [D loss: 0.000338] [G loss: 0.020010]\n",
            "[Epoch 187/200] [Batch 132/200] [D loss: 0.000321] [G loss: 0.017312]\n",
            "[Epoch 187/200] [Batch 133/200] [D loss: 0.000595] [G loss: 0.022759]\n",
            "[Epoch 187/200] [Batch 134/200] [D loss: 0.000788] [G loss: 0.022336]\n",
            "[Epoch 187/200] [Batch 135/200] [D loss: 0.000519] [G loss: 0.016852]\n",
            "[Epoch 187/200] [Batch 136/200] [D loss: 0.000397] [G loss: 0.017012]\n",
            "[Epoch 187/200] [Batch 137/200] [D loss: 0.000464] [G loss: 0.019184]\n",
            "[Epoch 187/200] [Batch 138/200] [D loss: 0.000270] [G loss: 0.021407]\n",
            "[Epoch 187/200] [Batch 139/200] [D loss: 0.000140] [G loss: 0.016757]\n",
            "[Epoch 187/200] [Batch 140/200] [D loss: 0.000277] [G loss: 0.017306]\n",
            "[Epoch 187/200] [Batch 141/200] [D loss: 0.000621] [G loss: 0.015500]\n",
            "[Epoch 187/200] [Batch 142/200] [D loss: 0.000474] [G loss: 0.017326]\n",
            "[Epoch 187/200] [Batch 143/200] [D loss: 0.000390] [G loss: 0.019286]\n",
            "[Epoch 187/200] [Batch 144/200] [D loss: 0.000424] [G loss: 0.016671]\n",
            "[Epoch 187/200] [Batch 145/200] [D loss: 0.000272] [G loss: 0.015858]\n",
            "[Epoch 187/200] [Batch 146/200] [D loss: 0.000357] [G loss: 0.018120]\n",
            "[Epoch 187/200] [Batch 147/200] [D loss: 0.000708] [G loss: 0.015883]\n",
            "[Epoch 187/200] [Batch 148/200] [D loss: 0.000881] [G loss: 0.019545]\n",
            "[Epoch 187/200] [Batch 149/200] [D loss: 0.000899] [G loss: 0.018549]\n",
            "[Epoch 187/200] [Batch 150/200] [D loss: 0.000435] [G loss: 0.015812]\n",
            "[Epoch 187/200] [Batch 151/200] [D loss: 0.001164] [G loss: 0.015890]\n",
            "[Epoch 187/200] [Batch 152/200] [D loss: 0.001337] [G loss: 0.017224]\n",
            "[Epoch 187/200] [Batch 153/200] [D loss: 0.000558] [G loss: 0.018992]\n",
            "[Epoch 187/200] [Batch 154/200] [D loss: 0.001006] [G loss: 0.017127]\n",
            "[Epoch 187/200] [Batch 155/200] [D loss: 0.000400] [G loss: 0.017171]\n",
            "[Epoch 187/200] [Batch 156/200] [D loss: 0.000201] [G loss: 0.014486]\n",
            "[Epoch 187/200] [Batch 157/200] [D loss: 0.000198] [G loss: 0.015764]\n",
            "[Epoch 187/200] [Batch 158/200] [D loss: 0.000213] [G loss: 0.015675]\n",
            "[Epoch 187/200] [Batch 159/200] [D loss: 0.000336] [G loss: 0.016770]\n",
            "[Epoch 187/200] [Batch 160/200] [D loss: 0.000362] [G loss: 0.019643]\n",
            "[Epoch 187/200] [Batch 161/200] [D loss: 0.000245] [G loss: 0.019269]\n",
            "[Epoch 187/200] [Batch 162/200] [D loss: 0.000133] [G loss: 0.017177]\n",
            "[Epoch 187/200] [Batch 163/200] [D loss: 0.000101] [G loss: 0.017111]\n",
            "[Epoch 187/200] [Batch 164/200] [D loss: 0.000252] [G loss: 0.016844]\n",
            "[Epoch 187/200] [Batch 165/200] [D loss: 0.000322] [G loss: 0.013727]\n",
            "[Epoch 187/200] [Batch 166/200] [D loss: 0.000177] [G loss: 0.017280]\n",
            "[Epoch 187/200] [Batch 167/200] [D loss: 0.000074] [G loss: 0.015226]\n",
            "[Epoch 187/200] [Batch 168/200] [D loss: 0.000158] [G loss: 0.015455]\n",
            "[Epoch 187/200] [Batch 169/200] [D loss: 0.000105] [G loss: 0.020055]\n",
            "[Epoch 187/200] [Batch 170/200] [D loss: 0.000185] [G loss: 0.016257]\n",
            "[Epoch 187/200] [Batch 171/200] [D loss: 0.000074] [G loss: 0.017874]\n",
            "[Epoch 187/200] [Batch 172/200] [D loss: 0.000219] [G loss: 0.018708]\n",
            "[Epoch 187/200] [Batch 173/200] [D loss: 0.000313] [G loss: 0.017764]\n",
            "[Epoch 187/200] [Batch 174/200] [D loss: 0.000130] [G loss: 0.017830]\n",
            "[Epoch 187/200] [Batch 175/200] [D loss: 0.000197] [G loss: 0.015398]\n",
            "[Epoch 187/200] [Batch 176/200] [D loss: 0.000146] [G loss: 0.021187]\n",
            "[Epoch 187/200] [Batch 177/200] [D loss: 0.000096] [G loss: 0.020157]\n",
            "[Epoch 187/200] [Batch 178/200] [D loss: 0.000113] [G loss: 0.016921]\n",
            "[Epoch 187/200] [Batch 179/200] [D loss: 0.000106] [G loss: 0.017108]\n",
            "[Epoch 187/200] [Batch 180/200] [D loss: 0.000076] [G loss: 0.018473]\n",
            "[Epoch 187/200] [Batch 181/200] [D loss: 0.000062] [G loss: 0.014527]\n",
            "[Epoch 187/200] [Batch 182/200] [D loss: 0.000175] [G loss: 0.014441]\n",
            "[Epoch 187/200] [Batch 183/200] [D loss: 0.000142] [G loss: 0.020296]\n",
            "[Epoch 187/200] [Batch 184/200] [D loss: 0.000111] [G loss: 0.021011]\n",
            "[Epoch 187/200] [Batch 185/200] [D loss: 0.000195] [G loss: 0.018393]\n",
            "[Epoch 187/200] [Batch 186/200] [D loss: 0.000115] [G loss: 0.015915]\n",
            "[Epoch 187/200] [Batch 187/200] [D loss: 0.000055] [G loss: 0.016554]\n",
            "[Epoch 187/200] [Batch 188/200] [D loss: 0.000093] [G loss: 0.019616]\n",
            "[Epoch 187/200] [Batch 189/200] [D loss: 0.000130] [G loss: 0.023798]\n",
            "[Epoch 187/200] [Batch 190/200] [D loss: 0.000110] [G loss: 0.020639]\n",
            "[Epoch 187/200] [Batch 191/200] [D loss: 0.000163] [G loss: 0.018872]\n",
            "[Epoch 187/200] [Batch 192/200] [D loss: 0.000185] [G loss: 0.016399]\n",
            "[Epoch 187/200] [Batch 193/200] [D loss: 0.000266] [G loss: 0.018899]\n",
            "[Epoch 187/200] [Batch 194/200] [D loss: 0.000365] [G loss: 0.017275]\n",
            "[Epoch 187/200] [Batch 195/200] [D loss: 0.000204] [G loss: 0.018027]\n",
            "[Epoch 187/200] [Batch 196/200] [D loss: 0.000150] [G loss: 0.020669]\n",
            "[Epoch 187/200] [Batch 197/200] [D loss: 0.000098] [G loss: 0.019431]\n",
            "[Epoch 187/200] [Batch 198/200] [D loss: 0.000121] [G loss: 0.016946]\n",
            "[Epoch 187/200] [Batch 199/200] [D loss: 0.000180] [G loss: 0.019207]\n",
            "[Epoch 188/200] [Batch 0/200] [D loss: 0.000154] [G loss: 0.013618]\n",
            "[Epoch 188/200] [Batch 1/200] [D loss: 0.000332] [G loss: 0.014902]\n",
            "[Epoch 188/200] [Batch 2/200] [D loss: 0.000570] [G loss: 0.015872]\n",
            "[Epoch 188/200] [Batch 3/200] [D loss: 0.000150] [G loss: 0.015136]\n",
            "[Epoch 188/200] [Batch 4/200] [D loss: 0.000378] [G loss: 0.020764]\n",
            "[Epoch 188/200] [Batch 5/200] [D loss: 0.000222] [G loss: 0.014769]\n",
            "[Epoch 188/200] [Batch 6/200] [D loss: 0.000324] [G loss: 0.018957]\n",
            "[Epoch 188/200] [Batch 7/200] [D loss: 0.000211] [G loss: 0.019472]\n",
            "[Epoch 188/200] [Batch 8/200] [D loss: 0.000392] [G loss: 0.014826]\n",
            "[Epoch 188/200] [Batch 9/200] [D loss: 0.000406] [G loss: 0.015109]\n",
            "[Epoch 188/200] [Batch 10/200] [D loss: 0.000425] [G loss: 0.012494]\n",
            "[Epoch 188/200] [Batch 11/200] [D loss: 0.000114] [G loss: 0.014413]\n",
            "[Epoch 188/200] [Batch 12/200] [D loss: 0.000127] [G loss: 0.017450]\n",
            "[Epoch 188/200] [Batch 13/200] [D loss: 0.000134] [G loss: 0.017976]\n",
            "[Epoch 188/200] [Batch 14/200] [D loss: 0.000127] [G loss: 0.017500]\n",
            "[Epoch 188/200] [Batch 15/200] [D loss: 0.000076] [G loss: 0.014766]\n",
            "[Epoch 188/200] [Batch 16/200] [D loss: 0.000080] [G loss: 0.017478]\n",
            "[Epoch 188/200] [Batch 17/200] [D loss: 0.000132] [G loss: 0.016926]\n",
            "[Epoch 188/200] [Batch 18/200] [D loss: 0.000174] [G loss: 0.016199]\n",
            "[Epoch 188/200] [Batch 19/200] [D loss: 0.000195] [G loss: 0.018318]\n",
            "[Epoch 188/200] [Batch 20/200] [D loss: 0.000142] [G loss: 0.021132]\n",
            "[Epoch 188/200] [Batch 21/200] [D loss: 0.000171] [G loss: 0.020140]\n",
            "[Epoch 188/200] [Batch 22/200] [D loss: 0.000145] [G loss: 0.018199]\n",
            "[Epoch 188/200] [Batch 23/200] [D loss: 0.000159] [G loss: 0.017630]\n",
            "[Epoch 188/200] [Batch 24/200] [D loss: 0.000249] [G loss: 0.013944]\n",
            "[Epoch 188/200] [Batch 25/200] [D loss: 0.000087] [G loss: 0.017284]\n",
            "[Epoch 188/200] [Batch 26/200] [D loss: 0.000627] [G loss: 0.016079]\n",
            "[Epoch 188/200] [Batch 27/200] [D loss: 0.001450] [G loss: 0.015084]\n",
            "[Epoch 188/200] [Batch 28/200] [D loss: 0.000464] [G loss: 0.017304]\n",
            "[Epoch 188/200] [Batch 29/200] [D loss: 0.000290] [G loss: 0.016165]\n",
            "[Epoch 188/200] [Batch 30/200] [D loss: 0.000264] [G loss: 0.018645]\n",
            "[Epoch 188/200] [Batch 31/200] [D loss: 0.000322] [G loss: 0.019806]\n",
            "[Epoch 188/200] [Batch 32/200] [D loss: 0.000237] [G loss: 0.016057]\n",
            "[Epoch 188/200] [Batch 33/200] [D loss: 0.000638] [G loss: 0.017752]\n",
            "[Epoch 188/200] [Batch 34/200] [D loss: 0.000888] [G loss: 0.013091]\n",
            "[Epoch 188/200] [Batch 35/200] [D loss: 0.000282] [G loss: 0.014102]\n",
            "[Epoch 188/200] [Batch 36/200] [D loss: 0.000124] [G loss: 0.018397]\n",
            "[Epoch 188/200] [Batch 37/200] [D loss: 0.000454] [G loss: 0.014935]\n",
            "[Epoch 188/200] [Batch 38/200] [D loss: 0.001155] [G loss: 0.013053]\n",
            "[Epoch 188/200] [Batch 39/200] [D loss: 0.000569] [G loss: 0.019400]\n",
            "[Epoch 188/200] [Batch 40/200] [D loss: 0.000153] [G loss: 0.017136]\n",
            "[Epoch 188/200] [Batch 41/200] [D loss: 0.000260] [G loss: 0.016413]\n",
            "[Epoch 188/200] [Batch 42/200] [D loss: 0.000276] [G loss: 0.017773]\n",
            "[Epoch 188/200] [Batch 43/200] [D loss: 0.000282] [G loss: 0.016248]\n",
            "[Epoch 188/200] [Batch 44/200] [D loss: 0.000210] [G loss: 0.016675]\n",
            "[Epoch 188/200] [Batch 45/200] [D loss: 0.000115] [G loss: 0.019519]\n",
            "[Epoch 188/200] [Batch 46/200] [D loss: 0.000202] [G loss: 0.014875]\n",
            "[Epoch 188/200] [Batch 47/200] [D loss: 0.000297] [G loss: 0.022070]\n",
            "[Epoch 188/200] [Batch 48/200] [D loss: 0.000201] [G loss: 0.020810]\n",
            "[Epoch 188/200] [Batch 49/200] [D loss: 0.000232] [G loss: 0.015049]\n",
            "[Epoch 188/200] [Batch 50/200] [D loss: 0.000396] [G loss: 0.016848]\n",
            "[Epoch 188/200] [Batch 51/200] [D loss: 0.000387] [G loss: 0.017312]\n",
            "[Epoch 188/200] [Batch 52/200] [D loss: 0.000120] [G loss: 0.015445]\n",
            "[Epoch 188/200] [Batch 53/200] [D loss: 0.000149] [G loss: 0.016956]\n",
            "[Epoch 188/200] [Batch 54/200] [D loss: 0.000203] [G loss: 0.020749]\n",
            "[Epoch 188/200] [Batch 55/200] [D loss: 0.000058] [G loss: 0.016618]\n",
            "[Epoch 188/200] [Batch 56/200] [D loss: 0.000264] [G loss: 0.018936]\n",
            "[Epoch 188/200] [Batch 57/200] [D loss: 0.000453] [G loss: 0.015423]\n",
            "[Epoch 188/200] [Batch 58/200] [D loss: 0.000416] [G loss: 0.019261]\n",
            "[Epoch 188/200] [Batch 59/200] [D loss: 0.000231] [G loss: 0.015626]\n",
            "[Epoch 188/200] [Batch 60/200] [D loss: 0.000162] [G loss: 0.013925]\n",
            "[Epoch 188/200] [Batch 61/200] [D loss: 0.000360] [G loss: 0.021750]\n",
            "[Epoch 188/200] [Batch 62/200] [D loss: 0.000245] [G loss: 0.019106]\n",
            "[Epoch 188/200] [Batch 63/200] [D loss: 0.000109] [G loss: 0.018006]\n",
            "[Epoch 188/200] [Batch 64/200] [D loss: 0.000097] [G loss: 0.017338]\n",
            "[Epoch 188/200] [Batch 65/200] [D loss: 0.000520] [G loss: 0.018425]\n",
            "[Epoch 188/200] [Batch 66/200] [D loss: 0.001399] [G loss: 0.017184]\n",
            "[Epoch 188/200] [Batch 67/200] [D loss: 0.000863] [G loss: 0.016830]\n",
            "[Epoch 188/200] [Batch 68/200] [D loss: 0.000685] [G loss: 0.019661]\n",
            "[Epoch 188/200] [Batch 69/200] [D loss: 0.001176] [G loss: 0.018399]\n",
            "[Epoch 188/200] [Batch 70/200] [D loss: 0.000311] [G loss: 0.014203]\n",
            "[Epoch 188/200] [Batch 71/200] [D loss: 0.000104] [G loss: 0.022312]\n",
            "[Epoch 188/200] [Batch 72/200] [D loss: 0.000123] [G loss: 0.019498]\n",
            "[Epoch 188/200] [Batch 73/200] [D loss: 0.000104] [G loss: 0.020108]\n",
            "[Epoch 188/200] [Batch 74/200] [D loss: 0.000138] [G loss: 0.018375]\n",
            "[Epoch 188/200] [Batch 75/200] [D loss: 0.000121] [G loss: 0.015863]\n",
            "[Epoch 188/200] [Batch 76/200] [D loss: 0.000079] [G loss: 0.018549]\n",
            "[Epoch 188/200] [Batch 77/200] [D loss: 0.000098] [G loss: 0.016797]\n",
            "[Epoch 188/200] [Batch 78/200] [D loss: 0.000177] [G loss: 0.021373]\n",
            "[Epoch 188/200] [Batch 79/200] [D loss: 0.000107] [G loss: 0.019521]\n",
            "[Epoch 188/200] [Batch 80/200] [D loss: 0.000155] [G loss: 0.015437]\n",
            "[Epoch 188/200] [Batch 81/200] [D loss: 0.000096] [G loss: 0.020116]\n",
            "[Epoch 188/200] [Batch 82/200] [D loss: 0.000071] [G loss: 0.020747]\n",
            "[Epoch 188/200] [Batch 83/200] [D loss: 0.000070] [G loss: 0.021056]\n",
            "[Epoch 188/200] [Batch 84/200] [D loss: 0.000057] [G loss: 0.015779]\n",
            "[Epoch 188/200] [Batch 85/200] [D loss: 0.000073] [G loss: 0.017155]\n",
            "[Epoch 188/200] [Batch 86/200] [D loss: 0.000073] [G loss: 0.017668]\n",
            "[Epoch 188/200] [Batch 87/200] [D loss: 0.000081] [G loss: 0.016660]\n",
            "[Epoch 188/200] [Batch 88/200] [D loss: 0.000080] [G loss: 0.017638]\n",
            "[Epoch 188/200] [Batch 89/200] [D loss: 0.000059] [G loss: 0.015768]\n",
            "[Epoch 188/200] [Batch 90/200] [D loss: 0.000095] [G loss: 0.017962]\n",
            "[Epoch 188/200] [Batch 91/200] [D loss: 0.000150] [G loss: 0.018787]\n",
            "[Epoch 188/200] [Batch 92/200] [D loss: 0.000260] [G loss: 0.018496]\n",
            "[Epoch 188/200] [Batch 93/200] [D loss: 0.000407] [G loss: 0.019234]\n",
            "[Epoch 188/200] [Batch 94/200] [D loss: 0.000241] [G loss: 0.014835]\n",
            "[Epoch 188/200] [Batch 95/200] [D loss: 0.000169] [G loss: 0.014629]\n",
            "[Epoch 188/200] [Batch 96/200] [D loss: 0.000351] [G loss: 0.016723]\n",
            "[Epoch 188/200] [Batch 97/200] [D loss: 0.000836] [G loss: 0.014546]\n",
            "[Epoch 188/200] [Batch 98/200] [D loss: 0.002104] [G loss: 0.019833]\n",
            "[Epoch 188/200] [Batch 99/200] [D loss: 0.000571] [G loss: 0.016716]\n",
            "[Epoch 188/200] [Batch 100/200] [D loss: 0.000568] [G loss: 0.020464]\n",
            "[Epoch 188/200] [Batch 101/200] [D loss: 0.000893] [G loss: 0.020953]\n",
            "[Epoch 188/200] [Batch 102/200] [D loss: 0.000589] [G loss: 0.015139]\n",
            "[Epoch 188/200] [Batch 103/200] [D loss: 0.000384] [G loss: 0.017414]\n",
            "[Epoch 188/200] [Batch 104/200] [D loss: 0.000519] [G loss: 0.017457]\n",
            "[Epoch 188/200] [Batch 105/200] [D loss: 0.000265] [G loss: 0.015536]\n",
            "[Epoch 188/200] [Batch 106/200] [D loss: 0.000120] [G loss: 0.021272]\n",
            "[Epoch 188/200] [Batch 107/200] [D loss: 0.000089] [G loss: 0.015740]\n",
            "[Epoch 188/200] [Batch 108/200] [D loss: 0.000156] [G loss: 0.020431]\n",
            "[Epoch 188/200] [Batch 109/200] [D loss: 0.000429] [G loss: 0.016831]\n",
            "[Epoch 188/200] [Batch 110/200] [D loss: 0.000300] [G loss: 0.019869]\n",
            "[Epoch 188/200] [Batch 111/200] [D loss: 0.000142] [G loss: 0.020103]\n",
            "[Epoch 188/200] [Batch 112/200] [D loss: 0.000103] [G loss: 0.021196]\n",
            "[Epoch 188/200] [Batch 113/200] [D loss: 0.000099] [G loss: 0.019477]\n",
            "[Epoch 188/200] [Batch 114/200] [D loss: 0.000129] [G loss: 0.019837]\n",
            "[Epoch 188/200] [Batch 115/200] [D loss: 0.000193] [G loss: 0.019076]\n",
            "[Epoch 188/200] [Batch 116/200] [D loss: 0.000130] [G loss: 0.016248]\n",
            "[Epoch 188/200] [Batch 117/200] [D loss: 0.000139] [G loss: 0.016782]\n",
            "[Epoch 188/200] [Batch 118/200] [D loss: 0.000139] [G loss: 0.018945]\n",
            "[Epoch 188/200] [Batch 119/200] [D loss: 0.000151] [G loss: 0.020968]\n",
            "[Epoch 188/200] [Batch 120/200] [D loss: 0.000421] [G loss: 0.019338]\n",
            "[Epoch 188/200] [Batch 121/200] [D loss: 0.000169] [G loss: 0.019197]\n",
            "[Epoch 188/200] [Batch 122/200] [D loss: 0.000248] [G loss: 0.017182]\n",
            "[Epoch 188/200] [Batch 123/200] [D loss: 0.000205] [G loss: 0.018328]\n",
            "[Epoch 188/200] [Batch 124/200] [D loss: 0.000115] [G loss: 0.015345]\n",
            "[Epoch 188/200] [Batch 125/200] [D loss: 0.000177] [G loss: 0.016506]\n",
            "[Epoch 188/200] [Batch 126/200] [D loss: 0.000087] [G loss: 0.016808]\n",
            "[Epoch 188/200] [Batch 127/200] [D loss: 0.000091] [G loss: 0.017964]\n",
            "[Epoch 188/200] [Batch 128/200] [D loss: 0.000100] [G loss: 0.018843]\n",
            "[Epoch 188/200] [Batch 129/200] [D loss: 0.000113] [G loss: 0.014630]\n",
            "[Epoch 188/200] [Batch 130/200] [D loss: 0.000099] [G loss: 0.021055]\n",
            "[Epoch 188/200] [Batch 131/200] [D loss: 0.000085] [G loss: 0.015359]\n",
            "[Epoch 188/200] [Batch 132/200] [D loss: 0.000080] [G loss: 0.012917]\n",
            "[Epoch 188/200] [Batch 133/200] [D loss: 0.000099] [G loss: 0.020503]\n",
            "[Epoch 188/200] [Batch 134/200] [D loss: 0.000098] [G loss: 0.019074]\n",
            "[Epoch 188/200] [Batch 135/200] [D loss: 0.000148] [G loss: 0.016211]\n",
            "[Epoch 188/200] [Batch 136/200] [D loss: 0.000079] [G loss: 0.018639]\n",
            "[Epoch 188/200] [Batch 137/200] [D loss: 0.000175] [G loss: 0.017365]\n",
            "[Epoch 188/200] [Batch 138/200] [D loss: 0.000074] [G loss: 0.021118]\n",
            "[Epoch 188/200] [Batch 139/200] [D loss: 0.000057] [G loss: 0.014835]\n",
            "[Epoch 188/200] [Batch 140/200] [D loss: 0.000081] [G loss: 0.019740]\n",
            "[Epoch 188/200] [Batch 141/200] [D loss: 0.000045] [G loss: 0.016682]\n",
            "[Epoch 188/200] [Batch 142/200] [D loss: 0.000062] [G loss: 0.015832]\n",
            "[Epoch 188/200] [Batch 143/200] [D loss: 0.000069] [G loss: 0.017379]\n",
            "[Epoch 188/200] [Batch 144/200] [D loss: 0.000137] [G loss: 0.016790]\n",
            "[Epoch 188/200] [Batch 145/200] [D loss: 0.000222] [G loss: 0.018815]\n",
            "[Epoch 188/200] [Batch 146/200] [D loss: 0.000170] [G loss: 0.017584]\n",
            "[Epoch 188/200] [Batch 147/200] [D loss: 0.000077] [G loss: 0.019755]\n",
            "[Epoch 188/200] [Batch 148/200] [D loss: 0.000087] [G loss: 0.017818]\n",
            "[Epoch 188/200] [Batch 149/200] [D loss: 0.000097] [G loss: 0.016865]\n",
            "[Epoch 188/200] [Batch 150/200] [D loss: 0.000115] [G loss: 0.021451]\n",
            "[Epoch 188/200] [Batch 151/200] [D loss: 0.000223] [G loss: 0.021653]\n",
            "[Epoch 188/200] [Batch 152/200] [D loss: 0.000094] [G loss: 0.016488]\n",
            "[Epoch 188/200] [Batch 153/200] [D loss: 0.000105] [G loss: 0.015214]\n",
            "[Epoch 188/200] [Batch 154/200] [D loss: 0.000192] [G loss: 0.019586]\n",
            "[Epoch 188/200] [Batch 155/200] [D loss: 0.000060] [G loss: 0.013963]\n",
            "[Epoch 188/200] [Batch 156/200] [D loss: 0.000108] [G loss: 0.018427]\n",
            "[Epoch 188/200] [Batch 157/200] [D loss: 0.000117] [G loss: 0.014806]\n",
            "[Epoch 188/200] [Batch 158/200] [D loss: 0.000115] [G loss: 0.014049]\n",
            "[Epoch 188/200] [Batch 159/200] [D loss: 0.000061] [G loss: 0.018013]\n",
            "[Epoch 188/200] [Batch 160/200] [D loss: 0.000095] [G loss: 0.016838]\n",
            "[Epoch 188/200] [Batch 161/200] [D loss: 0.000105] [G loss: 0.016937]\n",
            "[Epoch 188/200] [Batch 162/200] [D loss: 0.000057] [G loss: 0.018255]\n",
            "[Epoch 188/200] [Batch 163/200] [D loss: 0.000080] [G loss: 0.015443]\n",
            "[Epoch 188/200] [Batch 164/200] [D loss: 0.000089] [G loss: 0.017494]\n",
            "[Epoch 188/200] [Batch 165/200] [D loss: 0.000050] [G loss: 0.019533]\n",
            "[Epoch 188/200] [Batch 166/200] [D loss: 0.000094] [G loss: 0.018841]\n",
            "[Epoch 188/200] [Batch 167/200] [D loss: 0.000125] [G loss: 0.021116]\n",
            "[Epoch 188/200] [Batch 168/200] [D loss: 0.000254] [G loss: 0.019220]\n",
            "[Epoch 188/200] [Batch 169/200] [D loss: 0.000217] [G loss: 0.018651]\n",
            "[Epoch 188/200] [Batch 170/200] [D loss: 0.000074] [G loss: 0.015498]\n",
            "[Epoch 188/200] [Batch 171/200] [D loss: 0.000050] [G loss: 0.014264]\n",
            "[Epoch 188/200] [Batch 172/200] [D loss: 0.000088] [G loss: 0.020425]\n",
            "[Epoch 188/200] [Batch 173/200] [D loss: 0.000113] [G loss: 0.016146]\n",
            "[Epoch 188/200] [Batch 174/200] [D loss: 0.000101] [G loss: 0.016035]\n",
            "[Epoch 188/200] [Batch 175/200] [D loss: 0.000079] [G loss: 0.017831]\n",
            "[Epoch 188/200] [Batch 176/200] [D loss: 0.000078] [G loss: 0.019155]\n",
            "[Epoch 188/200] [Batch 177/200] [D loss: 0.000054] [G loss: 0.018372]\n",
            "[Epoch 188/200] [Batch 178/200] [D loss: 0.000108] [G loss: 0.020016]\n",
            "[Epoch 188/200] [Batch 179/200] [D loss: 0.000075] [G loss: 0.015328]\n",
            "[Epoch 188/200] [Batch 180/200] [D loss: 0.000077] [G loss: 0.018759]\n",
            "[Epoch 188/200] [Batch 181/200] [D loss: 0.000086] [G loss: 0.014460]\n",
            "[Epoch 188/200] [Batch 182/200] [D loss: 0.000111] [G loss: 0.016639]\n",
            "[Epoch 188/200] [Batch 183/200] [D loss: 0.000143] [G loss: 0.018136]\n",
            "[Epoch 188/200] [Batch 184/200] [D loss: 0.000181] [G loss: 0.019252]\n",
            "[Epoch 188/200] [Batch 185/200] [D loss: 0.000099] [G loss: 0.016761]\n",
            "[Epoch 188/200] [Batch 186/200] [D loss: 0.000171] [G loss: 0.017337]\n",
            "[Epoch 188/200] [Batch 187/200] [D loss: 0.000247] [G loss: 0.020321]\n",
            "[Epoch 188/200] [Batch 188/200] [D loss: 0.000296] [G loss: 0.015119]\n",
            "[Epoch 188/200] [Batch 189/200] [D loss: 0.000113] [G loss: 0.017801]\n",
            "[Epoch 188/200] [Batch 190/200] [D loss: 0.000078] [G loss: 0.018564]\n",
            "[Epoch 188/200] [Batch 191/200] [D loss: 0.000148] [G loss: 0.015632]\n",
            "[Epoch 188/200] [Batch 192/200] [D loss: 0.000190] [G loss: 0.017686]\n",
            "[Epoch 188/200] [Batch 193/200] [D loss: 0.000079] [G loss: 0.015686]\n",
            "[Epoch 188/200] [Batch 194/200] [D loss: 0.000062] [G loss: 0.021746]\n",
            "[Epoch 188/200] [Batch 195/200] [D loss: 0.000100] [G loss: 0.020099]\n",
            "[Epoch 188/200] [Batch 196/200] [D loss: 0.000101] [G loss: 0.022410]\n",
            "[Epoch 188/200] [Batch 197/200] [D loss: 0.000066] [G loss: 0.016672]\n",
            "[Epoch 188/200] [Batch 198/200] [D loss: 0.000088] [G loss: 0.015890]\n",
            "[Epoch 188/200] [Batch 199/200] [D loss: 0.000124] [G loss: 0.019458]\n",
            "[Epoch 189/200] [Batch 0/200] [D loss: 0.000125] [G loss: 0.017167]\n",
            "[Epoch 189/200] [Batch 1/200] [D loss: 0.000093] [G loss: 0.015680]\n",
            "[Epoch 189/200] [Batch 2/200] [D loss: 0.000256] [G loss: 0.018545]\n",
            "[Epoch 189/200] [Batch 3/200] [D loss: 0.000565] [G loss: 0.016904]\n",
            "[Epoch 189/200] [Batch 4/200] [D loss: 0.000190] [G loss: 0.018846]\n",
            "[Epoch 189/200] [Batch 5/200] [D loss: 0.000396] [G loss: 0.019719]\n",
            "[Epoch 189/200] [Batch 6/200] [D loss: 0.000257] [G loss: 0.015591]\n",
            "[Epoch 189/200] [Batch 7/200] [D loss: 0.000111] [G loss: 0.020658]\n",
            "[Epoch 189/200] [Batch 8/200] [D loss: 0.000106] [G loss: 0.016679]\n",
            "[Epoch 189/200] [Batch 9/200] [D loss: 0.000103] [G loss: 0.020404]\n",
            "[Epoch 189/200] [Batch 10/200] [D loss: 0.000284] [G loss: 0.013020]\n",
            "[Epoch 189/200] [Batch 11/200] [D loss: 0.000348] [G loss: 0.020117]\n",
            "[Epoch 189/200] [Batch 12/200] [D loss: 0.000254] [G loss: 0.020262]\n",
            "[Epoch 189/200] [Batch 13/200] [D loss: 0.000075] [G loss: 0.019051]\n",
            "[Epoch 189/200] [Batch 14/200] [D loss: 0.000167] [G loss: 0.019859]\n",
            "[Epoch 189/200] [Batch 15/200] [D loss: 0.000241] [G loss: 0.024881]\n",
            "[Epoch 189/200] [Batch 16/200] [D loss: 0.000384] [G loss: 0.016509]\n",
            "[Epoch 189/200] [Batch 17/200] [D loss: 0.000213] [G loss: 0.014188]\n",
            "[Epoch 189/200] [Batch 18/200] [D loss: 0.000092] [G loss: 0.013583]\n",
            "[Epoch 189/200] [Batch 19/200] [D loss: 0.000125] [G loss: 0.016702]\n",
            "[Epoch 189/200] [Batch 20/200] [D loss: 0.000314] [G loss: 0.018956]\n",
            "[Epoch 189/200] [Batch 21/200] [D loss: 0.000407] [G loss: 0.018035]\n",
            "[Epoch 189/200] [Batch 22/200] [D loss: 0.000088] [G loss: 0.015474]\n",
            "[Epoch 189/200] [Batch 23/200] [D loss: 0.000351] [G loss: 0.016709]\n",
            "[Epoch 189/200] [Batch 24/200] [D loss: 0.000370] [G loss: 0.019944]\n",
            "[Epoch 189/200] [Batch 25/200] [D loss: 0.000206] [G loss: 0.017514]\n",
            "[Epoch 189/200] [Batch 26/200] [D loss: 0.000256] [G loss: 0.013515]\n",
            "[Epoch 189/200] [Batch 27/200] [D loss: 0.000108] [G loss: 0.017866]\n",
            "[Epoch 189/200] [Batch 28/200] [D loss: 0.000215] [G loss: 0.021067]\n",
            "[Epoch 189/200] [Batch 29/200] [D loss: 0.000171] [G loss: 0.017112]\n",
            "[Epoch 189/200] [Batch 30/200] [D loss: 0.000160] [G loss: 0.018022]\n",
            "[Epoch 189/200] [Batch 31/200] [D loss: 0.000227] [G loss: 0.019681]\n",
            "[Epoch 189/200] [Batch 32/200] [D loss: 0.000129] [G loss: 0.016921]\n",
            "[Epoch 189/200] [Batch 33/200] [D loss: 0.000062] [G loss: 0.015496]\n",
            "[Epoch 189/200] [Batch 34/200] [D loss: 0.000057] [G loss: 0.019421]\n",
            "[Epoch 189/200] [Batch 35/200] [D loss: 0.000084] [G loss: 0.015454]\n",
            "[Epoch 189/200] [Batch 36/200] [D loss: 0.000073] [G loss: 0.019388]\n",
            "[Epoch 189/200] [Batch 37/200] [D loss: 0.000126] [G loss: 0.017774]\n",
            "[Epoch 189/200] [Batch 38/200] [D loss: 0.000143] [G loss: 0.014030]\n",
            "[Epoch 189/200] [Batch 39/200] [D loss: 0.000067] [G loss: 0.016112]\n",
            "[Epoch 189/200] [Batch 40/200] [D loss: 0.000117] [G loss: 0.015913]\n",
            "[Epoch 189/200] [Batch 41/200] [D loss: 0.000104] [G loss: 0.016010]\n",
            "[Epoch 189/200] [Batch 42/200] [D loss: 0.000108] [G loss: 0.017634]\n",
            "[Epoch 189/200] [Batch 43/200] [D loss: 0.000142] [G loss: 0.019214]\n",
            "[Epoch 189/200] [Batch 44/200] [D loss: 0.000170] [G loss: 0.013162]\n",
            "[Epoch 189/200] [Batch 45/200] [D loss: 0.000193] [G loss: 0.015836]\n",
            "[Epoch 189/200] [Batch 46/200] [D loss: 0.000144] [G loss: 0.016197]\n",
            "[Epoch 189/200] [Batch 47/200] [D loss: 0.000150] [G loss: 0.020555]\n",
            "[Epoch 189/200] [Batch 48/200] [D loss: 0.000117] [G loss: 0.016952]\n",
            "[Epoch 189/200] [Batch 49/200] [D loss: 0.000139] [G loss: 0.015559]\n",
            "[Epoch 189/200] [Batch 50/200] [D loss: 0.000110] [G loss: 0.017013]\n",
            "[Epoch 189/200] [Batch 51/200] [D loss: 0.000095] [G loss: 0.016759]\n",
            "[Epoch 189/200] [Batch 52/200] [D loss: 0.000201] [G loss: 0.016397]\n",
            "[Epoch 189/200] [Batch 53/200] [D loss: 0.000119] [G loss: 0.019686]\n",
            "[Epoch 189/200] [Batch 54/200] [D loss: 0.000086] [G loss: 0.019709]\n",
            "[Epoch 189/200] [Batch 55/200] [D loss: 0.000104] [G loss: 0.017550]\n",
            "[Epoch 189/200] [Batch 56/200] [D loss: 0.000077] [G loss: 0.019095]\n",
            "[Epoch 189/200] [Batch 57/200] [D loss: 0.000102] [G loss: 0.015280]\n",
            "[Epoch 189/200] [Batch 58/200] [D loss: 0.000114] [G loss: 0.017204]\n",
            "[Epoch 189/200] [Batch 59/200] [D loss: 0.000102] [G loss: 0.017614]\n",
            "[Epoch 189/200] [Batch 60/200] [D loss: 0.000072] [G loss: 0.017492]\n",
            "[Epoch 189/200] [Batch 61/200] [D loss: 0.000239] [G loss: 0.018951]\n",
            "[Epoch 189/200] [Batch 62/200] [D loss: 0.000864] [G loss: 0.013902]\n",
            "[Epoch 189/200] [Batch 63/200] [D loss: 0.000862] [G loss: 0.016922]\n",
            "[Epoch 189/200] [Batch 64/200] [D loss: 0.000130] [G loss: 0.016008]\n",
            "[Epoch 189/200] [Batch 65/200] [D loss: 0.000354] [G loss: 0.018860]\n",
            "[Epoch 189/200] [Batch 66/200] [D loss: 0.000172] [G loss: 0.017220]\n",
            "[Epoch 189/200] [Batch 67/200] [D loss: 0.000145] [G loss: 0.021059]\n",
            "[Epoch 189/200] [Batch 68/200] [D loss: 0.000117] [G loss: 0.020576]\n",
            "[Epoch 189/200] [Batch 69/200] [D loss: 0.000083] [G loss: 0.020464]\n",
            "[Epoch 189/200] [Batch 70/200] [D loss: 0.000124] [G loss: 0.018263]\n",
            "[Epoch 189/200] [Batch 71/200] [D loss: 0.000181] [G loss: 0.017389]\n",
            "[Epoch 189/200] [Batch 72/200] [D loss: 0.000099] [G loss: 0.018038]\n",
            "[Epoch 189/200] [Batch 73/200] [D loss: 0.000118] [G loss: 0.015328]\n",
            "[Epoch 189/200] [Batch 74/200] [D loss: 0.000166] [G loss: 0.016298]\n",
            "[Epoch 189/200] [Batch 75/200] [D loss: 0.000225] [G loss: 0.022285]\n",
            "[Epoch 189/200] [Batch 76/200] [D loss: 0.000125] [G loss: 0.017390]\n",
            "[Epoch 189/200] [Batch 77/200] [D loss: 0.000148] [G loss: 0.015108]\n",
            "[Epoch 189/200] [Batch 78/200] [D loss: 0.000100] [G loss: 0.015888]\n",
            "[Epoch 189/200] [Batch 79/200] [D loss: 0.000176] [G loss: 0.018318]\n",
            "[Epoch 189/200] [Batch 80/200] [D loss: 0.000058] [G loss: 0.015360]\n",
            "[Epoch 189/200] [Batch 81/200] [D loss: 0.000106] [G loss: 0.018364]\n",
            "[Epoch 189/200] [Batch 82/200] [D loss: 0.000089] [G loss: 0.018088]\n",
            "[Epoch 189/200] [Batch 83/200] [D loss: 0.000097] [G loss: 0.018784]\n",
            "[Epoch 189/200] [Batch 84/200] [D loss: 0.000099] [G loss: 0.014107]\n",
            "[Epoch 189/200] [Batch 85/200] [D loss: 0.000078] [G loss: 0.016057]\n",
            "[Epoch 189/200] [Batch 86/200] [D loss: 0.000112] [G loss: 0.014139]\n",
            "[Epoch 189/200] [Batch 87/200] [D loss: 0.000265] [G loss: 0.016169]\n",
            "[Epoch 189/200] [Batch 88/200] [D loss: 0.000475] [G loss: 0.019727]\n",
            "[Epoch 189/200] [Batch 89/200] [D loss: 0.000471] [G loss: 0.023457]\n",
            "[Epoch 189/200] [Batch 90/200] [D loss: 0.000307] [G loss: 0.020861]\n",
            "[Epoch 189/200] [Batch 91/200] [D loss: 0.000125] [G loss: 0.019096]\n",
            "[Epoch 189/200] [Batch 92/200] [D loss: 0.000251] [G loss: 0.012494]\n",
            "[Epoch 189/200] [Batch 93/200] [D loss: 0.000298] [G loss: 0.020030]\n",
            "[Epoch 189/200] [Batch 94/200] [D loss: 0.000159] [G loss: 0.015395]\n",
            "[Epoch 189/200] [Batch 95/200] [D loss: 0.000108] [G loss: 0.018026]\n",
            "[Epoch 189/200] [Batch 96/200] [D loss: 0.000130] [G loss: 0.016735]\n",
            "[Epoch 189/200] [Batch 97/200] [D loss: 0.000084] [G loss: 0.017588]\n",
            "[Epoch 189/200] [Batch 98/200] [D loss: 0.000208] [G loss: 0.021490]\n",
            "[Epoch 189/200] [Batch 99/200] [D loss: 0.000228] [G loss: 0.016617]\n",
            "[Epoch 189/200] [Batch 100/200] [D loss: 0.000198] [G loss: 0.017535]\n",
            "[Epoch 189/200] [Batch 101/200] [D loss: 0.000159] [G loss: 0.018665]\n",
            "[Epoch 189/200] [Batch 102/200] [D loss: 0.000096] [G loss: 0.014227]\n",
            "[Epoch 189/200] [Batch 103/200] [D loss: 0.000069] [G loss: 0.020513]\n",
            "[Epoch 189/200] [Batch 104/200] [D loss: 0.000076] [G loss: 0.020367]\n",
            "[Epoch 189/200] [Batch 105/200] [D loss: 0.000104] [G loss: 0.013690]\n",
            "[Epoch 189/200] [Batch 106/200] [D loss: 0.000092] [G loss: 0.019016]\n",
            "[Epoch 189/200] [Batch 107/200] [D loss: 0.000093] [G loss: 0.018127]\n",
            "[Epoch 189/200] [Batch 108/200] [D loss: 0.000084] [G loss: 0.017027]\n",
            "[Epoch 189/200] [Batch 109/200] [D loss: 0.000061] [G loss: 0.017553]\n",
            "[Epoch 189/200] [Batch 110/200] [D loss: 0.000102] [G loss: 0.016147]\n",
            "[Epoch 189/200] [Batch 111/200] [D loss: 0.000291] [G loss: 0.017615]\n",
            "[Epoch 189/200] [Batch 112/200] [D loss: 0.000477] [G loss: 0.015253]\n",
            "[Epoch 189/200] [Batch 113/200] [D loss: 0.000955] [G loss: 0.018314]\n",
            "[Epoch 189/200] [Batch 114/200] [D loss: 0.000346] [G loss: 0.012961]\n",
            "[Epoch 189/200] [Batch 115/200] [D loss: 0.000625] [G loss: 0.017698]\n",
            "[Epoch 189/200] [Batch 116/200] [D loss: 0.000418] [G loss: 0.019906]\n",
            "[Epoch 189/200] [Batch 117/200] [D loss: 0.000255] [G loss: 0.014571]\n",
            "[Epoch 189/200] [Batch 118/200] [D loss: 0.000262] [G loss: 0.017566]\n",
            "[Epoch 189/200] [Batch 119/200] [D loss: 0.000163] [G loss: 0.020082]\n",
            "[Epoch 189/200] [Batch 120/200] [D loss: 0.000283] [G loss: 0.015552]\n",
            "[Epoch 189/200] [Batch 121/200] [D loss: 0.000759] [G loss: 0.019910]\n",
            "[Epoch 189/200] [Batch 122/200] [D loss: 0.000178] [G loss: 0.019245]\n",
            "[Epoch 189/200] [Batch 123/200] [D loss: 0.000401] [G loss: 0.015407]\n",
            "[Epoch 189/200] [Batch 124/200] [D loss: 0.000539] [G loss: 0.016858]\n",
            "[Epoch 189/200] [Batch 125/200] [D loss: 0.000787] [G loss: 0.012295]\n",
            "[Epoch 189/200] [Batch 126/200] [D loss: 0.000480] [G loss: 0.016349]\n",
            "[Epoch 189/200] [Batch 127/200] [D loss: 0.000224] [G loss: 0.018216]\n",
            "[Epoch 189/200] [Batch 128/200] [D loss: 0.000178] [G loss: 0.014889]\n",
            "[Epoch 189/200] [Batch 129/200] [D loss: 0.000113] [G loss: 0.017258]\n",
            "[Epoch 189/200] [Batch 130/200] [D loss: 0.000105] [G loss: 0.015746]\n",
            "[Epoch 189/200] [Batch 131/200] [D loss: 0.000170] [G loss: 0.018304]\n",
            "[Epoch 189/200] [Batch 132/200] [D loss: 0.000380] [G loss: 0.018720]\n",
            "[Epoch 189/200] [Batch 133/200] [D loss: 0.000234] [G loss: 0.018769]\n",
            "[Epoch 189/200] [Batch 134/200] [D loss: 0.000200] [G loss: 0.017983]\n",
            "[Epoch 189/200] [Batch 135/200] [D loss: 0.000289] [G loss: 0.018171]\n",
            "[Epoch 189/200] [Batch 136/200] [D loss: 0.000120] [G loss: 0.017497]\n",
            "[Epoch 189/200] [Batch 137/200] [D loss: 0.000159] [G loss: 0.016815]\n",
            "[Epoch 189/200] [Batch 138/200] [D loss: 0.000191] [G loss: 0.019341]\n",
            "[Epoch 189/200] [Batch 139/200] [D loss: 0.000145] [G loss: 0.019471]\n",
            "[Epoch 189/200] [Batch 140/200] [D loss: 0.000349] [G loss: 0.020368]\n",
            "[Epoch 189/200] [Batch 141/200] [D loss: 0.000210] [G loss: 0.014178]\n",
            "[Epoch 189/200] [Batch 142/200] [D loss: 0.000360] [G loss: 0.017555]\n",
            "[Epoch 189/200] [Batch 143/200] [D loss: 0.000782] [G loss: 0.020463]\n",
            "[Epoch 189/200] [Batch 144/200] [D loss: 0.000195] [G loss: 0.016801]\n",
            "[Epoch 189/200] [Batch 145/200] [D loss: 0.000228] [G loss: 0.015885]\n",
            "[Epoch 189/200] [Batch 146/200] [D loss: 0.000172] [G loss: 0.018542]\n",
            "[Epoch 189/200] [Batch 147/200] [D loss: 0.000253] [G loss: 0.016802]\n",
            "[Epoch 189/200] [Batch 148/200] [D loss: 0.000544] [G loss: 0.018680]\n",
            "[Epoch 189/200] [Batch 149/200] [D loss: 0.000266] [G loss: 0.015131]\n",
            "[Epoch 189/200] [Batch 150/200] [D loss: 0.000525] [G loss: 0.015808]\n",
            "[Epoch 189/200] [Batch 151/200] [D loss: 0.000678] [G loss: 0.020727]\n",
            "[Epoch 189/200] [Batch 152/200] [D loss: 0.000289] [G loss: 0.016903]\n",
            "[Epoch 189/200] [Batch 153/200] [D loss: 0.000372] [G loss: 0.021737]\n",
            "[Epoch 189/200] [Batch 154/200] [D loss: 0.000258] [G loss: 0.017133]\n",
            "[Epoch 189/200] [Batch 155/200] [D loss: 0.000251] [G loss: 0.017763]\n",
            "[Epoch 189/200] [Batch 156/200] [D loss: 0.000656] [G loss: 0.021874]\n",
            "[Epoch 189/200] [Batch 157/200] [D loss: 0.000477] [G loss: 0.019091]\n",
            "[Epoch 189/200] [Batch 158/200] [D loss: 0.000241] [G loss: 0.017931]\n",
            "[Epoch 189/200] [Batch 159/200] [D loss: 0.000491] [G loss: 0.019835]\n",
            "[Epoch 189/200] [Batch 160/200] [D loss: 0.001165] [G loss: 0.016789]\n",
            "[Epoch 189/200] [Batch 161/200] [D loss: 0.001092] [G loss: 0.019990]\n",
            "[Epoch 189/200] [Batch 162/200] [D loss: 0.000520] [G loss: 0.016766]\n",
            "[Epoch 189/200] [Batch 163/200] [D loss: 0.000195] [G loss: 0.014854]\n",
            "[Epoch 189/200] [Batch 164/200] [D loss: 0.000232] [G loss: 0.020241]\n",
            "[Epoch 189/200] [Batch 165/200] [D loss: 0.000213] [G loss: 0.016896]\n",
            "[Epoch 189/200] [Batch 166/200] [D loss: 0.000183] [G loss: 0.012086]\n",
            "[Epoch 189/200] [Batch 167/200] [D loss: 0.000277] [G loss: 0.015955]\n",
            "[Epoch 189/200] [Batch 168/200] [D loss: 0.000396] [G loss: 0.018295]\n",
            "[Epoch 189/200] [Batch 169/200] [D loss: 0.000608] [G loss: 0.020577]\n",
            "[Epoch 189/200] [Batch 170/200] [D loss: 0.001070] [G loss: 0.019147]\n",
            "[Epoch 189/200] [Batch 171/200] [D loss: 0.001370] [G loss: 0.015815]\n",
            "[Epoch 189/200] [Batch 172/200] [D loss: 0.000719] [G loss: 0.018344]\n",
            "[Epoch 189/200] [Batch 173/200] [D loss: 0.000366] [G loss: 0.015163]\n",
            "[Epoch 189/200] [Batch 174/200] [D loss: 0.000250] [G loss: 0.020228]\n",
            "[Epoch 189/200] [Batch 175/200] [D loss: 0.000340] [G loss: 0.012745]\n",
            "[Epoch 189/200] [Batch 176/200] [D loss: 0.000230] [G loss: 0.019981]\n",
            "[Epoch 189/200] [Batch 177/200] [D loss: 0.000137] [G loss: 0.019044]\n",
            "[Epoch 189/200] [Batch 178/200] [D loss: 0.000519] [G loss: 0.016127]\n",
            "[Epoch 189/200] [Batch 179/200] [D loss: 0.000477] [G loss: 0.020770]\n",
            "[Epoch 189/200] [Batch 180/200] [D loss: 0.000335] [G loss: 0.015124]\n",
            "[Epoch 189/200] [Batch 181/200] [D loss: 0.000259] [G loss: 0.018009]\n",
            "[Epoch 189/200] [Batch 182/200] [D loss: 0.000304] [G loss: 0.017661]\n",
            "[Epoch 189/200] [Batch 183/200] [D loss: 0.000178] [G loss: 0.022377]\n",
            "[Epoch 189/200] [Batch 184/200] [D loss: 0.000233] [G loss: 0.022131]\n",
            "[Epoch 189/200] [Batch 185/200] [D loss: 0.000202] [G loss: 0.020152]\n",
            "[Epoch 189/200] [Batch 186/200] [D loss: 0.000203] [G loss: 0.021497]\n",
            "[Epoch 189/200] [Batch 187/200] [D loss: 0.000623] [G loss: 0.016143]\n",
            "[Epoch 189/200] [Batch 188/200] [D loss: 0.000623] [G loss: 0.018907]\n",
            "[Epoch 189/200] [Batch 189/200] [D loss: 0.000351] [G loss: 0.019391]\n",
            "[Epoch 189/200] [Batch 190/200] [D loss: 0.000216] [G loss: 0.017871]\n",
            "[Epoch 189/200] [Batch 191/200] [D loss: 0.000389] [G loss: 0.016454]\n",
            "[Epoch 189/200] [Batch 192/200] [D loss: 0.000533] [G loss: 0.018475]\n",
            "[Epoch 189/200] [Batch 193/200] [D loss: 0.000375] [G loss: 0.014935]\n",
            "[Epoch 189/200] [Batch 194/200] [D loss: 0.000285] [G loss: 0.016926]\n",
            "[Epoch 189/200] [Batch 195/200] [D loss: 0.000519] [G loss: 0.015883]\n",
            "[Epoch 189/200] [Batch 196/200] [D loss: 0.000224] [G loss: 0.020579]\n",
            "[Epoch 189/200] [Batch 197/200] [D loss: 0.000182] [G loss: 0.015447]\n",
            "[Epoch 189/200] [Batch 198/200] [D loss: 0.000317] [G loss: 0.013692]\n",
            "[Epoch 189/200] [Batch 199/200] [D loss: 0.000148] [G loss: 0.021216]\n",
            "[Epoch 190/200] [Batch 0/200] [D loss: 0.000204] [G loss: 0.016379]\n",
            "[Epoch 190/200] [Batch 1/200] [D loss: 0.000165] [G loss: 0.014362]\n",
            "[Epoch 190/200] [Batch 2/200] [D loss: 0.000276] [G loss: 0.017894]\n",
            "[Epoch 190/200] [Batch 3/200] [D loss: 0.000258] [G loss: 0.017917]\n",
            "[Epoch 190/200] [Batch 4/200] [D loss: 0.000080] [G loss: 0.017617]\n",
            "[Epoch 190/200] [Batch 5/200] [D loss: 0.000122] [G loss: 0.016164]\n",
            "[Epoch 190/200] [Batch 6/200] [D loss: 0.000114] [G loss: 0.016525]\n",
            "[Epoch 190/200] [Batch 7/200] [D loss: 0.000093] [G loss: 0.023547]\n",
            "[Epoch 190/200] [Batch 8/200] [D loss: 0.000102] [G loss: 0.013810]\n",
            "[Epoch 190/200] [Batch 9/200] [D loss: 0.000053] [G loss: 0.015547]\n",
            "[Epoch 190/200] [Batch 10/200] [D loss: 0.000055] [G loss: 0.016798]\n",
            "[Epoch 190/200] [Batch 11/200] [D loss: 0.000074] [G loss: 0.018157]\n",
            "[Epoch 190/200] [Batch 12/200] [D loss: 0.000150] [G loss: 0.015426]\n",
            "[Epoch 190/200] [Batch 13/200] [D loss: 0.000189] [G loss: 0.017335]\n",
            "[Epoch 190/200] [Batch 14/200] [D loss: 0.000141] [G loss: 0.015646]\n",
            "[Epoch 190/200] [Batch 15/200] [D loss: 0.000156] [G loss: 0.021144]\n",
            "[Epoch 190/200] [Batch 16/200] [D loss: 0.000100] [G loss: 0.016430]\n",
            "[Epoch 190/200] [Batch 17/200] [D loss: 0.000114] [G loss: 0.013808]\n",
            "[Epoch 190/200] [Batch 18/200] [D loss: 0.000145] [G loss: 0.020621]\n",
            "[Epoch 190/200] [Batch 19/200] [D loss: 0.000094] [G loss: 0.017040]\n",
            "[Epoch 190/200] [Batch 20/200] [D loss: 0.000047] [G loss: 0.020936]\n",
            "[Epoch 190/200] [Batch 21/200] [D loss: 0.000088] [G loss: 0.016843]\n",
            "[Epoch 190/200] [Batch 22/200] [D loss: 0.000287] [G loss: 0.020900]\n",
            "[Epoch 190/200] [Batch 23/200] [D loss: 0.000395] [G loss: 0.015726]\n",
            "[Epoch 190/200] [Batch 24/200] [D loss: 0.000190] [G loss: 0.015399]\n",
            "[Epoch 190/200] [Batch 25/200] [D loss: 0.000211] [G loss: 0.012550]\n",
            "[Epoch 190/200] [Batch 26/200] [D loss: 0.000447] [G loss: 0.016171]\n",
            "[Epoch 190/200] [Batch 27/200] [D loss: 0.000244] [G loss: 0.015654]\n",
            "[Epoch 190/200] [Batch 28/200] [D loss: 0.000418] [G loss: 0.016943]\n",
            "[Epoch 190/200] [Batch 29/200] [D loss: 0.000458] [G loss: 0.019477]\n",
            "[Epoch 190/200] [Batch 30/200] [D loss: 0.000161] [G loss: 0.012375]\n",
            "[Epoch 190/200] [Batch 31/200] [D loss: 0.000107] [G loss: 0.018348]\n",
            "[Epoch 190/200] [Batch 32/200] [D loss: 0.000171] [G loss: 0.019385]\n",
            "[Epoch 190/200] [Batch 33/200] [D loss: 0.000298] [G loss: 0.014368]\n",
            "[Epoch 190/200] [Batch 34/200] [D loss: 0.000221] [G loss: 0.016348]\n",
            "[Epoch 190/200] [Batch 35/200] [D loss: 0.000086] [G loss: 0.017056]\n",
            "[Epoch 190/200] [Batch 36/200] [D loss: 0.000155] [G loss: 0.018298]\n",
            "[Epoch 190/200] [Batch 37/200] [D loss: 0.000366] [G loss: 0.013565]\n",
            "[Epoch 190/200] [Batch 38/200] [D loss: 0.000225] [G loss: 0.018906]\n",
            "[Epoch 190/200] [Batch 39/200] [D loss: 0.000155] [G loss: 0.017348]\n",
            "[Epoch 190/200] [Batch 40/200] [D loss: 0.000137] [G loss: 0.021207]\n",
            "[Epoch 190/200] [Batch 41/200] [D loss: 0.000083] [G loss: 0.018856]\n",
            "[Epoch 190/200] [Batch 42/200] [D loss: 0.000083] [G loss: 0.017771]\n",
            "[Epoch 190/200] [Batch 43/200] [D loss: 0.000110] [G loss: 0.016451]\n",
            "[Epoch 190/200] [Batch 44/200] [D loss: 0.000170] [G loss: 0.020176]\n",
            "[Epoch 190/200] [Batch 45/200] [D loss: 0.000139] [G loss: 0.018137]\n",
            "[Epoch 190/200] [Batch 46/200] [D loss: 0.000055] [G loss: 0.017897]\n",
            "[Epoch 190/200] [Batch 47/200] [D loss: 0.000131] [G loss: 0.020486]\n",
            "[Epoch 190/200] [Batch 48/200] [D loss: 0.000070] [G loss: 0.016639]\n",
            "[Epoch 190/200] [Batch 49/200] [D loss: 0.000082] [G loss: 0.017712]\n",
            "[Epoch 190/200] [Batch 50/200] [D loss: 0.000080] [G loss: 0.018306]\n",
            "[Epoch 190/200] [Batch 51/200] [D loss: 0.000106] [G loss: 0.017867]\n",
            "[Epoch 190/200] [Batch 52/200] [D loss: 0.000122] [G loss: 0.017503]\n",
            "[Epoch 190/200] [Batch 53/200] [D loss: 0.000113] [G loss: 0.017231]\n",
            "[Epoch 190/200] [Batch 54/200] [D loss: 0.000146] [G loss: 0.017323]\n",
            "[Epoch 190/200] [Batch 55/200] [D loss: 0.000178] [G loss: 0.015825]\n",
            "[Epoch 190/200] [Batch 56/200] [D loss: 0.000124] [G loss: 0.019768]\n",
            "[Epoch 190/200] [Batch 57/200] [D loss: 0.000080] [G loss: 0.017701]\n",
            "[Epoch 190/200] [Batch 58/200] [D loss: 0.000101] [G loss: 0.019198]\n",
            "[Epoch 190/200] [Batch 59/200] [D loss: 0.000151] [G loss: 0.024594]\n",
            "[Epoch 190/200] [Batch 60/200] [D loss: 0.000141] [G loss: 0.015196]\n",
            "[Epoch 190/200] [Batch 61/200] [D loss: 0.000119] [G loss: 0.023641]\n",
            "[Epoch 190/200] [Batch 62/200] [D loss: 0.000086] [G loss: 0.020036]\n",
            "[Epoch 190/200] [Batch 63/200] [D loss: 0.000090] [G loss: 0.022199]\n",
            "[Epoch 190/200] [Batch 64/200] [D loss: 0.000106] [G loss: 0.017348]\n",
            "[Epoch 190/200] [Batch 65/200] [D loss: 0.000198] [G loss: 0.014417]\n",
            "[Epoch 190/200] [Batch 66/200] [D loss: 0.000100] [G loss: 0.017490]\n",
            "[Epoch 190/200] [Batch 67/200] [D loss: 0.000095] [G loss: 0.017958]\n",
            "[Epoch 190/200] [Batch 68/200] [D loss: 0.000106] [G loss: 0.019244]\n",
            "[Epoch 190/200] [Batch 69/200] [D loss: 0.000162] [G loss: 0.017525]\n",
            "[Epoch 190/200] [Batch 70/200] [D loss: 0.000219] [G loss: 0.016491]\n",
            "[Epoch 190/200] [Batch 71/200] [D loss: 0.000138] [G loss: 0.017043]\n",
            "[Epoch 190/200] [Batch 72/200] [D loss: 0.000119] [G loss: 0.023015]\n",
            "[Epoch 190/200] [Batch 73/200] [D loss: 0.000155] [G loss: 0.013873]\n",
            "[Epoch 190/200] [Batch 74/200] [D loss: 0.000116] [G loss: 0.016380]\n",
            "[Epoch 190/200] [Batch 75/200] [D loss: 0.000098] [G loss: 0.015323]\n",
            "[Epoch 190/200] [Batch 76/200] [D loss: 0.000079] [G loss: 0.021237]\n",
            "[Epoch 190/200] [Batch 77/200] [D loss: 0.000070] [G loss: 0.017962]\n",
            "[Epoch 190/200] [Batch 78/200] [D loss: 0.000071] [G loss: 0.015957]\n",
            "[Epoch 190/200] [Batch 79/200] [D loss: 0.000085] [G loss: 0.017276]\n",
            "[Epoch 190/200] [Batch 80/200] [D loss: 0.000094] [G loss: 0.016856]\n",
            "[Epoch 190/200] [Batch 81/200] [D loss: 0.000142] [G loss: 0.017868]\n",
            "[Epoch 190/200] [Batch 82/200] [D loss: 0.000100] [G loss: 0.019098]\n",
            "[Epoch 190/200] [Batch 83/200] [D loss: 0.000311] [G loss: 0.012802]\n",
            "[Epoch 190/200] [Batch 84/200] [D loss: 0.000352] [G loss: 0.016811]\n",
            "[Epoch 190/200] [Batch 85/200] [D loss: 0.000148] [G loss: 0.015397]\n",
            "[Epoch 190/200] [Batch 86/200] [D loss: 0.000099] [G loss: 0.018516]\n",
            "[Epoch 190/200] [Batch 87/200] [D loss: 0.000105] [G loss: 0.017681]\n",
            "[Epoch 190/200] [Batch 88/200] [D loss: 0.000095] [G loss: 0.015996]\n",
            "[Epoch 190/200] [Batch 89/200] [D loss: 0.000081] [G loss: 0.019493]\n",
            "[Epoch 190/200] [Batch 90/200] [D loss: 0.000086] [G loss: 0.017044]\n",
            "[Epoch 190/200] [Batch 91/200] [D loss: 0.000093] [G loss: 0.017898]\n",
            "[Epoch 190/200] [Batch 92/200] [D loss: 0.000097] [G loss: 0.018694]\n",
            "[Epoch 190/200] [Batch 93/200] [D loss: 0.000083] [G loss: 0.019340]\n",
            "[Epoch 190/200] [Batch 94/200] [D loss: 0.000080] [G loss: 0.015997]\n",
            "[Epoch 190/200] [Batch 95/200] [D loss: 0.000165] [G loss: 0.020676]\n",
            "[Epoch 190/200] [Batch 96/200] [D loss: 0.000039] [G loss: 0.016412]\n",
            "[Epoch 190/200] [Batch 97/200] [D loss: 0.000068] [G loss: 0.012783]\n",
            "[Epoch 190/200] [Batch 98/200] [D loss: 0.000198] [G loss: 0.016748]\n",
            "[Epoch 190/200] [Batch 99/200] [D loss: 0.000111] [G loss: 0.017562]\n",
            "[Epoch 190/200] [Batch 100/200] [D loss: 0.000125] [G loss: 0.017580]\n",
            "[Epoch 190/200] [Batch 101/200] [D loss: 0.000100] [G loss: 0.019680]\n",
            "[Epoch 190/200] [Batch 102/200] [D loss: 0.000170] [G loss: 0.019030]\n",
            "[Epoch 190/200] [Batch 103/200] [D loss: 0.000102] [G loss: 0.019248]\n",
            "[Epoch 190/200] [Batch 104/200] [D loss: 0.000097] [G loss: 0.016297]\n",
            "[Epoch 190/200] [Batch 105/200] [D loss: 0.000060] [G loss: 0.015981]\n",
            "[Epoch 190/200] [Batch 106/200] [D loss: 0.000047] [G loss: 0.017762]\n",
            "[Epoch 190/200] [Batch 107/200] [D loss: 0.000089] [G loss: 0.018760]\n",
            "[Epoch 190/200] [Batch 108/200] [D loss: 0.000108] [G loss: 0.018760]\n",
            "[Epoch 190/200] [Batch 109/200] [D loss: 0.000061] [G loss: 0.017540]\n",
            "[Epoch 190/200] [Batch 110/200] [D loss: 0.000190] [G loss: 0.017297]\n",
            "[Epoch 190/200] [Batch 111/200] [D loss: 0.000235] [G loss: 0.019538]\n",
            "[Epoch 190/200] [Batch 112/200] [D loss: 0.000334] [G loss: 0.016454]\n",
            "[Epoch 190/200] [Batch 113/200] [D loss: 0.000182] [G loss: 0.020485]\n",
            "[Epoch 190/200] [Batch 114/200] [D loss: 0.000092] [G loss: 0.016666]\n",
            "[Epoch 190/200] [Batch 115/200] [D loss: 0.000043] [G loss: 0.017190]\n",
            "[Epoch 190/200] [Batch 116/200] [D loss: 0.000088] [G loss: 0.016393]\n",
            "[Epoch 190/200] [Batch 117/200] [D loss: 0.000166] [G loss: 0.017069]\n",
            "[Epoch 190/200] [Batch 118/200] [D loss: 0.000429] [G loss: 0.013545]\n",
            "[Epoch 190/200] [Batch 119/200] [D loss: 0.000432] [G loss: 0.020632]\n",
            "[Epoch 190/200] [Batch 120/200] [D loss: 0.000434] [G loss: 0.017239]\n",
            "[Epoch 190/200] [Batch 121/200] [D loss: 0.000312] [G loss: 0.016541]\n",
            "[Epoch 190/200] [Batch 122/200] [D loss: 0.000503] [G loss: 0.017361]\n",
            "[Epoch 190/200] [Batch 123/200] [D loss: 0.000868] [G loss: 0.020647]\n",
            "[Epoch 190/200] [Batch 124/200] [D loss: 0.000571] [G loss: 0.017331]\n",
            "[Epoch 190/200] [Batch 125/200] [D loss: 0.000120] [G loss: 0.021585]\n",
            "[Epoch 190/200] [Batch 126/200] [D loss: 0.000187] [G loss: 0.016529]\n",
            "[Epoch 190/200] [Batch 127/200] [D loss: 0.000167] [G loss: 0.016499]\n",
            "[Epoch 190/200] [Batch 128/200] [D loss: 0.000123] [G loss: 0.019072]\n",
            "[Epoch 190/200] [Batch 129/200] [D loss: 0.000088] [G loss: 0.014862]\n",
            "[Epoch 190/200] [Batch 130/200] [D loss: 0.000108] [G loss: 0.016818]\n",
            "[Epoch 190/200] [Batch 131/200] [D loss: 0.000464] [G loss: 0.016597]\n",
            "[Epoch 190/200] [Batch 132/200] [D loss: 0.000411] [G loss: 0.019467]\n",
            "[Epoch 190/200] [Batch 133/200] [D loss: 0.000274] [G loss: 0.019742]\n",
            "[Epoch 190/200] [Batch 134/200] [D loss: 0.000187] [G loss: 0.015989]\n",
            "[Epoch 190/200] [Batch 135/200] [D loss: 0.000182] [G loss: 0.015298]\n",
            "[Epoch 190/200] [Batch 136/200] [D loss: 0.000162] [G loss: 0.018904]\n",
            "[Epoch 190/200] [Batch 137/200] [D loss: 0.000131] [G loss: 0.017852]\n",
            "[Epoch 190/200] [Batch 138/200] [D loss: 0.000170] [G loss: 0.018084]\n",
            "[Epoch 190/200] [Batch 139/200] [D loss: 0.000095] [G loss: 0.016614]\n",
            "[Epoch 190/200] [Batch 140/200] [D loss: 0.000111] [G loss: 0.016329]\n",
            "[Epoch 190/200] [Batch 141/200] [D loss: 0.000136] [G loss: 0.016244]\n",
            "[Epoch 190/200] [Batch 142/200] [D loss: 0.000120] [G loss: 0.014237]\n",
            "[Epoch 190/200] [Batch 143/200] [D loss: 0.000119] [G loss: 0.017618]\n",
            "[Epoch 190/200] [Batch 144/200] [D loss: 0.000174] [G loss: 0.019061]\n",
            "[Epoch 190/200] [Batch 145/200] [D loss: 0.000095] [G loss: 0.019261]\n",
            "[Epoch 190/200] [Batch 146/200] [D loss: 0.000270] [G loss: 0.015474]\n",
            "[Epoch 190/200] [Batch 147/200] [D loss: 0.000530] [G loss: 0.015631]\n",
            "[Epoch 190/200] [Batch 148/200] [D loss: 0.000416] [G loss: 0.017930]\n",
            "[Epoch 190/200] [Batch 149/200] [D loss: 0.000173] [G loss: 0.016281]\n",
            "[Epoch 190/200] [Batch 150/200] [D loss: 0.000413] [G loss: 0.015949]\n",
            "[Epoch 190/200] [Batch 151/200] [D loss: 0.000741] [G loss: 0.016547]\n",
            "[Epoch 190/200] [Batch 152/200] [D loss: 0.000542] [G loss: 0.016140]\n",
            "[Epoch 190/200] [Batch 153/200] [D loss: 0.000203] [G loss: 0.015391]\n",
            "[Epoch 190/200] [Batch 154/200] [D loss: 0.000172] [G loss: 0.018805]\n",
            "[Epoch 190/200] [Batch 155/200] [D loss: 0.000233] [G loss: 0.018519]\n",
            "[Epoch 190/200] [Batch 156/200] [D loss: 0.000141] [G loss: 0.017682]\n",
            "[Epoch 190/200] [Batch 157/200] [D loss: 0.000111] [G loss: 0.014691]\n",
            "[Epoch 190/200] [Batch 158/200] [D loss: 0.000172] [G loss: 0.016978]\n",
            "[Epoch 190/200] [Batch 159/200] [D loss: 0.000099] [G loss: 0.015914]\n",
            "[Epoch 190/200] [Batch 160/200] [D loss: 0.000108] [G loss: 0.018746]\n",
            "[Epoch 190/200] [Batch 161/200] [D loss: 0.000121] [G loss: 0.017740]\n",
            "[Epoch 190/200] [Batch 162/200] [D loss: 0.000147] [G loss: 0.017587]\n",
            "[Epoch 190/200] [Batch 163/200] [D loss: 0.000076] [G loss: 0.017325]\n",
            "[Epoch 190/200] [Batch 164/200] [D loss: 0.000120] [G loss: 0.018195]\n",
            "[Epoch 190/200] [Batch 165/200] [D loss: 0.000089] [G loss: 0.018411]\n",
            "[Epoch 190/200] [Batch 166/200] [D loss: 0.000102] [G loss: 0.019307]\n",
            "[Epoch 190/200] [Batch 167/200] [D loss: 0.000282] [G loss: 0.017078]\n",
            "[Epoch 190/200] [Batch 168/200] [D loss: 0.000200] [G loss: 0.017123]\n",
            "[Epoch 190/200] [Batch 169/200] [D loss: 0.000098] [G loss: 0.014494]\n",
            "[Epoch 190/200] [Batch 170/200] [D loss: 0.000081] [G loss: 0.017776]\n",
            "[Epoch 190/200] [Batch 171/200] [D loss: 0.000045] [G loss: 0.018442]\n",
            "[Epoch 190/200] [Batch 172/200] [D loss: 0.000116] [G loss: 0.018229]\n",
            "[Epoch 190/200] [Batch 173/200] [D loss: 0.000182] [G loss: 0.016786]\n",
            "[Epoch 190/200] [Batch 174/200] [D loss: 0.000205] [G loss: 0.018562]\n",
            "[Epoch 190/200] [Batch 175/200] [D loss: 0.000094] [G loss: 0.017286]\n",
            "[Epoch 190/200] [Batch 176/200] [D loss: 0.000167] [G loss: 0.023599]\n",
            "[Epoch 190/200] [Batch 177/200] [D loss: 0.000140] [G loss: 0.015638]\n",
            "[Epoch 190/200] [Batch 178/200] [D loss: 0.000111] [G loss: 0.019973]\n",
            "[Epoch 190/200] [Batch 179/200] [D loss: 0.000081] [G loss: 0.015829]\n",
            "[Epoch 190/200] [Batch 180/200] [D loss: 0.000195] [G loss: 0.019865]\n",
            "[Epoch 190/200] [Batch 181/200] [D loss: 0.000288] [G loss: 0.016412]\n",
            "[Epoch 190/200] [Batch 182/200] [D loss: 0.000138] [G loss: 0.018262]\n",
            "[Epoch 190/200] [Batch 183/200] [D loss: 0.000078] [G loss: 0.016046]\n",
            "[Epoch 190/200] [Batch 184/200] [D loss: 0.000084] [G loss: 0.018727]\n",
            "[Epoch 190/200] [Batch 185/200] [D loss: 0.000041] [G loss: 0.013854]\n",
            "[Epoch 190/200] [Batch 186/200] [D loss: 0.000128] [G loss: 0.023508]\n",
            "[Epoch 190/200] [Batch 187/200] [D loss: 0.000078] [G loss: 0.014420]\n",
            "[Epoch 190/200] [Batch 188/200] [D loss: 0.000167] [G loss: 0.017011]\n",
            "[Epoch 190/200] [Batch 189/200] [D loss: 0.000154] [G loss: 0.021615]\n",
            "[Epoch 190/200] [Batch 190/200] [D loss: 0.000102] [G loss: 0.017642]\n",
            "[Epoch 190/200] [Batch 191/200] [D loss: 0.000160] [G loss: 0.020075]\n",
            "[Epoch 190/200] [Batch 192/200] [D loss: 0.000127] [G loss: 0.015745]\n",
            "[Epoch 190/200] [Batch 193/200] [D loss: 0.000087] [G loss: 0.017252]\n",
            "[Epoch 190/200] [Batch 194/200] [D loss: 0.000107] [G loss: 0.020693]\n",
            "[Epoch 190/200] [Batch 195/200] [D loss: 0.000076] [G loss: 0.019877]\n",
            "[Epoch 190/200] [Batch 196/200] [D loss: 0.000060] [G loss: 0.018546]\n",
            "[Epoch 190/200] [Batch 197/200] [D loss: 0.000042] [G loss: 0.016633]\n",
            "[Epoch 190/200] [Batch 198/200] [D loss: 0.000155] [G loss: 0.021912]\n",
            "[Epoch 190/200] [Batch 199/200] [D loss: 0.000307] [G loss: 0.018289]\n",
            "[Epoch 191/200] [Batch 0/200] [D loss: 0.000100] [G loss: 0.015892]\n",
            "[Epoch 191/200] [Batch 1/200] [D loss: 0.000148] [G loss: 0.016609]\n",
            "[Epoch 191/200] [Batch 2/200] [D loss: 0.000107] [G loss: 0.016317]\n",
            "[Epoch 191/200] [Batch 3/200] [D loss: 0.000114] [G loss: 0.018019]\n",
            "[Epoch 191/200] [Batch 4/200] [D loss: 0.000295] [G loss: 0.020021]\n",
            "[Epoch 191/200] [Batch 5/200] [D loss: 0.000272] [G loss: 0.017242]\n",
            "[Epoch 191/200] [Batch 6/200] [D loss: 0.000127] [G loss: 0.017516]\n",
            "[Epoch 191/200] [Batch 7/200] [D loss: 0.000091] [G loss: 0.013233]\n",
            "[Epoch 191/200] [Batch 8/200] [D loss: 0.000203] [G loss: 0.017927]\n",
            "[Epoch 191/200] [Batch 9/200] [D loss: 0.000069] [G loss: 0.017290]\n",
            "[Epoch 191/200] [Batch 10/200] [D loss: 0.000191] [G loss: 0.017327]\n",
            "[Epoch 191/200] [Batch 11/200] [D loss: 0.000237] [G loss: 0.017610]\n",
            "[Epoch 191/200] [Batch 12/200] [D loss: 0.000140] [G loss: 0.016580]\n",
            "[Epoch 191/200] [Batch 13/200] [D loss: 0.000192] [G loss: 0.016871]\n",
            "[Epoch 191/200] [Batch 14/200] [D loss: 0.000436] [G loss: 0.015192]\n",
            "[Epoch 191/200] [Batch 15/200] [D loss: 0.000496] [G loss: 0.018140]\n",
            "[Epoch 191/200] [Batch 16/200] [D loss: 0.000710] [G loss: 0.020537]\n",
            "[Epoch 191/200] [Batch 17/200] [D loss: 0.002110] [G loss: 0.015545]\n",
            "[Epoch 191/200] [Batch 18/200] [D loss: 0.001740] [G loss: 0.015183]\n",
            "[Epoch 191/200] [Batch 19/200] [D loss: 0.002692] [G loss: 0.020043]\n",
            "[Epoch 191/200] [Batch 20/200] [D loss: 0.003242] [G loss: 0.015500]\n",
            "[Epoch 191/200] [Batch 21/200] [D loss: 0.001270] [G loss: 0.017139]\n",
            "[Epoch 191/200] [Batch 22/200] [D loss: 0.000962] [G loss: 0.018945]\n",
            "[Epoch 191/200] [Batch 23/200] [D loss: 0.001712] [G loss: 0.017758]\n",
            "[Epoch 191/200] [Batch 24/200] [D loss: 0.001628] [G loss: 0.018647]\n",
            "[Epoch 191/200] [Batch 25/200] [D loss: 0.000845] [G loss: 0.019248]\n",
            "[Epoch 191/200] [Batch 26/200] [D loss: 0.000886] [G loss: 0.015351]\n",
            "[Epoch 191/200] [Batch 27/200] [D loss: 0.000921] [G loss: 0.017699]\n",
            "[Epoch 191/200] [Batch 28/200] [D loss: 0.000364] [G loss: 0.014829]\n",
            "[Epoch 191/200] [Batch 29/200] [D loss: 0.001159] [G loss: 0.021741]\n",
            "[Epoch 191/200] [Batch 30/200] [D loss: 0.001670] [G loss: 0.019438]\n",
            "[Epoch 191/200] [Batch 31/200] [D loss: 0.000295] [G loss: 0.018938]\n",
            "[Epoch 191/200] [Batch 32/200] [D loss: 0.000541] [G loss: 0.019399]\n",
            "[Epoch 191/200] [Batch 33/200] [D loss: 0.000485] [G loss: 0.019486]\n",
            "[Epoch 191/200] [Batch 34/200] [D loss: 0.001239] [G loss: 0.019167]\n",
            "[Epoch 191/200] [Batch 35/200] [D loss: 0.000994] [G loss: 0.016368]\n",
            "[Epoch 191/200] [Batch 36/200] [D loss: 0.000833] [G loss: 0.014142]\n",
            "[Epoch 191/200] [Batch 37/200] [D loss: 0.000501] [G loss: 0.018773]\n",
            "[Epoch 191/200] [Batch 38/200] [D loss: 0.000510] [G loss: 0.022874]\n",
            "[Epoch 191/200] [Batch 39/200] [D loss: 0.000198] [G loss: 0.017429]\n",
            "[Epoch 191/200] [Batch 40/200] [D loss: 0.000386] [G loss: 0.017353]\n",
            "[Epoch 191/200] [Batch 41/200] [D loss: 0.000205] [G loss: 0.014689]\n",
            "[Epoch 191/200] [Batch 42/200] [D loss: 0.000338] [G loss: 0.020343]\n",
            "[Epoch 191/200] [Batch 43/200] [D loss: 0.000296] [G loss: 0.020560]\n",
            "[Epoch 191/200] [Batch 44/200] [D loss: 0.000174] [G loss: 0.014870]\n",
            "[Epoch 191/200] [Batch 45/200] [D loss: 0.000222] [G loss: 0.017792]\n",
            "[Epoch 191/200] [Batch 46/200] [D loss: 0.000242] [G loss: 0.017474]\n",
            "[Epoch 191/200] [Batch 47/200] [D loss: 0.000184] [G loss: 0.016277]\n",
            "[Epoch 191/200] [Batch 48/200] [D loss: 0.000112] [G loss: 0.016569]\n",
            "[Epoch 191/200] [Batch 49/200] [D loss: 0.000149] [G loss: 0.018870]\n",
            "[Epoch 191/200] [Batch 50/200] [D loss: 0.000146] [G loss: 0.022467]\n",
            "[Epoch 191/200] [Batch 51/200] [D loss: 0.000160] [G loss: 0.016639]\n",
            "[Epoch 191/200] [Batch 52/200] [D loss: 0.000144] [G loss: 0.016092]\n",
            "[Epoch 191/200] [Batch 53/200] [D loss: 0.000165] [G loss: 0.020757]\n",
            "[Epoch 191/200] [Batch 54/200] [D loss: 0.000181] [G loss: 0.012768]\n",
            "[Epoch 191/200] [Batch 55/200] [D loss: 0.000180] [G loss: 0.022397]\n",
            "[Epoch 191/200] [Batch 56/200] [D loss: 0.000122] [G loss: 0.016524]\n",
            "[Epoch 191/200] [Batch 57/200] [D loss: 0.000164] [G loss: 0.015779]\n",
            "[Epoch 191/200] [Batch 58/200] [D loss: 0.000147] [G loss: 0.020283]\n",
            "[Epoch 191/200] [Batch 59/200] [D loss: 0.000155] [G loss: 0.018380]\n",
            "[Epoch 191/200] [Batch 60/200] [D loss: 0.000124] [G loss: 0.014320]\n",
            "[Epoch 191/200] [Batch 61/200] [D loss: 0.000053] [G loss: 0.016899]\n",
            "[Epoch 191/200] [Batch 62/200] [D loss: 0.000112] [G loss: 0.016448]\n",
            "[Epoch 191/200] [Batch 63/200] [D loss: 0.000190] [G loss: 0.020069]\n",
            "[Epoch 191/200] [Batch 64/200] [D loss: 0.000128] [G loss: 0.018916]\n",
            "[Epoch 191/200] [Batch 65/200] [D loss: 0.000068] [G loss: 0.017696]\n",
            "[Epoch 191/200] [Batch 66/200] [D loss: 0.000111] [G loss: 0.018434]\n",
            "[Epoch 191/200] [Batch 67/200] [D loss: 0.000109] [G loss: 0.015827]\n",
            "[Epoch 191/200] [Batch 68/200] [D loss: 0.000193] [G loss: 0.018450]\n",
            "[Epoch 191/200] [Batch 69/200] [D loss: 0.000211] [G loss: 0.015919]\n",
            "[Epoch 191/200] [Batch 70/200] [D loss: 0.000247] [G loss: 0.016194]\n",
            "[Epoch 191/200] [Batch 71/200] [D loss: 0.000204] [G loss: 0.018188]\n",
            "[Epoch 191/200] [Batch 72/200] [D loss: 0.000208] [G loss: 0.020811]\n",
            "[Epoch 191/200] [Batch 73/200] [D loss: 0.000215] [G loss: 0.023447]\n",
            "[Epoch 191/200] [Batch 74/200] [D loss: 0.000124] [G loss: 0.017438]\n",
            "[Epoch 191/200] [Batch 75/200] [D loss: 0.000245] [G loss: 0.016475]\n",
            "[Epoch 191/200] [Batch 76/200] [D loss: 0.000478] [G loss: 0.016494]\n",
            "[Epoch 191/200] [Batch 77/200] [D loss: 0.000410] [G loss: 0.014916]\n",
            "[Epoch 191/200] [Batch 78/200] [D loss: 0.000690] [G loss: 0.017972]\n",
            "[Epoch 191/200] [Batch 79/200] [D loss: 0.000309] [G loss: 0.017552]\n",
            "[Epoch 191/200] [Batch 80/200] [D loss: 0.000324] [G loss: 0.019296]\n",
            "[Epoch 191/200] [Batch 81/200] [D loss: 0.000180] [G loss: 0.018251]\n",
            "[Epoch 191/200] [Batch 82/200] [D loss: 0.000416] [G loss: 0.018022]\n",
            "[Epoch 191/200] [Batch 83/200] [D loss: 0.000676] [G loss: 0.018510]\n",
            "[Epoch 191/200] [Batch 84/200] [D loss: 0.000346] [G loss: 0.018807]\n",
            "[Epoch 191/200] [Batch 85/200] [D loss: 0.000215] [G loss: 0.022187]\n",
            "[Epoch 191/200] [Batch 86/200] [D loss: 0.000191] [G loss: 0.017946]\n",
            "[Epoch 191/200] [Batch 87/200] [D loss: 0.000539] [G loss: 0.018148]\n",
            "[Epoch 191/200] [Batch 88/200] [D loss: 0.000496] [G loss: 0.014121]\n",
            "[Epoch 191/200] [Batch 89/200] [D loss: 0.000644] [G loss: 0.019035]\n",
            "[Epoch 191/200] [Batch 90/200] [D loss: 0.000409] [G loss: 0.019990]\n",
            "[Epoch 191/200] [Batch 91/200] [D loss: 0.001054] [G loss: 0.014201]\n",
            "[Epoch 191/200] [Batch 92/200] [D loss: 0.001605] [G loss: 0.015710]\n",
            "[Epoch 191/200] [Batch 93/200] [D loss: 0.001629] [G loss: 0.018511]\n",
            "[Epoch 191/200] [Batch 94/200] [D loss: 0.000786] [G loss: 0.018197]\n",
            "[Epoch 191/200] [Batch 95/200] [D loss: 0.000881] [G loss: 0.018596]\n",
            "[Epoch 191/200] [Batch 96/200] [D loss: 0.000834] [G loss: 0.013366]\n",
            "[Epoch 191/200] [Batch 97/200] [D loss: 0.000470] [G loss: 0.018352]\n",
            "[Epoch 191/200] [Batch 98/200] [D loss: 0.000333] [G loss: 0.016961]\n",
            "[Epoch 191/200] [Batch 99/200] [D loss: 0.000287] [G loss: 0.017595]\n",
            "[Epoch 191/200] [Batch 100/200] [D loss: 0.000535] [G loss: 0.014735]\n",
            "[Epoch 191/200] [Batch 101/200] [D loss: 0.000306] [G loss: 0.018443]\n",
            "[Epoch 191/200] [Batch 102/200] [D loss: 0.000293] [G loss: 0.018520]\n",
            "[Epoch 191/200] [Batch 103/200] [D loss: 0.000300] [G loss: 0.020162]\n",
            "[Epoch 191/200] [Batch 104/200] [D loss: 0.000374] [G loss: 0.015056]\n",
            "[Epoch 191/200] [Batch 105/200] [D loss: 0.000284] [G loss: 0.015582]\n",
            "[Epoch 191/200] [Batch 106/200] [D loss: 0.000553] [G loss: 0.014208]\n",
            "[Epoch 191/200] [Batch 107/200] [D loss: 0.000491] [G loss: 0.014416]\n",
            "[Epoch 191/200] [Batch 108/200] [D loss: 0.000408] [G loss: 0.022103]\n",
            "[Epoch 191/200] [Batch 109/200] [D loss: 0.000270] [G loss: 0.017640]\n",
            "[Epoch 191/200] [Batch 110/200] [D loss: 0.000153] [G loss: 0.020813]\n",
            "[Epoch 191/200] [Batch 111/200] [D loss: 0.000157] [G loss: 0.016411]\n",
            "[Epoch 191/200] [Batch 112/200] [D loss: 0.000244] [G loss: 0.016689]\n",
            "[Epoch 191/200] [Batch 113/200] [D loss: 0.000174] [G loss: 0.015528]\n",
            "[Epoch 191/200] [Batch 114/200] [D loss: 0.000145] [G loss: 0.020375]\n",
            "[Epoch 191/200] [Batch 115/200] [D loss: 0.000255] [G loss: 0.019163]\n",
            "[Epoch 191/200] [Batch 116/200] [D loss: 0.000172] [G loss: 0.019556]\n",
            "[Epoch 191/200] [Batch 117/200] [D loss: 0.000166] [G loss: 0.012418]\n",
            "[Epoch 191/200] [Batch 118/200] [D loss: 0.000255] [G loss: 0.016761]\n",
            "[Epoch 191/200] [Batch 119/200] [D loss: 0.000255] [G loss: 0.019872]\n",
            "[Epoch 191/200] [Batch 120/200] [D loss: 0.000262] [G loss: 0.019162]\n",
            "[Epoch 191/200] [Batch 121/200] [D loss: 0.000177] [G loss: 0.017677]\n",
            "[Epoch 191/200] [Batch 122/200] [D loss: 0.000116] [G loss: 0.015521]\n",
            "[Epoch 191/200] [Batch 123/200] [D loss: 0.000239] [G loss: 0.019169]\n",
            "[Epoch 191/200] [Batch 124/200] [D loss: 0.000103] [G loss: 0.019199]\n",
            "[Epoch 191/200] [Batch 125/200] [D loss: 0.000160] [G loss: 0.018169]\n",
            "[Epoch 191/200] [Batch 126/200] [D loss: 0.000243] [G loss: 0.018646]\n",
            "[Epoch 191/200] [Batch 127/200] [D loss: 0.000165] [G loss: 0.017651]\n",
            "[Epoch 191/200] [Batch 128/200] [D loss: 0.000063] [G loss: 0.016636]\n",
            "[Epoch 191/200] [Batch 129/200] [D loss: 0.000138] [G loss: 0.021784]\n",
            "[Epoch 191/200] [Batch 130/200] [D loss: 0.000116] [G loss: 0.014578]\n",
            "[Epoch 191/200] [Batch 131/200] [D loss: 0.000121] [G loss: 0.017135]\n",
            "[Epoch 191/200] [Batch 132/200] [D loss: 0.000115] [G loss: 0.019443]\n",
            "[Epoch 191/200] [Batch 133/200] [D loss: 0.000060] [G loss: 0.014626]\n",
            "[Epoch 191/200] [Batch 134/200] [D loss: 0.000106] [G loss: 0.017572]\n",
            "[Epoch 191/200] [Batch 135/200] [D loss: 0.000111] [G loss: 0.019201]\n",
            "[Epoch 191/200] [Batch 136/200] [D loss: 0.000106] [G loss: 0.014144]\n",
            "[Epoch 191/200] [Batch 137/200] [D loss: 0.000134] [G loss: 0.018833]\n",
            "[Epoch 191/200] [Batch 138/200] [D loss: 0.000123] [G loss: 0.020928]\n",
            "[Epoch 191/200] [Batch 139/200] [D loss: 0.000076] [G loss: 0.018120]\n",
            "[Epoch 191/200] [Batch 140/200] [D loss: 0.000243] [G loss: 0.016537]\n",
            "[Epoch 191/200] [Batch 141/200] [D loss: 0.000449] [G loss: 0.017201]\n",
            "[Epoch 191/200] [Batch 142/200] [D loss: 0.000350] [G loss: 0.020484]\n",
            "[Epoch 191/200] [Batch 143/200] [D loss: 0.000347] [G loss: 0.017502]\n",
            "[Epoch 191/200] [Batch 144/200] [D loss: 0.000304] [G loss: 0.017705]\n",
            "[Epoch 191/200] [Batch 145/200] [D loss: 0.000444] [G loss: 0.016776]\n",
            "[Epoch 191/200] [Batch 146/200] [D loss: 0.000156] [G loss: 0.020490]\n",
            "[Epoch 191/200] [Batch 147/200] [D loss: 0.000310] [G loss: 0.021861]\n",
            "[Epoch 191/200] [Batch 148/200] [D loss: 0.000407] [G loss: 0.015529]\n",
            "[Epoch 191/200] [Batch 149/200] [D loss: 0.000260] [G loss: 0.018547]\n",
            "[Epoch 191/200] [Batch 150/200] [D loss: 0.000323] [G loss: 0.014027]\n",
            "[Epoch 191/200] [Batch 151/200] [D loss: 0.000332] [G loss: 0.018020]\n",
            "[Epoch 191/200] [Batch 152/200] [D loss: 0.000241] [G loss: 0.014078]\n",
            "[Epoch 191/200] [Batch 153/200] [D loss: 0.000613] [G loss: 0.019426]\n",
            "[Epoch 191/200] [Batch 154/200] [D loss: 0.000551] [G loss: 0.015441]\n",
            "[Epoch 191/200] [Batch 155/200] [D loss: 0.000367] [G loss: 0.016044]\n",
            "[Epoch 191/200] [Batch 156/200] [D loss: 0.000278] [G loss: 0.015435]\n",
            "[Epoch 191/200] [Batch 157/200] [D loss: 0.000222] [G loss: 0.017429]\n",
            "[Epoch 191/200] [Batch 158/200] [D loss: 0.000291] [G loss: 0.016149]\n",
            "[Epoch 191/200] [Batch 159/200] [D loss: 0.000138] [G loss: 0.015479]\n",
            "[Epoch 191/200] [Batch 160/200] [D loss: 0.000124] [G loss: 0.017391]\n",
            "[Epoch 191/200] [Batch 161/200] [D loss: 0.000102] [G loss: 0.018399]\n",
            "[Epoch 191/200] [Batch 162/200] [D loss: 0.000073] [G loss: 0.019859]\n",
            "[Epoch 191/200] [Batch 163/200] [D loss: 0.000062] [G loss: 0.019279]\n",
            "[Epoch 191/200] [Batch 164/200] [D loss: 0.000088] [G loss: 0.016621]\n",
            "[Epoch 191/200] [Batch 165/200] [D loss: 0.000079] [G loss: 0.015464]\n",
            "[Epoch 191/200] [Batch 166/200] [D loss: 0.000071] [G loss: 0.016217]\n",
            "[Epoch 191/200] [Batch 167/200] [D loss: 0.000171] [G loss: 0.016334]\n",
            "[Epoch 191/200] [Batch 168/200] [D loss: 0.000131] [G loss: 0.020736]\n",
            "[Epoch 191/200] [Batch 169/200] [D loss: 0.000128] [G loss: 0.019085]\n",
            "[Epoch 191/200] [Batch 170/200] [D loss: 0.000122] [G loss: 0.015820]\n",
            "[Epoch 191/200] [Batch 171/200] [D loss: 0.000222] [G loss: 0.016173]\n",
            "[Epoch 191/200] [Batch 172/200] [D loss: 0.000184] [G loss: 0.018319]\n",
            "[Epoch 191/200] [Batch 173/200] [D loss: 0.000120] [G loss: 0.015695]\n",
            "[Epoch 191/200] [Batch 174/200] [D loss: 0.000080] [G loss: 0.017338]\n",
            "[Epoch 191/200] [Batch 175/200] [D loss: 0.000102] [G loss: 0.017498]\n",
            "[Epoch 191/200] [Batch 176/200] [D loss: 0.000083] [G loss: 0.017218]\n",
            "[Epoch 191/200] [Batch 177/200] [D loss: 0.000081] [G loss: 0.019798]\n",
            "[Epoch 191/200] [Batch 178/200] [D loss: 0.000069] [G loss: 0.016903]\n",
            "[Epoch 191/200] [Batch 179/200] [D loss: 0.000101] [G loss: 0.015473]\n",
            "[Epoch 191/200] [Batch 180/200] [D loss: 0.000197] [G loss: 0.013768]\n",
            "[Epoch 191/200] [Batch 181/200] [D loss: 0.000212] [G loss: 0.019185]\n",
            "[Epoch 191/200] [Batch 182/200] [D loss: 0.000184] [G loss: 0.015494]\n",
            "[Epoch 191/200] [Batch 183/200] [D loss: 0.000180] [G loss: 0.022240]\n",
            "[Epoch 191/200] [Batch 184/200] [D loss: 0.000166] [G loss: 0.016700]\n",
            "[Epoch 191/200] [Batch 185/200] [D loss: 0.000067] [G loss: 0.019702]\n",
            "[Epoch 191/200] [Batch 186/200] [D loss: 0.000060] [G loss: 0.017185]\n",
            "[Epoch 191/200] [Batch 187/200] [D loss: 0.000098] [G loss: 0.021176]\n",
            "[Epoch 191/200] [Batch 188/200] [D loss: 0.000164] [G loss: 0.016191]\n",
            "[Epoch 191/200] [Batch 189/200] [D loss: 0.000069] [G loss: 0.015785]\n",
            "[Epoch 191/200] [Batch 190/200] [D loss: 0.000122] [G loss: 0.015966]\n",
            "[Epoch 191/200] [Batch 191/200] [D loss: 0.000107] [G loss: 0.017201]\n",
            "[Epoch 191/200] [Batch 192/200] [D loss: 0.000042] [G loss: 0.017352]\n",
            "[Epoch 191/200] [Batch 193/200] [D loss: 0.000046] [G loss: 0.013278]\n",
            "[Epoch 191/200] [Batch 194/200] [D loss: 0.000054] [G loss: 0.019781]\n",
            "[Epoch 191/200] [Batch 195/200] [D loss: 0.000060] [G loss: 0.018236]\n",
            "[Epoch 191/200] [Batch 196/200] [D loss: 0.000078] [G loss: 0.016068]\n",
            "[Epoch 191/200] [Batch 197/200] [D loss: 0.000163] [G loss: 0.015978]\n",
            "[Epoch 191/200] [Batch 198/200] [D loss: 0.000086] [G loss: 0.019418]\n",
            "[Epoch 191/200] [Batch 199/200] [D loss: 0.000065] [G loss: 0.020575]\n",
            "[Epoch 192/200] [Batch 0/200] [D loss: 0.000069] [G loss: 0.022369]\n",
            "[Epoch 192/200] [Batch 1/200] [D loss: 0.000130] [G loss: 0.016904]\n",
            "[Epoch 192/200] [Batch 2/200] [D loss: 0.000083] [G loss: 0.016187]\n",
            "[Epoch 192/200] [Batch 3/200] [D loss: 0.000048] [G loss: 0.018233]\n",
            "[Epoch 192/200] [Batch 4/200] [D loss: 0.000081] [G loss: 0.016454]\n",
            "[Epoch 192/200] [Batch 5/200] [D loss: 0.000143] [G loss: 0.018583]\n",
            "[Epoch 192/200] [Batch 6/200] [D loss: 0.000128] [G loss: 0.017650]\n",
            "[Epoch 192/200] [Batch 7/200] [D loss: 0.000282] [G loss: 0.022352]\n",
            "[Epoch 192/200] [Batch 8/200] [D loss: 0.000179] [G loss: 0.017089]\n",
            "[Epoch 192/200] [Batch 9/200] [D loss: 0.000229] [G loss: 0.018856]\n",
            "[Epoch 192/200] [Batch 10/200] [D loss: 0.000116] [G loss: 0.017001]\n",
            "[Epoch 192/200] [Batch 11/200] [D loss: 0.000105] [G loss: 0.018032]\n",
            "[Epoch 192/200] [Batch 12/200] [D loss: 0.000132] [G loss: 0.015336]\n",
            "[Epoch 192/200] [Batch 13/200] [D loss: 0.000090] [G loss: 0.015885]\n",
            "[Epoch 192/200] [Batch 14/200] [D loss: 0.000114] [G loss: 0.019388]\n",
            "[Epoch 192/200] [Batch 15/200] [D loss: 0.000153] [G loss: 0.019357]\n",
            "[Epoch 192/200] [Batch 16/200] [D loss: 0.000110] [G loss: 0.019003]\n",
            "[Epoch 192/200] [Batch 17/200] [D loss: 0.000057] [G loss: 0.016511]\n",
            "[Epoch 192/200] [Batch 18/200] [D loss: 0.000072] [G loss: 0.016516]\n",
            "[Epoch 192/200] [Batch 19/200] [D loss: 0.000056] [G loss: 0.018943]\n",
            "[Epoch 192/200] [Batch 20/200] [D loss: 0.000118] [G loss: 0.019390]\n",
            "[Epoch 192/200] [Batch 21/200] [D loss: 0.000098] [G loss: 0.015583]\n",
            "[Epoch 192/200] [Batch 22/200] [D loss: 0.000104] [G loss: 0.014771]\n",
            "[Epoch 192/200] [Batch 23/200] [D loss: 0.000172] [G loss: 0.013662]\n",
            "[Epoch 192/200] [Batch 24/200] [D loss: 0.000115] [G loss: 0.018269]\n",
            "[Epoch 192/200] [Batch 25/200] [D loss: 0.000125] [G loss: 0.017871]\n",
            "[Epoch 192/200] [Batch 26/200] [D loss: 0.000083] [G loss: 0.017302]\n",
            "[Epoch 192/200] [Batch 27/200] [D loss: 0.000070] [G loss: 0.015958]\n",
            "[Epoch 192/200] [Batch 28/200] [D loss: 0.000078] [G loss: 0.018868]\n",
            "[Epoch 192/200] [Batch 29/200] [D loss: 0.000062] [G loss: 0.018421]\n",
            "[Epoch 192/200] [Batch 30/200] [D loss: 0.000105] [G loss: 0.018606]\n",
            "[Epoch 192/200] [Batch 31/200] [D loss: 0.000072] [G loss: 0.018321]\n",
            "[Epoch 192/200] [Batch 32/200] [D loss: 0.000043] [G loss: 0.017802]\n",
            "[Epoch 192/200] [Batch 33/200] [D loss: 0.000087] [G loss: 0.016355]\n",
            "[Epoch 192/200] [Batch 34/200] [D loss: 0.000096] [G loss: 0.018336]\n",
            "[Epoch 192/200] [Batch 35/200] [D loss: 0.000097] [G loss: 0.019066]\n",
            "[Epoch 192/200] [Batch 36/200] [D loss: 0.000089] [G loss: 0.020281]\n",
            "[Epoch 192/200] [Batch 37/200] [D loss: 0.000089] [G loss: 0.020417]\n",
            "[Epoch 192/200] [Batch 38/200] [D loss: 0.000088] [G loss: 0.015922]\n",
            "[Epoch 192/200] [Batch 39/200] [D loss: 0.000074] [G loss: 0.017047]\n",
            "[Epoch 192/200] [Batch 40/200] [D loss: 0.000086] [G loss: 0.017665]\n",
            "[Epoch 192/200] [Batch 41/200] [D loss: 0.000081] [G loss: 0.019041]\n",
            "[Epoch 192/200] [Batch 42/200] [D loss: 0.000063] [G loss: 0.016536]\n",
            "[Epoch 192/200] [Batch 43/200] [D loss: 0.000066] [G loss: 0.013747]\n",
            "[Epoch 192/200] [Batch 44/200] [D loss: 0.000073] [G loss: 0.015648]\n",
            "[Epoch 192/200] [Batch 45/200] [D loss: 0.000075] [G loss: 0.018310]\n",
            "[Epoch 192/200] [Batch 46/200] [D loss: 0.000112] [G loss: 0.019008]\n",
            "[Epoch 192/200] [Batch 47/200] [D loss: 0.000089] [G loss: 0.015142]\n",
            "[Epoch 192/200] [Batch 48/200] [D loss: 0.000076] [G loss: 0.015789]\n",
            "[Epoch 192/200] [Batch 49/200] [D loss: 0.000108] [G loss: 0.016693]\n",
            "[Epoch 192/200] [Batch 50/200] [D loss: 0.000069] [G loss: 0.016017]\n",
            "[Epoch 192/200] [Batch 51/200] [D loss: 0.000101] [G loss: 0.019763]\n",
            "[Epoch 192/200] [Batch 52/200] [D loss: 0.000076] [G loss: 0.017631]\n",
            "[Epoch 192/200] [Batch 53/200] [D loss: 0.000050] [G loss: 0.018892]\n",
            "[Epoch 192/200] [Batch 54/200] [D loss: 0.000059] [G loss: 0.016035]\n",
            "[Epoch 192/200] [Batch 55/200] [D loss: 0.000036] [G loss: 0.018614]\n",
            "[Epoch 192/200] [Batch 56/200] [D loss: 0.000032] [G loss: 0.019795]\n",
            "[Epoch 192/200] [Batch 57/200] [D loss: 0.000065] [G loss: 0.023635]\n",
            "[Epoch 192/200] [Batch 58/200] [D loss: 0.000080] [G loss: 0.015593]\n",
            "[Epoch 192/200] [Batch 59/200] [D loss: 0.000088] [G loss: 0.017695]\n",
            "[Epoch 192/200] [Batch 60/200] [D loss: 0.000136] [G loss: 0.021674]\n",
            "[Epoch 192/200] [Batch 61/200] [D loss: 0.000079] [G loss: 0.018596]\n",
            "[Epoch 192/200] [Batch 62/200] [D loss: 0.000143] [G loss: 0.019363]\n",
            "[Epoch 192/200] [Batch 63/200] [D loss: 0.000215] [G loss: 0.016963]\n",
            "[Epoch 192/200] [Batch 64/200] [D loss: 0.000197] [G loss: 0.018283]\n",
            "[Epoch 192/200] [Batch 65/200] [D loss: 0.000119] [G loss: 0.018795]\n",
            "[Epoch 192/200] [Batch 66/200] [D loss: 0.000279] [G loss: 0.018046]\n",
            "[Epoch 192/200] [Batch 67/200] [D loss: 0.000382] [G loss: 0.014553]\n",
            "[Epoch 192/200] [Batch 68/200] [D loss: 0.000173] [G loss: 0.014098]\n",
            "[Epoch 192/200] [Batch 69/200] [D loss: 0.000301] [G loss: 0.018888]\n",
            "[Epoch 192/200] [Batch 70/200] [D loss: 0.000135] [G loss: 0.021946]\n",
            "[Epoch 192/200] [Batch 71/200] [D loss: 0.000080] [G loss: 0.019375]\n",
            "[Epoch 192/200] [Batch 72/200] [D loss: 0.000179] [G loss: 0.016609]\n",
            "[Epoch 192/200] [Batch 73/200] [D loss: 0.000215] [G loss: 0.015746]\n",
            "[Epoch 192/200] [Batch 74/200] [D loss: 0.000290] [G loss: 0.017853]\n",
            "[Epoch 192/200] [Batch 75/200] [D loss: 0.000304] [G loss: 0.012986]\n",
            "[Epoch 192/200] [Batch 76/200] [D loss: 0.000086] [G loss: 0.016912]\n",
            "[Epoch 192/200] [Batch 77/200] [D loss: 0.000117] [G loss: 0.024976]\n",
            "[Epoch 192/200] [Batch 78/200] [D loss: 0.000072] [G loss: 0.017412]\n",
            "[Epoch 192/200] [Batch 79/200] [D loss: 0.000092] [G loss: 0.018472]\n",
            "[Epoch 192/200] [Batch 80/200] [D loss: 0.000205] [G loss: 0.013605]\n",
            "[Epoch 192/200] [Batch 81/200] [D loss: 0.000670] [G loss: 0.019004]\n",
            "[Epoch 192/200] [Batch 82/200] [D loss: 0.000314] [G loss: 0.018848]\n",
            "[Epoch 192/200] [Batch 83/200] [D loss: 0.000131] [G loss: 0.017849]\n",
            "[Epoch 192/200] [Batch 84/200] [D loss: 0.000365] [G loss: 0.020465]\n",
            "[Epoch 192/200] [Batch 85/200] [D loss: 0.000252] [G loss: 0.018111]\n",
            "[Epoch 192/200] [Batch 86/200] [D loss: 0.000088] [G loss: 0.018723]\n",
            "[Epoch 192/200] [Batch 87/200] [D loss: 0.000070] [G loss: 0.015487]\n",
            "[Epoch 192/200] [Batch 88/200] [D loss: 0.000067] [G loss: 0.016357]\n",
            "[Epoch 192/200] [Batch 89/200] [D loss: 0.000174] [G loss: 0.016209]\n",
            "[Epoch 192/200] [Batch 90/200] [D loss: 0.000875] [G loss: 0.014754]\n",
            "[Epoch 192/200] [Batch 91/200] [D loss: 0.001441] [G loss: 0.015127]\n",
            "[Epoch 192/200] [Batch 92/200] [D loss: 0.001761] [G loss: 0.015661]\n",
            "[Epoch 192/200] [Batch 93/200] [D loss: 0.001515] [G loss: 0.013789]\n",
            "[Epoch 192/200] [Batch 94/200] [D loss: 0.001366] [G loss: 0.019789]\n",
            "[Epoch 192/200] [Batch 95/200] [D loss: 0.000874] [G loss: 0.019569]\n",
            "[Epoch 192/200] [Batch 96/200] [D loss: 0.000965] [G loss: 0.012683]\n",
            "[Epoch 192/200] [Batch 97/200] [D loss: 0.000309] [G loss: 0.017458]\n",
            "[Epoch 192/200] [Batch 98/200] [D loss: 0.000530] [G loss: 0.018246]\n",
            "[Epoch 192/200] [Batch 99/200] [D loss: 0.000751] [G loss: 0.018377]\n",
            "[Epoch 192/200] [Batch 100/200] [D loss: 0.001011] [G loss: 0.017132]\n",
            "[Epoch 192/200] [Batch 101/200] [D loss: 0.000432] [G loss: 0.013542]\n",
            "[Epoch 192/200] [Batch 102/200] [D loss: 0.000955] [G loss: 0.016626]\n",
            "[Epoch 192/200] [Batch 103/200] [D loss: 0.001295] [G loss: 0.019787]\n",
            "[Epoch 192/200] [Batch 104/200] [D loss: 0.001408] [G loss: 0.017610]\n",
            "[Epoch 192/200] [Batch 105/200] [D loss: 0.000986] [G loss: 0.016377]\n",
            "[Epoch 192/200] [Batch 106/200] [D loss: 0.000300] [G loss: 0.017699]\n",
            "[Epoch 192/200] [Batch 107/200] [D loss: 0.000587] [G loss: 0.016664]\n",
            "[Epoch 192/200] [Batch 108/200] [D loss: 0.000305] [G loss: 0.019687]\n",
            "[Epoch 192/200] [Batch 109/200] [D loss: 0.000410] [G loss: 0.017976]\n",
            "[Epoch 192/200] [Batch 110/200] [D loss: 0.001037] [G loss: 0.023246]\n",
            "[Epoch 192/200] [Batch 111/200] [D loss: 0.000247] [G loss: 0.018544]\n",
            "[Epoch 192/200] [Batch 112/200] [D loss: 0.000430] [G loss: 0.014380]\n",
            "[Epoch 192/200] [Batch 113/200] [D loss: 0.000502] [G loss: 0.014298]\n",
            "[Epoch 192/200] [Batch 114/200] [D loss: 0.000437] [G loss: 0.014292]\n",
            "[Epoch 192/200] [Batch 115/200] [D loss: 0.000607] [G loss: 0.017619]\n",
            "[Epoch 192/200] [Batch 116/200] [D loss: 0.000548] [G loss: 0.015378]\n",
            "[Epoch 192/200] [Batch 117/200] [D loss: 0.000416] [G loss: 0.016191]\n",
            "[Epoch 192/200] [Batch 118/200] [D loss: 0.000526] [G loss: 0.016915]\n",
            "[Epoch 192/200] [Batch 119/200] [D loss: 0.000684] [G loss: 0.018086]\n",
            "[Epoch 192/200] [Batch 120/200] [D loss: 0.000582] [G loss: 0.019343]\n",
            "[Epoch 192/200] [Batch 121/200] [D loss: 0.000819] [G loss: 0.015600]\n",
            "[Epoch 192/200] [Batch 122/200] [D loss: 0.000949] [G loss: 0.018157]\n",
            "[Epoch 192/200] [Batch 123/200] [D loss: 0.000306] [G loss: 0.016754]\n",
            "[Epoch 192/200] [Batch 124/200] [D loss: 0.000306] [G loss: 0.018047]\n",
            "[Epoch 192/200] [Batch 125/200] [D loss: 0.000246] [G loss: 0.015595]\n",
            "[Epoch 192/200] [Batch 126/200] [D loss: 0.000273] [G loss: 0.020862]\n",
            "[Epoch 192/200] [Batch 127/200] [D loss: 0.000122] [G loss: 0.018093]\n",
            "[Epoch 192/200] [Batch 128/200] [D loss: 0.000129] [G loss: 0.016992]\n",
            "[Epoch 192/200] [Batch 129/200] [D loss: 0.000093] [G loss: 0.016839]\n",
            "[Epoch 192/200] [Batch 130/200] [D loss: 0.000112] [G loss: 0.017717]\n",
            "[Epoch 192/200] [Batch 131/200] [D loss: 0.000211] [G loss: 0.016690]\n",
            "[Epoch 192/200] [Batch 132/200] [D loss: 0.000129] [G loss: 0.019434]\n",
            "[Epoch 192/200] [Batch 133/200] [D loss: 0.000157] [G loss: 0.018747]\n",
            "[Epoch 192/200] [Batch 134/200] [D loss: 0.000152] [G loss: 0.016141]\n",
            "[Epoch 192/200] [Batch 135/200] [D loss: 0.000259] [G loss: 0.019077]\n",
            "[Epoch 192/200] [Batch 136/200] [D loss: 0.000088] [G loss: 0.013086]\n",
            "[Epoch 192/200] [Batch 137/200] [D loss: 0.000180] [G loss: 0.018433]\n",
            "[Epoch 192/200] [Batch 138/200] [D loss: 0.000092] [G loss: 0.020025]\n",
            "[Epoch 192/200] [Batch 139/200] [D loss: 0.000084] [G loss: 0.019592]\n",
            "[Epoch 192/200] [Batch 140/200] [D loss: 0.000081] [G loss: 0.016178]\n",
            "[Epoch 192/200] [Batch 141/200] [D loss: 0.000109] [G loss: 0.018135]\n",
            "[Epoch 192/200] [Batch 142/200] [D loss: 0.000092] [G loss: 0.016039]\n",
            "[Epoch 192/200] [Batch 143/200] [D loss: 0.000126] [G loss: 0.018066]\n",
            "[Epoch 192/200] [Batch 144/200] [D loss: 0.000133] [G loss: 0.018289]\n",
            "[Epoch 192/200] [Batch 145/200] [D loss: 0.000095] [G loss: 0.021211]\n",
            "[Epoch 192/200] [Batch 146/200] [D loss: 0.000102] [G loss: 0.016075]\n",
            "[Epoch 192/200] [Batch 147/200] [D loss: 0.000131] [G loss: 0.016706]\n",
            "[Epoch 192/200] [Batch 148/200] [D loss: 0.000156] [G loss: 0.020030]\n",
            "[Epoch 192/200] [Batch 149/200] [D loss: 0.000206] [G loss: 0.015526]\n",
            "[Epoch 192/200] [Batch 150/200] [D loss: 0.000183] [G loss: 0.017171]\n",
            "[Epoch 192/200] [Batch 151/200] [D loss: 0.000772] [G loss: 0.016239]\n",
            "[Epoch 192/200] [Batch 152/200] [D loss: 0.000710] [G loss: 0.016916]\n",
            "[Epoch 192/200] [Batch 153/200] [D loss: 0.000398] [G loss: 0.016462]\n",
            "[Epoch 192/200] [Batch 154/200] [D loss: 0.002305] [G loss: 0.018472]\n",
            "[Epoch 192/200] [Batch 155/200] [D loss: 0.003799] [G loss: 0.020463]\n",
            "[Epoch 192/200] [Batch 156/200] [D loss: 0.002108] [G loss: 0.021108]\n",
            "[Epoch 192/200] [Batch 157/200] [D loss: 0.000786] [G loss: 0.015810]\n",
            "[Epoch 192/200] [Batch 158/200] [D loss: 0.000437] [G loss: 0.017288]\n",
            "[Epoch 192/200] [Batch 159/200] [D loss: 0.000473] [G loss: 0.018322]\n",
            "[Epoch 192/200] [Batch 160/200] [D loss: 0.000540] [G loss: 0.016277]\n",
            "[Epoch 192/200] [Batch 161/200] [D loss: 0.000401] [G loss: 0.017731]\n",
            "[Epoch 192/200] [Batch 162/200] [D loss: 0.000255] [G loss: 0.018515]\n",
            "[Epoch 192/200] [Batch 163/200] [D loss: 0.000435] [G loss: 0.017636]\n",
            "[Epoch 192/200] [Batch 164/200] [D loss: 0.000565] [G loss: 0.017701]\n",
            "[Epoch 192/200] [Batch 165/200] [D loss: 0.000360] [G loss: 0.017279]\n",
            "[Epoch 192/200] [Batch 166/200] [D loss: 0.000190] [G loss: 0.016504]\n",
            "[Epoch 192/200] [Batch 167/200] [D loss: 0.000251] [G loss: 0.015929]\n",
            "[Epoch 192/200] [Batch 168/200] [D loss: 0.000686] [G loss: 0.021772]\n",
            "[Epoch 192/200] [Batch 169/200] [D loss: 0.001167] [G loss: 0.019080]\n",
            "[Epoch 192/200] [Batch 170/200] [D loss: 0.000862] [G loss: 0.017631]\n",
            "[Epoch 192/200] [Batch 171/200] [D loss: 0.000435] [G loss: 0.019131]\n",
            "[Epoch 192/200] [Batch 172/200] [D loss: 0.000366] [G loss: 0.015707]\n",
            "[Epoch 192/200] [Batch 173/200] [D loss: 0.000504] [G loss: 0.016524]\n",
            "[Epoch 192/200] [Batch 174/200] [D loss: 0.000684] [G loss: 0.016829]\n",
            "[Epoch 192/200] [Batch 175/200] [D loss: 0.000258] [G loss: 0.018303]\n",
            "[Epoch 192/200] [Batch 176/200] [D loss: 0.000187] [G loss: 0.019579]\n",
            "[Epoch 192/200] [Batch 177/200] [D loss: 0.000130] [G loss: 0.016755]\n",
            "[Epoch 192/200] [Batch 178/200] [D loss: 0.000180] [G loss: 0.017172]\n",
            "[Epoch 192/200] [Batch 179/200] [D loss: 0.000467] [G loss: 0.018436]\n",
            "[Epoch 192/200] [Batch 180/200] [D loss: 0.000438] [G loss: 0.017750]\n",
            "[Epoch 192/200] [Batch 181/200] [D loss: 0.000197] [G loss: 0.018785]\n",
            "[Epoch 192/200] [Batch 182/200] [D loss: 0.000342] [G loss: 0.017464]\n",
            "[Epoch 192/200] [Batch 183/200] [D loss: 0.000274] [G loss: 0.016532]\n",
            "[Epoch 192/200] [Batch 184/200] [D loss: 0.000478] [G loss: 0.017180]\n",
            "[Epoch 192/200] [Batch 185/200] [D loss: 0.000300] [G loss: 0.014024]\n",
            "[Epoch 192/200] [Batch 186/200] [D loss: 0.000305] [G loss: 0.020531]\n",
            "[Epoch 192/200] [Batch 187/200] [D loss: 0.000428] [G loss: 0.014502]\n",
            "[Epoch 192/200] [Batch 188/200] [D loss: 0.000473] [G loss: 0.016166]\n",
            "[Epoch 192/200] [Batch 189/200] [D loss: 0.000494] [G loss: 0.016980]\n",
            "[Epoch 192/200] [Batch 190/200] [D loss: 0.000212] [G loss: 0.019867]\n",
            "[Epoch 192/200] [Batch 191/200] [D loss: 0.000434] [G loss: 0.016131]\n",
            "[Epoch 192/200] [Batch 192/200] [D loss: 0.000349] [G loss: 0.019362]\n",
            "[Epoch 192/200] [Batch 193/200] [D loss: 0.000097] [G loss: 0.021109]\n",
            "[Epoch 192/200] [Batch 194/200] [D loss: 0.000121] [G loss: 0.017119]\n",
            "[Epoch 192/200] [Batch 195/200] [D loss: 0.000571] [G loss: 0.017697]\n",
            "[Epoch 192/200] [Batch 196/200] [D loss: 0.001843] [G loss: 0.015599]\n",
            "[Epoch 192/200] [Batch 197/200] [D loss: 0.000464] [G loss: 0.015429]\n",
            "[Epoch 192/200] [Batch 198/200] [D loss: 0.000589] [G loss: 0.018216]\n",
            "[Epoch 192/200] [Batch 199/200] [D loss: 0.000805] [G loss: 0.015495]\n",
            "[Epoch 193/200] [Batch 0/200] [D loss: 0.000331] [G loss: 0.022516]\n",
            "[Epoch 193/200] [Batch 1/200] [D loss: 0.000223] [G loss: 0.018958]\n",
            "[Epoch 193/200] [Batch 2/200] [D loss: 0.000198] [G loss: 0.016268]\n",
            "[Epoch 193/200] [Batch 3/200] [D loss: 0.000128] [G loss: 0.016319]\n",
            "[Epoch 193/200] [Batch 4/200] [D loss: 0.000117] [G loss: 0.015912]\n",
            "[Epoch 193/200] [Batch 5/200] [D loss: 0.000125] [G loss: 0.016820]\n",
            "[Epoch 193/200] [Batch 6/200] [D loss: 0.000136] [G loss: 0.019401]\n",
            "[Epoch 193/200] [Batch 7/200] [D loss: 0.000075] [G loss: 0.018874]\n",
            "[Epoch 193/200] [Batch 8/200] [D loss: 0.000135] [G loss: 0.020231]\n",
            "[Epoch 193/200] [Batch 9/200] [D loss: 0.000114] [G loss: 0.017800]\n",
            "[Epoch 193/200] [Batch 10/200] [D loss: 0.000235] [G loss: 0.021650]\n",
            "[Epoch 193/200] [Batch 11/200] [D loss: 0.000150] [G loss: 0.015131]\n",
            "[Epoch 193/200] [Batch 12/200] [D loss: 0.000250] [G loss: 0.017447]\n",
            "[Epoch 193/200] [Batch 13/200] [D loss: 0.000352] [G loss: 0.017494]\n",
            "[Epoch 193/200] [Batch 14/200] [D loss: 0.000219] [G loss: 0.021128]\n",
            "[Epoch 193/200] [Batch 15/200] [D loss: 0.000241] [G loss: 0.016916]\n",
            "[Epoch 193/200] [Batch 16/200] [D loss: 0.000281] [G loss: 0.017528]\n",
            "[Epoch 193/200] [Batch 17/200] [D loss: 0.000096] [G loss: 0.016900]\n",
            "[Epoch 193/200] [Batch 18/200] [D loss: 0.000151] [G loss: 0.013988]\n",
            "[Epoch 193/200] [Batch 19/200] [D loss: 0.000189] [G loss: 0.016524]\n",
            "[Epoch 193/200] [Batch 20/200] [D loss: 0.000529] [G loss: 0.018828]\n",
            "[Epoch 193/200] [Batch 21/200] [D loss: 0.000987] [G loss: 0.016611]\n",
            "[Epoch 193/200] [Batch 22/200] [D loss: 0.000409] [G loss: 0.018131]\n",
            "[Epoch 193/200] [Batch 23/200] [D loss: 0.000403] [G loss: 0.018641]\n",
            "[Epoch 193/200] [Batch 24/200] [D loss: 0.000595] [G loss: 0.016659]\n",
            "[Epoch 193/200] [Batch 25/200] [D loss: 0.000376] [G loss: 0.020104]\n",
            "[Epoch 193/200] [Batch 26/200] [D loss: 0.000464] [G loss: 0.020895]\n",
            "[Epoch 193/200] [Batch 27/200] [D loss: 0.000182] [G loss: 0.017031]\n",
            "[Epoch 193/200] [Batch 28/200] [D loss: 0.000118] [G loss: 0.019775]\n",
            "[Epoch 193/200] [Batch 29/200] [D loss: 0.000091] [G loss: 0.019762]\n",
            "[Epoch 193/200] [Batch 30/200] [D loss: 0.000183] [G loss: 0.017266]\n",
            "[Epoch 193/200] [Batch 31/200] [D loss: 0.000311] [G loss: 0.017088]\n",
            "[Epoch 193/200] [Batch 32/200] [D loss: 0.000117] [G loss: 0.014019]\n",
            "[Epoch 193/200] [Batch 33/200] [D loss: 0.000135] [G loss: 0.018581]\n",
            "[Epoch 193/200] [Batch 34/200] [D loss: 0.000100] [G loss: 0.015408]\n",
            "[Epoch 193/200] [Batch 35/200] [D loss: 0.000091] [G loss: 0.017076]\n",
            "[Epoch 193/200] [Batch 36/200] [D loss: 0.000101] [G loss: 0.016234]\n",
            "[Epoch 193/200] [Batch 37/200] [D loss: 0.000075] [G loss: 0.015496]\n",
            "[Epoch 193/200] [Batch 38/200] [D loss: 0.000152] [G loss: 0.016306]\n",
            "[Epoch 193/200] [Batch 39/200] [D loss: 0.000476] [G loss: 0.019100]\n",
            "[Epoch 193/200] [Batch 40/200] [D loss: 0.000125] [G loss: 0.016139]\n",
            "[Epoch 193/200] [Batch 41/200] [D loss: 0.000198] [G loss: 0.014168]\n",
            "[Epoch 193/200] [Batch 42/200] [D loss: 0.000273] [G loss: 0.020940]\n",
            "[Epoch 193/200] [Batch 43/200] [D loss: 0.000122] [G loss: 0.017397]\n",
            "[Epoch 193/200] [Batch 44/200] [D loss: 0.000076] [G loss: 0.017689]\n",
            "[Epoch 193/200] [Batch 45/200] [D loss: 0.000058] [G loss: 0.016580]\n",
            "[Epoch 193/200] [Batch 46/200] [D loss: 0.000058] [G loss: 0.019404]\n",
            "[Epoch 193/200] [Batch 47/200] [D loss: 0.000072] [G loss: 0.022015]\n",
            "[Epoch 193/200] [Batch 48/200] [D loss: 0.000069] [G loss: 0.015981]\n",
            "[Epoch 193/200] [Batch 49/200] [D loss: 0.000085] [G loss: 0.016099]\n",
            "[Epoch 193/200] [Batch 50/200] [D loss: 0.000142] [G loss: 0.014801]\n",
            "[Epoch 193/200] [Batch 51/200] [D loss: 0.000123] [G loss: 0.020023]\n",
            "[Epoch 193/200] [Batch 52/200] [D loss: 0.000158] [G loss: 0.017265]\n",
            "[Epoch 193/200] [Batch 53/200] [D loss: 0.000163] [G loss: 0.015638]\n",
            "[Epoch 193/200] [Batch 54/200] [D loss: 0.000086] [G loss: 0.015479]\n",
            "[Epoch 193/200] [Batch 55/200] [D loss: 0.000082] [G loss: 0.017506]\n",
            "[Epoch 193/200] [Batch 56/200] [D loss: 0.000266] [G loss: 0.018827]\n",
            "[Epoch 193/200] [Batch 57/200] [D loss: 0.000550] [G loss: 0.014869]\n",
            "[Epoch 193/200] [Batch 58/200] [D loss: 0.000254] [G loss: 0.018163]\n",
            "[Epoch 193/200] [Batch 59/200] [D loss: 0.000069] [G loss: 0.016181]\n",
            "[Epoch 193/200] [Batch 60/200] [D loss: 0.000099] [G loss: 0.022598]\n",
            "[Epoch 193/200] [Batch 61/200] [D loss: 0.000061] [G loss: 0.013563]\n",
            "[Epoch 193/200] [Batch 62/200] [D loss: 0.000074] [G loss: 0.015967]\n",
            "[Epoch 193/200] [Batch 63/200] [D loss: 0.000060] [G loss: 0.015541]\n",
            "[Epoch 193/200] [Batch 64/200] [D loss: 0.000085] [G loss: 0.019676]\n",
            "[Epoch 193/200] [Batch 65/200] [D loss: 0.000058] [G loss: 0.014720]\n",
            "[Epoch 193/200] [Batch 66/200] [D loss: 0.000079] [G loss: 0.015321]\n",
            "[Epoch 193/200] [Batch 67/200] [D loss: 0.000061] [G loss: 0.018581]\n",
            "[Epoch 193/200] [Batch 68/200] [D loss: 0.000063] [G loss: 0.019920]\n",
            "[Epoch 193/200] [Batch 69/200] [D loss: 0.000030] [G loss: 0.015303]\n",
            "[Epoch 193/200] [Batch 70/200] [D loss: 0.000039] [G loss: 0.016828]\n",
            "[Epoch 193/200] [Batch 71/200] [D loss: 0.000087] [G loss: 0.015664]\n",
            "[Epoch 193/200] [Batch 72/200] [D loss: 0.000110] [G loss: 0.015402]\n",
            "[Epoch 193/200] [Batch 73/200] [D loss: 0.000060] [G loss: 0.016751]\n",
            "[Epoch 193/200] [Batch 74/200] [D loss: 0.000041] [G loss: 0.016218]\n",
            "[Epoch 193/200] [Batch 75/200] [D loss: 0.000040] [G loss: 0.017990]\n",
            "[Epoch 193/200] [Batch 76/200] [D loss: 0.000115] [G loss: 0.019620]\n",
            "[Epoch 193/200] [Batch 77/200] [D loss: 0.000160] [G loss: 0.019123]\n",
            "[Epoch 193/200] [Batch 78/200] [D loss: 0.000073] [G loss: 0.019558]\n",
            "[Epoch 193/200] [Batch 79/200] [D loss: 0.000096] [G loss: 0.014297]\n",
            "[Epoch 193/200] [Batch 80/200] [D loss: 0.000128] [G loss: 0.017096]\n",
            "[Epoch 193/200] [Batch 81/200] [D loss: 0.000227] [G loss: 0.019799]\n",
            "[Epoch 193/200] [Batch 82/200] [D loss: 0.000231] [G loss: 0.014289]\n",
            "[Epoch 193/200] [Batch 83/200] [D loss: 0.000181] [G loss: 0.017042]\n",
            "[Epoch 193/200] [Batch 84/200] [D loss: 0.000061] [G loss: 0.017910]\n",
            "[Epoch 193/200] [Batch 85/200] [D loss: 0.000065] [G loss: 0.016292]\n",
            "[Epoch 193/200] [Batch 86/200] [D loss: 0.000049] [G loss: 0.017178]\n",
            "[Epoch 193/200] [Batch 87/200] [D loss: 0.000107] [G loss: 0.020240]\n",
            "[Epoch 193/200] [Batch 88/200] [D loss: 0.000149] [G loss: 0.016369]\n",
            "[Epoch 193/200] [Batch 89/200] [D loss: 0.000121] [G loss: 0.014749]\n",
            "[Epoch 193/200] [Batch 90/200] [D loss: 0.000075] [G loss: 0.016276]\n",
            "[Epoch 193/200] [Batch 91/200] [D loss: 0.000094] [G loss: 0.020923]\n",
            "[Epoch 193/200] [Batch 92/200] [D loss: 0.000145] [G loss: 0.016608]\n",
            "[Epoch 193/200] [Batch 93/200] [D loss: 0.000480] [G loss: 0.023077]\n",
            "[Epoch 193/200] [Batch 94/200] [D loss: 0.000468] [G loss: 0.020558]\n",
            "[Epoch 193/200] [Batch 95/200] [D loss: 0.000181] [G loss: 0.015332]\n",
            "[Epoch 193/200] [Batch 96/200] [D loss: 0.000181] [G loss: 0.020304]\n",
            "[Epoch 193/200] [Batch 97/200] [D loss: 0.000096] [G loss: 0.016448]\n",
            "[Epoch 193/200] [Batch 98/200] [D loss: 0.000259] [G loss: 0.023944]\n",
            "[Epoch 193/200] [Batch 99/200] [D loss: 0.000489] [G loss: 0.017305]\n",
            "[Epoch 193/200] [Batch 100/200] [D loss: 0.000272] [G loss: 0.020710]\n",
            "[Epoch 193/200] [Batch 101/200] [D loss: 0.000413] [G loss: 0.017765]\n",
            "[Epoch 193/200] [Batch 102/200] [D loss: 0.000427] [G loss: 0.014767]\n",
            "[Epoch 193/200] [Batch 103/200] [D loss: 0.000232] [G loss: 0.020091]\n",
            "[Epoch 193/200] [Batch 104/200] [D loss: 0.000312] [G loss: 0.015366]\n",
            "[Epoch 193/200] [Batch 105/200] [D loss: 0.000902] [G loss: 0.019018]\n",
            "[Epoch 193/200] [Batch 106/200] [D loss: 0.000428] [G loss: 0.020434]\n",
            "[Epoch 193/200] [Batch 107/200] [D loss: 0.000415] [G loss: 0.021125]\n",
            "[Epoch 193/200] [Batch 108/200] [D loss: 0.000356] [G loss: 0.017602]\n",
            "[Epoch 193/200] [Batch 109/200] [D loss: 0.000107] [G loss: 0.020659]\n",
            "[Epoch 193/200] [Batch 110/200] [D loss: 0.000333] [G loss: 0.020081]\n",
            "[Epoch 193/200] [Batch 111/200] [D loss: 0.000216] [G loss: 0.016857]\n",
            "[Epoch 193/200] [Batch 112/200] [D loss: 0.000151] [G loss: 0.019192]\n",
            "[Epoch 193/200] [Batch 113/200] [D loss: 0.000077] [G loss: 0.019243]\n",
            "[Epoch 193/200] [Batch 114/200] [D loss: 0.000059] [G loss: 0.014588]\n",
            "[Epoch 193/200] [Batch 115/200] [D loss: 0.000176] [G loss: 0.013277]\n",
            "[Epoch 193/200] [Batch 116/200] [D loss: 0.000240] [G loss: 0.018400]\n",
            "[Epoch 193/200] [Batch 117/200] [D loss: 0.000169] [G loss: 0.020494]\n",
            "[Epoch 193/200] [Batch 118/200] [D loss: 0.000061] [G loss: 0.014096]\n",
            "[Epoch 193/200] [Batch 119/200] [D loss: 0.000192] [G loss: 0.018415]\n",
            "[Epoch 193/200] [Batch 120/200] [D loss: 0.000316] [G loss: 0.022802]\n",
            "[Epoch 193/200] [Batch 121/200] [D loss: 0.000191] [G loss: 0.018967]\n",
            "[Epoch 193/200] [Batch 122/200] [D loss: 0.000124] [G loss: 0.016319]\n",
            "[Epoch 193/200] [Batch 123/200] [D loss: 0.000082] [G loss: 0.015120]\n",
            "[Epoch 193/200] [Batch 124/200] [D loss: 0.000090] [G loss: 0.014357]\n",
            "[Epoch 193/200] [Batch 125/200] [D loss: 0.000138] [G loss: 0.018165]\n",
            "[Epoch 193/200] [Batch 126/200] [D loss: 0.000249] [G loss: 0.014273]\n",
            "[Epoch 193/200] [Batch 127/200] [D loss: 0.000635] [G loss: 0.017561]\n",
            "[Epoch 193/200] [Batch 128/200] [D loss: 0.000295] [G loss: 0.015030]\n",
            "[Epoch 193/200] [Batch 129/200] [D loss: 0.000193] [G loss: 0.018244]\n",
            "[Epoch 193/200] [Batch 130/200] [D loss: 0.000119] [G loss: 0.020286]\n",
            "[Epoch 193/200] [Batch 131/200] [D loss: 0.000201] [G loss: 0.016228]\n",
            "[Epoch 193/200] [Batch 132/200] [D loss: 0.000362] [G loss: 0.016325]\n",
            "[Epoch 193/200] [Batch 133/200] [D loss: 0.000142] [G loss: 0.018827]\n",
            "[Epoch 193/200] [Batch 134/200] [D loss: 0.000183] [G loss: 0.018941]\n",
            "[Epoch 193/200] [Batch 135/200] [D loss: 0.000227] [G loss: 0.015248]\n",
            "[Epoch 193/200] [Batch 136/200] [D loss: 0.000169] [G loss: 0.016965]\n",
            "[Epoch 193/200] [Batch 137/200] [D loss: 0.000145] [G loss: 0.019131]\n",
            "[Epoch 193/200] [Batch 138/200] [D loss: 0.000199] [G loss: 0.022361]\n",
            "[Epoch 193/200] [Batch 139/200] [D loss: 0.000116] [G loss: 0.018565]\n",
            "[Epoch 193/200] [Batch 140/200] [D loss: 0.000180] [G loss: 0.018148]\n",
            "[Epoch 193/200] [Batch 141/200] [D loss: 0.000141] [G loss: 0.015912]\n",
            "[Epoch 193/200] [Batch 142/200] [D loss: 0.000140] [G loss: 0.015400]\n",
            "[Epoch 193/200] [Batch 143/200] [D loss: 0.000256] [G loss: 0.021771]\n",
            "[Epoch 193/200] [Batch 144/200] [D loss: 0.000266] [G loss: 0.018471]\n",
            "[Epoch 193/200] [Batch 145/200] [D loss: 0.000131] [G loss: 0.015676]\n",
            "[Epoch 193/200] [Batch 146/200] [D loss: 0.000263] [G loss: 0.016235]\n",
            "[Epoch 193/200] [Batch 147/200] [D loss: 0.000133] [G loss: 0.018204]\n",
            "[Epoch 193/200] [Batch 148/200] [D loss: 0.000107] [G loss: 0.019015]\n",
            "[Epoch 193/200] [Batch 149/200] [D loss: 0.000154] [G loss: 0.018484]\n",
            "[Epoch 193/200] [Batch 150/200] [D loss: 0.000195] [G loss: 0.014012]\n",
            "[Epoch 193/200] [Batch 151/200] [D loss: 0.000245] [G loss: 0.018243]\n",
            "[Epoch 193/200] [Batch 152/200] [D loss: 0.000106] [G loss: 0.018711]\n",
            "[Epoch 193/200] [Batch 153/200] [D loss: 0.000098] [G loss: 0.014451]\n",
            "[Epoch 193/200] [Batch 154/200] [D loss: 0.000143] [G loss: 0.017764]\n",
            "[Epoch 193/200] [Batch 155/200] [D loss: 0.000120] [G loss: 0.013720]\n",
            "[Epoch 193/200] [Batch 156/200] [D loss: 0.000066] [G loss: 0.017988]\n",
            "[Epoch 193/200] [Batch 157/200] [D loss: 0.000116] [G loss: 0.014582]\n",
            "[Epoch 193/200] [Batch 158/200] [D loss: 0.000120] [G loss: 0.016253]\n",
            "[Epoch 193/200] [Batch 159/200] [D loss: 0.000131] [G loss: 0.019045]\n",
            "[Epoch 193/200] [Batch 160/200] [D loss: 0.000134] [G loss: 0.017042]\n",
            "[Epoch 193/200] [Batch 161/200] [D loss: 0.000138] [G loss: 0.016471]\n",
            "[Epoch 193/200] [Batch 162/200] [D loss: 0.000183] [G loss: 0.020178]\n",
            "[Epoch 193/200] [Batch 163/200] [D loss: 0.000327] [G loss: 0.016407]\n",
            "[Epoch 193/200] [Batch 164/200] [D loss: 0.000352] [G loss: 0.019919]\n",
            "[Epoch 193/200] [Batch 165/200] [D loss: 0.000170] [G loss: 0.020584]\n",
            "[Epoch 193/200] [Batch 166/200] [D loss: 0.000254] [G loss: 0.015422]\n",
            "[Epoch 193/200] [Batch 167/200] [D loss: 0.000263] [G loss: 0.016482]\n",
            "[Epoch 193/200] [Batch 168/200] [D loss: 0.000198] [G loss: 0.016269]\n",
            "[Epoch 193/200] [Batch 169/200] [D loss: 0.000177] [G loss: 0.016521]\n",
            "[Epoch 193/200] [Batch 170/200] [D loss: 0.000078] [G loss: 0.015119]\n",
            "[Epoch 193/200] [Batch 171/200] [D loss: 0.000066] [G loss: 0.015725]\n",
            "[Epoch 193/200] [Batch 172/200] [D loss: 0.000065] [G loss: 0.021528]\n",
            "[Epoch 193/200] [Batch 173/200] [D loss: 0.000078] [G loss: 0.019052]\n",
            "[Epoch 193/200] [Batch 174/200] [D loss: 0.000210] [G loss: 0.017323]\n",
            "[Epoch 193/200] [Batch 175/200] [D loss: 0.000253] [G loss: 0.015014]\n",
            "[Epoch 193/200] [Batch 176/200] [D loss: 0.000222] [G loss: 0.016304]\n",
            "[Epoch 193/200] [Batch 177/200] [D loss: 0.000370] [G loss: 0.016582]\n",
            "[Epoch 193/200] [Batch 178/200] [D loss: 0.000213] [G loss: 0.015920]\n",
            "[Epoch 193/200] [Batch 179/200] [D loss: 0.000338] [G loss: 0.018081]\n",
            "[Epoch 193/200] [Batch 180/200] [D loss: 0.000667] [G loss: 0.013942]\n",
            "[Epoch 193/200] [Batch 181/200] [D loss: 0.000751] [G loss: 0.018542]\n",
            "[Epoch 193/200] [Batch 182/200] [D loss: 0.000286] [G loss: 0.019673]\n",
            "[Epoch 193/200] [Batch 183/200] [D loss: 0.000835] [G loss: 0.018398]\n",
            "[Epoch 193/200] [Batch 184/200] [D loss: 0.000420] [G loss: 0.016156]\n",
            "[Epoch 193/200] [Batch 185/200] [D loss: 0.000957] [G loss: 0.018866]\n",
            "[Epoch 193/200] [Batch 186/200] [D loss: 0.000791] [G loss: 0.018370]\n",
            "[Epoch 193/200] [Batch 187/200] [D loss: 0.000852] [G loss: 0.016405]\n",
            "[Epoch 193/200] [Batch 188/200] [D loss: 0.000981] [G loss: 0.017280]\n",
            "[Epoch 193/200] [Batch 189/200] [D loss: 0.001837] [G loss: 0.016420]\n",
            "[Epoch 193/200] [Batch 190/200] [D loss: 0.001808] [G loss: 0.015531]\n",
            "[Epoch 193/200] [Batch 191/200] [D loss: 0.002248] [G loss: 0.014303]\n",
            "[Epoch 193/200] [Batch 192/200] [D loss: 0.001114] [G loss: 0.015726]\n",
            "[Epoch 193/200] [Batch 193/200] [D loss: 0.001187] [G loss: 0.017632]\n",
            "[Epoch 193/200] [Batch 194/200] [D loss: 0.001887] [G loss: 0.015027]\n",
            "[Epoch 193/200] [Batch 195/200] [D loss: 0.002108] [G loss: 0.018183]\n",
            "[Epoch 193/200] [Batch 196/200] [D loss: 0.003067] [G loss: 0.020378]\n",
            "[Epoch 193/200] [Batch 197/200] [D loss: 0.000953] [G loss: 0.022773]\n",
            "[Epoch 193/200] [Batch 198/200] [D loss: 0.000603] [G loss: 0.017940]\n",
            "[Epoch 193/200] [Batch 199/200] [D loss: 0.000957] [G loss: 0.018301]\n",
            "[Epoch 194/200] [Batch 0/200] [D loss: 0.000889] [G loss: 0.015664]\n",
            "[Epoch 194/200] [Batch 1/200] [D loss: 0.000921] [G loss: 0.015429]\n",
            "[Epoch 194/200] [Batch 2/200] [D loss: 0.000592] [G loss: 0.021044]\n",
            "[Epoch 194/200] [Batch 3/200] [D loss: 0.000309] [G loss: 0.016064]\n",
            "[Epoch 194/200] [Batch 4/200] [D loss: 0.000266] [G loss: 0.014496]\n",
            "[Epoch 194/200] [Batch 5/200] [D loss: 0.000338] [G loss: 0.019056]\n",
            "[Epoch 194/200] [Batch 6/200] [D loss: 0.000191] [G loss: 0.017076]\n",
            "[Epoch 194/200] [Batch 7/200] [D loss: 0.000184] [G loss: 0.018375]\n",
            "[Epoch 194/200] [Batch 8/200] [D loss: 0.000351] [G loss: 0.019950]\n",
            "[Epoch 194/200] [Batch 9/200] [D loss: 0.000579] [G loss: 0.018574]\n",
            "[Epoch 194/200] [Batch 10/200] [D loss: 0.000593] [G loss: 0.019836]\n",
            "[Epoch 194/200] [Batch 11/200] [D loss: 0.000737] [G loss: 0.020861]\n",
            "[Epoch 194/200] [Batch 12/200] [D loss: 0.000452] [G loss: 0.020356]\n",
            "[Epoch 194/200] [Batch 13/200] [D loss: 0.000170] [G loss: 0.016000]\n",
            "[Epoch 194/200] [Batch 14/200] [D loss: 0.000114] [G loss: 0.020178]\n",
            "[Epoch 194/200] [Batch 15/200] [D loss: 0.000084] [G loss: 0.015413]\n",
            "[Epoch 194/200] [Batch 16/200] [D loss: 0.000079] [G loss: 0.018222]\n",
            "[Epoch 194/200] [Batch 17/200] [D loss: 0.000066] [G loss: 0.019784]\n",
            "[Epoch 194/200] [Batch 18/200] [D loss: 0.000063] [G loss: 0.019632]\n",
            "[Epoch 194/200] [Batch 19/200] [D loss: 0.000108] [G loss: 0.015392]\n",
            "[Epoch 194/200] [Batch 20/200] [D loss: 0.000071] [G loss: 0.015979]\n",
            "[Epoch 194/200] [Batch 21/200] [D loss: 0.000119] [G loss: 0.017080]\n",
            "[Epoch 194/200] [Batch 22/200] [D loss: 0.000139] [G loss: 0.019002]\n",
            "[Epoch 194/200] [Batch 23/200] [D loss: 0.000100] [G loss: 0.013512]\n",
            "[Epoch 194/200] [Batch 24/200] [D loss: 0.000104] [G loss: 0.018886]\n",
            "[Epoch 194/200] [Batch 25/200] [D loss: 0.000104] [G loss: 0.019199]\n",
            "[Epoch 194/200] [Batch 26/200] [D loss: 0.000238] [G loss: 0.014171]\n",
            "[Epoch 194/200] [Batch 27/200] [D loss: 0.000235] [G loss: 0.013423]\n",
            "[Epoch 194/200] [Batch 28/200] [D loss: 0.000312] [G loss: 0.016711]\n",
            "[Epoch 194/200] [Batch 29/200] [D loss: 0.000148] [G loss: 0.014785]\n",
            "[Epoch 194/200] [Batch 30/200] [D loss: 0.000053] [G loss: 0.017213]\n",
            "[Epoch 194/200] [Batch 31/200] [D loss: 0.000136] [G loss: 0.014567]\n",
            "[Epoch 194/200] [Batch 32/200] [D loss: 0.000051] [G loss: 0.015561]\n",
            "[Epoch 194/200] [Batch 33/200] [D loss: 0.000174] [G loss: 0.019686]\n",
            "[Epoch 194/200] [Batch 34/200] [D loss: 0.000120] [G loss: 0.024235]\n",
            "[Epoch 194/200] [Batch 35/200] [D loss: 0.000425] [G loss: 0.016031]\n",
            "[Epoch 194/200] [Batch 36/200] [D loss: 0.000550] [G loss: 0.016864]\n",
            "[Epoch 194/200] [Batch 37/200] [D loss: 0.000177] [G loss: 0.018030]\n",
            "[Epoch 194/200] [Batch 38/200] [D loss: 0.000081] [G loss: 0.016950]\n",
            "[Epoch 194/200] [Batch 39/200] [D loss: 0.000190] [G loss: 0.015105]\n",
            "[Epoch 194/200] [Batch 40/200] [D loss: 0.000374] [G loss: 0.016291]\n",
            "[Epoch 194/200] [Batch 41/200] [D loss: 0.000235] [G loss: 0.016846]\n",
            "[Epoch 194/200] [Batch 42/200] [D loss: 0.000144] [G loss: 0.016335]\n",
            "[Epoch 194/200] [Batch 43/200] [D loss: 0.000174] [G loss: 0.018602]\n",
            "[Epoch 194/200] [Batch 44/200] [D loss: 0.000324] [G loss: 0.018552]\n",
            "[Epoch 194/200] [Batch 45/200] [D loss: 0.000128] [G loss: 0.014352]\n",
            "[Epoch 194/200] [Batch 46/200] [D loss: 0.000181] [G loss: 0.019468]\n",
            "[Epoch 194/200] [Batch 47/200] [D loss: 0.000181] [G loss: 0.016564]\n",
            "[Epoch 194/200] [Batch 48/200] [D loss: 0.000206] [G loss: 0.018626]\n",
            "[Epoch 194/200] [Batch 49/200] [D loss: 0.000139] [G loss: 0.016843]\n",
            "[Epoch 194/200] [Batch 50/200] [D loss: 0.000143] [G loss: 0.014515]\n",
            "[Epoch 194/200] [Batch 51/200] [D loss: 0.000128] [G loss: 0.020364]\n",
            "[Epoch 194/200] [Batch 52/200] [D loss: 0.000301] [G loss: 0.016348]\n",
            "[Epoch 194/200] [Batch 53/200] [D loss: 0.000912] [G loss: 0.016827]\n",
            "[Epoch 194/200] [Batch 54/200] [D loss: 0.000903] [G loss: 0.016049]\n",
            "[Epoch 194/200] [Batch 55/200] [D loss: 0.000345] [G loss: 0.020943]\n",
            "[Epoch 194/200] [Batch 56/200] [D loss: 0.000271] [G loss: 0.015792]\n",
            "[Epoch 194/200] [Batch 57/200] [D loss: 0.000185] [G loss: 0.015977]\n",
            "[Epoch 194/200] [Batch 58/200] [D loss: 0.000304] [G loss: 0.017567]\n",
            "[Epoch 194/200] [Batch 59/200] [D loss: 0.000221] [G loss: 0.019546]\n",
            "[Epoch 194/200] [Batch 60/200] [D loss: 0.000159] [G loss: 0.014182]\n",
            "[Epoch 194/200] [Batch 61/200] [D loss: 0.000433] [G loss: 0.019551]\n",
            "[Epoch 194/200] [Batch 62/200] [D loss: 0.000650] [G loss: 0.014051]\n",
            "[Epoch 194/200] [Batch 63/200] [D loss: 0.000183] [G loss: 0.020533]\n",
            "[Epoch 194/200] [Batch 64/200] [D loss: 0.000274] [G loss: 0.016945]\n",
            "[Epoch 194/200] [Batch 65/200] [D loss: 0.000328] [G loss: 0.014800]\n",
            "[Epoch 194/200] [Batch 66/200] [D loss: 0.000586] [G loss: 0.016936]\n",
            "[Epoch 194/200] [Batch 67/200] [D loss: 0.001549] [G loss: 0.018764]\n",
            "[Epoch 194/200] [Batch 68/200] [D loss: 0.000447] [G loss: 0.020777]\n",
            "[Epoch 194/200] [Batch 69/200] [D loss: 0.000665] [G loss: 0.016091]\n",
            "[Epoch 194/200] [Batch 70/200] [D loss: 0.000508] [G loss: 0.017363]\n",
            "[Epoch 194/200] [Batch 71/200] [D loss: 0.001687] [G loss: 0.021068]\n",
            "[Epoch 194/200] [Batch 72/200] [D loss: 0.003325] [G loss: 0.020269]\n",
            "[Epoch 194/200] [Batch 73/200] [D loss: 0.001957] [G loss: 0.011973]\n",
            "[Epoch 194/200] [Batch 74/200] [D loss: 0.001071] [G loss: 0.018281]\n",
            "[Epoch 194/200] [Batch 75/200] [D loss: 0.001554] [G loss: 0.017068]\n",
            "[Epoch 194/200] [Batch 76/200] [D loss: 0.000738] [G loss: 0.022356]\n",
            "[Epoch 194/200] [Batch 77/200] [D loss: 0.000849] [G loss: 0.016266]\n",
            "[Epoch 194/200] [Batch 78/200] [D loss: 0.000846] [G loss: 0.019552]\n",
            "[Epoch 194/200] [Batch 79/200] [D loss: 0.002194] [G loss: 0.017237]\n",
            "[Epoch 194/200] [Batch 80/200] [D loss: 0.002401] [G loss: 0.012818]\n",
            "[Epoch 194/200] [Batch 81/200] [D loss: 0.009850] [G loss: 0.019991]\n",
            "[Epoch 194/200] [Batch 82/200] [D loss: 0.011520] [G loss: 0.017549]\n",
            "[Epoch 194/200] [Batch 83/200] [D loss: 0.008864] [G loss: 0.019783]\n",
            "[Epoch 194/200] [Batch 84/200] [D loss: 0.002694] [G loss: 0.018625]\n",
            "[Epoch 194/200] [Batch 85/200] [D loss: 0.001665] [G loss: 0.016174]\n",
            "[Epoch 194/200] [Batch 86/200] [D loss: 0.000750] [G loss: 0.018077]\n",
            "[Epoch 194/200] [Batch 87/200] [D loss: 0.000705] [G loss: 0.016639]\n",
            "[Epoch 194/200] [Batch 88/200] [D loss: 0.000391] [G loss: 0.017405]\n",
            "[Epoch 194/200] [Batch 89/200] [D loss: 0.000945] [G loss: 0.017150]\n",
            "[Epoch 194/200] [Batch 90/200] [D loss: 0.001748] [G loss: 0.015902]\n",
            "[Epoch 194/200] [Batch 91/200] [D loss: 0.001529] [G loss: 0.018516]\n",
            "[Epoch 194/200] [Batch 92/200] [D loss: 0.001570] [G loss: 0.019560]\n",
            "[Epoch 194/200] [Batch 93/200] [D loss: 0.003928] [G loss: 0.016309]\n",
            "[Epoch 194/200] [Batch 94/200] [D loss: 0.007231] [G loss: 0.017313]\n",
            "[Epoch 194/200] [Batch 95/200] [D loss: 0.001758] [G loss: 0.015389]\n",
            "[Epoch 194/200] [Batch 96/200] [D loss: 0.000927] [G loss: 0.019815]\n",
            "[Epoch 194/200] [Batch 97/200] [D loss: 0.000836] [G loss: 0.017914]\n",
            "[Epoch 194/200] [Batch 98/200] [D loss: 0.001538] [G loss: 0.017145]\n",
            "[Epoch 194/200] [Batch 99/200] [D loss: 0.001447] [G loss: 0.018325]\n",
            "[Epoch 194/200] [Batch 100/200] [D loss: 0.001112] [G loss: 0.017774]\n",
            "[Epoch 194/200] [Batch 101/200] [D loss: 0.004818] [G loss: 0.017164]\n",
            "[Epoch 194/200] [Batch 102/200] [D loss: 0.003202] [G loss: 0.017330]\n",
            "[Epoch 194/200] [Batch 103/200] [D loss: 0.000669] [G loss: 0.019560]\n",
            "[Epoch 194/200] [Batch 104/200] [D loss: 0.001125] [G loss: 0.018494]\n",
            "[Epoch 194/200] [Batch 105/200] [D loss: 0.000513] [G loss: 0.016144]\n",
            "[Epoch 194/200] [Batch 106/200] [D loss: 0.000705] [G loss: 0.021478]\n",
            "[Epoch 194/200] [Batch 107/200] [D loss: 0.000428] [G loss: 0.017415]\n",
            "[Epoch 194/200] [Batch 108/200] [D loss: 0.000434] [G loss: 0.016365]\n",
            "[Epoch 194/200] [Batch 109/200] [D loss: 0.000163] [G loss: 0.018950]\n",
            "[Epoch 194/200] [Batch 110/200] [D loss: 0.000161] [G loss: 0.016275]\n",
            "[Epoch 194/200] [Batch 111/200] [D loss: 0.000141] [G loss: 0.015614]\n",
            "[Epoch 194/200] [Batch 112/200] [D loss: 0.000870] [G loss: 0.018077]\n",
            "[Epoch 194/200] [Batch 113/200] [D loss: 0.000659] [G loss: 0.018411]\n",
            "[Epoch 194/200] [Batch 114/200] [D loss: 0.000319] [G loss: 0.015541]\n",
            "[Epoch 194/200] [Batch 115/200] [D loss: 0.000391] [G loss: 0.017869]\n",
            "[Epoch 194/200] [Batch 116/200] [D loss: 0.000495] [G loss: 0.019566]\n",
            "[Epoch 194/200] [Batch 117/200] [D loss: 0.000301] [G loss: 0.017746]\n",
            "[Epoch 194/200] [Batch 118/200] [D loss: 0.000230] [G loss: 0.018044]\n",
            "[Epoch 194/200] [Batch 119/200] [D loss: 0.000105] [G loss: 0.020642]\n",
            "[Epoch 194/200] [Batch 120/200] [D loss: 0.000131] [G loss: 0.018466]\n",
            "[Epoch 194/200] [Batch 121/200] [D loss: 0.000317] [G loss: 0.015971]\n",
            "[Epoch 194/200] [Batch 122/200] [D loss: 0.000222] [G loss: 0.020453]\n",
            "[Epoch 194/200] [Batch 123/200] [D loss: 0.000180] [G loss: 0.013697]\n",
            "[Epoch 194/200] [Batch 124/200] [D loss: 0.000149] [G loss: 0.020828]\n",
            "[Epoch 194/200] [Batch 125/200] [D loss: 0.000137] [G loss: 0.013872]\n",
            "[Epoch 194/200] [Batch 126/200] [D loss: 0.000136] [G loss: 0.017958]\n",
            "[Epoch 194/200] [Batch 127/200] [D loss: 0.000154] [G loss: 0.018728]\n",
            "[Epoch 194/200] [Batch 128/200] [D loss: 0.000084] [G loss: 0.018559]\n",
            "[Epoch 194/200] [Batch 129/200] [D loss: 0.000117] [G loss: 0.015942]\n",
            "[Epoch 194/200] [Batch 130/200] [D loss: 0.000104] [G loss: 0.017840]\n",
            "[Epoch 194/200] [Batch 131/200] [D loss: 0.000151] [G loss: 0.016312]\n",
            "[Epoch 194/200] [Batch 132/200] [D loss: 0.000114] [G loss: 0.016640]\n",
            "[Epoch 194/200] [Batch 133/200] [D loss: 0.000153] [G loss: 0.017940]\n",
            "[Epoch 194/200] [Batch 134/200] [D loss: 0.000274] [G loss: 0.017441]\n",
            "[Epoch 194/200] [Batch 135/200] [D loss: 0.000419] [G loss: 0.012731]\n",
            "[Epoch 194/200] [Batch 136/200] [D loss: 0.000888] [G loss: 0.019713]\n",
            "[Epoch 194/200] [Batch 137/200] [D loss: 0.001446] [G loss: 0.017066]\n",
            "[Epoch 194/200] [Batch 138/200] [D loss: 0.001101] [G loss: 0.016917]\n",
            "[Epoch 194/200] [Batch 139/200] [D loss: 0.000496] [G loss: 0.019020]\n",
            "[Epoch 194/200] [Batch 140/200] [D loss: 0.000520] [G loss: 0.013689]\n",
            "[Epoch 194/200] [Batch 141/200] [D loss: 0.000231] [G loss: 0.018165]\n",
            "[Epoch 194/200] [Batch 142/200] [D loss: 0.000228] [G loss: 0.018637]\n",
            "[Epoch 194/200] [Batch 143/200] [D loss: 0.000162] [G loss: 0.021931]\n",
            "[Epoch 194/200] [Batch 144/200] [D loss: 0.000164] [G loss: 0.020922]\n",
            "[Epoch 194/200] [Batch 145/200] [D loss: 0.000096] [G loss: 0.017804]\n",
            "[Epoch 194/200] [Batch 146/200] [D loss: 0.000099] [G loss: 0.013965]\n",
            "[Epoch 194/200] [Batch 147/200] [D loss: 0.000118] [G loss: 0.015540]\n",
            "[Epoch 194/200] [Batch 148/200] [D loss: 0.000118] [G loss: 0.019278]\n",
            "[Epoch 194/200] [Batch 149/200] [D loss: 0.000149] [G loss: 0.020599]\n",
            "[Epoch 194/200] [Batch 150/200] [D loss: 0.000158] [G loss: 0.021785]\n",
            "[Epoch 194/200] [Batch 151/200] [D loss: 0.000298] [G loss: 0.016101]\n",
            "[Epoch 194/200] [Batch 152/200] [D loss: 0.000066] [G loss: 0.015639]\n",
            "[Epoch 194/200] [Batch 153/200] [D loss: 0.000262] [G loss: 0.019514]\n",
            "[Epoch 194/200] [Batch 154/200] [D loss: 0.000282] [G loss: 0.014735]\n",
            "[Epoch 194/200] [Batch 155/200] [D loss: 0.000217] [G loss: 0.014580]\n",
            "[Epoch 194/200] [Batch 156/200] [D loss: 0.000177] [G loss: 0.018667]\n",
            "[Epoch 194/200] [Batch 157/200] [D loss: 0.000256] [G loss: 0.015617]\n",
            "[Epoch 194/200] [Batch 158/200] [D loss: 0.000498] [G loss: 0.015008]\n",
            "[Epoch 194/200] [Batch 159/200] [D loss: 0.000619] [G loss: 0.019781]\n",
            "[Epoch 194/200] [Batch 160/200] [D loss: 0.000367] [G loss: 0.018343]\n",
            "[Epoch 194/200] [Batch 161/200] [D loss: 0.000271] [G loss: 0.019456]\n",
            "[Epoch 194/200] [Batch 162/200] [D loss: 0.000291] [G loss: 0.016113]\n",
            "[Epoch 194/200] [Batch 163/200] [D loss: 0.000193] [G loss: 0.021874]\n",
            "[Epoch 194/200] [Batch 164/200] [D loss: 0.000185] [G loss: 0.018607]\n",
            "[Epoch 194/200] [Batch 165/200] [D loss: 0.000217] [G loss: 0.015408]\n",
            "[Epoch 194/200] [Batch 166/200] [D loss: 0.000284] [G loss: 0.016857]\n",
            "[Epoch 194/200] [Batch 167/200] [D loss: 0.000315] [G loss: 0.019212]\n",
            "[Epoch 194/200] [Batch 168/200] [D loss: 0.000095] [G loss: 0.017882]\n",
            "[Epoch 194/200] [Batch 169/200] [D loss: 0.000099] [G loss: 0.017371]\n",
            "[Epoch 194/200] [Batch 170/200] [D loss: 0.000661] [G loss: 0.017476]\n",
            "[Epoch 194/200] [Batch 171/200] [D loss: 0.001255] [G loss: 0.014520]\n",
            "[Epoch 194/200] [Batch 172/200] [D loss: 0.000614] [G loss: 0.018332]\n",
            "[Epoch 194/200] [Batch 173/200] [D loss: 0.000224] [G loss: 0.015516]\n",
            "[Epoch 194/200] [Batch 174/200] [D loss: 0.000344] [G loss: 0.016121]\n",
            "[Epoch 194/200] [Batch 175/200] [D loss: 0.000087] [G loss: 0.018719]\n",
            "[Epoch 194/200] [Batch 176/200] [D loss: 0.000116] [G loss: 0.017306]\n",
            "[Epoch 194/200] [Batch 177/200] [D loss: 0.000146] [G loss: 0.018502]\n",
            "[Epoch 194/200] [Batch 178/200] [D loss: 0.000079] [G loss: 0.018260]\n",
            "[Epoch 194/200] [Batch 179/200] [D loss: 0.000153] [G loss: 0.021623]\n",
            "[Epoch 194/200] [Batch 180/200] [D loss: 0.000181] [G loss: 0.017454]\n",
            "[Epoch 194/200] [Batch 181/200] [D loss: 0.000377] [G loss: 0.016286]\n",
            "[Epoch 194/200] [Batch 182/200] [D loss: 0.000176] [G loss: 0.019991]\n",
            "[Epoch 194/200] [Batch 183/200] [D loss: 0.000087] [G loss: 0.011351]\n",
            "[Epoch 194/200] [Batch 184/200] [D loss: 0.000121] [G loss: 0.019006]\n",
            "[Epoch 194/200] [Batch 185/200] [D loss: 0.000123] [G loss: 0.018224]\n",
            "[Epoch 194/200] [Batch 186/200] [D loss: 0.000054] [G loss: 0.019056]\n",
            "[Epoch 194/200] [Batch 187/200] [D loss: 0.000117] [G loss: 0.021560]\n",
            "[Epoch 194/200] [Batch 188/200] [D loss: 0.000116] [G loss: 0.020504]\n",
            "[Epoch 194/200] [Batch 189/200] [D loss: 0.000198] [G loss: 0.016333]\n",
            "[Epoch 194/200] [Batch 190/200] [D loss: 0.000280] [G loss: 0.018545]\n",
            "[Epoch 194/200] [Batch 191/200] [D loss: 0.000151] [G loss: 0.021355]\n",
            "[Epoch 194/200] [Batch 192/200] [D loss: 0.000319] [G loss: 0.019755]\n",
            "[Epoch 194/200] [Batch 193/200] [D loss: 0.000152] [G loss: 0.015207]\n",
            "[Epoch 194/200] [Batch 194/200] [D loss: 0.000191] [G loss: 0.018803]\n",
            "[Epoch 194/200] [Batch 195/200] [D loss: 0.000233] [G loss: 0.013836]\n",
            "[Epoch 194/200] [Batch 196/200] [D loss: 0.000093] [G loss: 0.017024]\n",
            "[Epoch 194/200] [Batch 197/200] [D loss: 0.000104] [G loss: 0.016644]\n",
            "[Epoch 194/200] [Batch 198/200] [D loss: 0.000085] [G loss: 0.017398]\n",
            "[Epoch 194/200] [Batch 199/200] [D loss: 0.000280] [G loss: 0.017596]\n",
            "[Epoch 195/200] [Batch 0/200] [D loss: 0.000275] [G loss: 0.018008]\n",
            "[Epoch 195/200] [Batch 1/200] [D loss: 0.000113] [G loss: 0.017063]\n",
            "[Epoch 195/200] [Batch 2/200] [D loss: 0.000163] [G loss: 0.017994]\n",
            "[Epoch 195/200] [Batch 3/200] [D loss: 0.000318] [G loss: 0.015797]\n",
            "[Epoch 195/200] [Batch 4/200] [D loss: 0.000099] [G loss: 0.021361]\n",
            "[Epoch 195/200] [Batch 5/200] [D loss: 0.000186] [G loss: 0.018933]\n",
            "[Epoch 195/200] [Batch 6/200] [D loss: 0.000198] [G loss: 0.020773]\n",
            "[Epoch 195/200] [Batch 7/200] [D loss: 0.000135] [G loss: 0.014219]\n",
            "[Epoch 195/200] [Batch 8/200] [D loss: 0.000227] [G loss: 0.019814]\n",
            "[Epoch 195/200] [Batch 9/200] [D loss: 0.000233] [G loss: 0.019199]\n",
            "[Epoch 195/200] [Batch 10/200] [D loss: 0.000096] [G loss: 0.016482]\n",
            "[Epoch 195/200] [Batch 11/200] [D loss: 0.000108] [G loss: 0.018382]\n",
            "[Epoch 195/200] [Batch 12/200] [D loss: 0.000129] [G loss: 0.015575]\n",
            "[Epoch 195/200] [Batch 13/200] [D loss: 0.000101] [G loss: 0.016388]\n",
            "[Epoch 195/200] [Batch 14/200] [D loss: 0.000131] [G loss: 0.021287]\n",
            "[Epoch 195/200] [Batch 15/200] [D loss: 0.000096] [G loss: 0.019098]\n",
            "[Epoch 195/200] [Batch 16/200] [D loss: 0.000113] [G loss: 0.016582]\n",
            "[Epoch 195/200] [Batch 17/200] [D loss: 0.000110] [G loss: 0.018898]\n",
            "[Epoch 195/200] [Batch 18/200] [D loss: 0.000082] [G loss: 0.021172]\n",
            "[Epoch 195/200] [Batch 19/200] [D loss: 0.000149] [G loss: 0.016896]\n",
            "[Epoch 195/200] [Batch 20/200] [D loss: 0.000318] [G loss: 0.018025]\n",
            "[Epoch 195/200] [Batch 21/200] [D loss: 0.000231] [G loss: 0.020139]\n",
            "[Epoch 195/200] [Batch 22/200] [D loss: 0.000079] [G loss: 0.016551]\n",
            "[Epoch 195/200] [Batch 23/200] [D loss: 0.000242] [G loss: 0.016436]\n",
            "[Epoch 195/200] [Batch 24/200] [D loss: 0.000258] [G loss: 0.018164]\n",
            "[Epoch 195/200] [Batch 25/200] [D loss: 0.000162] [G loss: 0.017905]\n",
            "[Epoch 195/200] [Batch 26/200] [D loss: 0.000115] [G loss: 0.023231]\n",
            "[Epoch 195/200] [Batch 27/200] [D loss: 0.000232] [G loss: 0.018110]\n",
            "[Epoch 195/200] [Batch 28/200] [D loss: 0.000324] [G loss: 0.015313]\n",
            "[Epoch 195/200] [Batch 29/200] [D loss: 0.000209] [G loss: 0.019374]\n",
            "[Epoch 195/200] [Batch 30/200] [D loss: 0.000148] [G loss: 0.019205]\n",
            "[Epoch 195/200] [Batch 31/200] [D loss: 0.000117] [G loss: 0.015826]\n",
            "[Epoch 195/200] [Batch 32/200] [D loss: 0.000069] [G loss: 0.013442]\n",
            "[Epoch 195/200] [Batch 33/200] [D loss: 0.000259] [G loss: 0.018978]\n",
            "[Epoch 195/200] [Batch 34/200] [D loss: 0.000180] [G loss: 0.016533]\n",
            "[Epoch 195/200] [Batch 35/200] [D loss: 0.000101] [G loss: 0.018053]\n",
            "[Epoch 195/200] [Batch 36/200] [D loss: 0.000188] [G loss: 0.015017]\n",
            "[Epoch 195/200] [Batch 37/200] [D loss: 0.000099] [G loss: 0.013921]\n",
            "[Epoch 195/200] [Batch 38/200] [D loss: 0.000226] [G loss: 0.021025]\n",
            "[Epoch 195/200] [Batch 39/200] [D loss: 0.000112] [G loss: 0.017561]\n",
            "[Epoch 195/200] [Batch 40/200] [D loss: 0.000098] [G loss: 0.018380]\n",
            "[Epoch 195/200] [Batch 41/200] [D loss: 0.000117] [G loss: 0.017155]\n",
            "[Epoch 195/200] [Batch 42/200] [D loss: 0.000273] [G loss: 0.016334]\n",
            "[Epoch 195/200] [Batch 43/200] [D loss: 0.000476] [G loss: 0.019141]\n",
            "[Epoch 195/200] [Batch 44/200] [D loss: 0.000415] [G loss: 0.016657]\n",
            "[Epoch 195/200] [Batch 45/200] [D loss: 0.000120] [G loss: 0.017514]\n",
            "[Epoch 195/200] [Batch 46/200] [D loss: 0.000199] [G loss: 0.017423]\n",
            "[Epoch 195/200] [Batch 47/200] [D loss: 0.000230] [G loss: 0.018057]\n",
            "[Epoch 195/200] [Batch 48/200] [D loss: 0.000096] [G loss: 0.016749]\n",
            "[Epoch 195/200] [Batch 49/200] [D loss: 0.000179] [G loss: 0.018074]\n",
            "[Epoch 195/200] [Batch 50/200] [D loss: 0.000068] [G loss: 0.016631]\n",
            "[Epoch 195/200] [Batch 51/200] [D loss: 0.000146] [G loss: 0.016971]\n",
            "[Epoch 195/200] [Batch 52/200] [D loss: 0.000146] [G loss: 0.014859]\n",
            "[Epoch 195/200] [Batch 53/200] [D loss: 0.000058] [G loss: 0.014968]\n",
            "[Epoch 195/200] [Batch 54/200] [D loss: 0.000094] [G loss: 0.017054]\n",
            "[Epoch 195/200] [Batch 55/200] [D loss: 0.000071] [G loss: 0.016075]\n",
            "[Epoch 195/200] [Batch 56/200] [D loss: 0.000041] [G loss: 0.015174]\n",
            "[Epoch 195/200] [Batch 57/200] [D loss: 0.000109] [G loss: 0.019566]\n",
            "[Epoch 195/200] [Batch 58/200] [D loss: 0.000110] [G loss: 0.013572]\n",
            "[Epoch 195/200] [Batch 59/200] [D loss: 0.000142] [G loss: 0.017801]\n",
            "[Epoch 195/200] [Batch 60/200] [D loss: 0.000242] [G loss: 0.013221]\n",
            "[Epoch 195/200] [Batch 61/200] [D loss: 0.000221] [G loss: 0.016842]\n",
            "[Epoch 195/200] [Batch 62/200] [D loss: 0.000236] [G loss: 0.017581]\n",
            "[Epoch 195/200] [Batch 63/200] [D loss: 0.000287] [G loss: 0.016788]\n",
            "[Epoch 195/200] [Batch 64/200] [D loss: 0.000094] [G loss: 0.017786]\n",
            "[Epoch 195/200] [Batch 65/200] [D loss: 0.000150] [G loss: 0.017818]\n",
            "[Epoch 195/200] [Batch 66/200] [D loss: 0.000212] [G loss: 0.017055]\n",
            "[Epoch 195/200] [Batch 67/200] [D loss: 0.000091] [G loss: 0.016639]\n",
            "[Epoch 195/200] [Batch 68/200] [D loss: 0.000141] [G loss: 0.015807]\n",
            "[Epoch 195/200] [Batch 69/200] [D loss: 0.000151] [G loss: 0.018872]\n",
            "[Epoch 195/200] [Batch 70/200] [D loss: 0.000175] [G loss: 0.016495]\n",
            "[Epoch 195/200] [Batch 71/200] [D loss: 0.000100] [G loss: 0.013087]\n",
            "[Epoch 195/200] [Batch 72/200] [D loss: 0.000055] [G loss: 0.016241]\n",
            "[Epoch 195/200] [Batch 73/200] [D loss: 0.000098] [G loss: 0.019406]\n",
            "[Epoch 195/200] [Batch 74/200] [D loss: 0.000075] [G loss: 0.017206]\n",
            "[Epoch 195/200] [Batch 75/200] [D loss: 0.000033] [G loss: 0.018263]\n",
            "[Epoch 195/200] [Batch 76/200] [D loss: 0.000037] [G loss: 0.019804]\n",
            "[Epoch 195/200] [Batch 77/200] [D loss: 0.000052] [G loss: 0.016701]\n",
            "[Epoch 195/200] [Batch 78/200] [D loss: 0.000136] [G loss: 0.020946]\n",
            "[Epoch 195/200] [Batch 79/200] [D loss: 0.000127] [G loss: 0.015084]\n",
            "[Epoch 195/200] [Batch 80/200] [D loss: 0.000098] [G loss: 0.015066]\n",
            "[Epoch 195/200] [Batch 81/200] [D loss: 0.000143] [G loss: 0.022622]\n",
            "[Epoch 195/200] [Batch 82/200] [D loss: 0.000113] [G loss: 0.016386]\n",
            "[Epoch 195/200] [Batch 83/200] [D loss: 0.000057] [G loss: 0.016366]\n",
            "[Epoch 195/200] [Batch 84/200] [D loss: 0.000035] [G loss: 0.015809]\n",
            "[Epoch 195/200] [Batch 85/200] [D loss: 0.000063] [G loss: 0.018924]\n",
            "[Epoch 195/200] [Batch 86/200] [D loss: 0.000070] [G loss: 0.013832]\n",
            "[Epoch 195/200] [Batch 87/200] [D loss: 0.000068] [G loss: 0.016820]\n",
            "[Epoch 195/200] [Batch 88/200] [D loss: 0.000048] [G loss: 0.017621]\n",
            "[Epoch 195/200] [Batch 89/200] [D loss: 0.000126] [G loss: 0.015454]\n",
            "[Epoch 195/200] [Batch 90/200] [D loss: 0.000266] [G loss: 0.019978]\n",
            "[Epoch 195/200] [Batch 91/200] [D loss: 0.000154] [G loss: 0.014461]\n",
            "[Epoch 195/200] [Batch 92/200] [D loss: 0.000082] [G loss: 0.020937]\n",
            "[Epoch 195/200] [Batch 93/200] [D loss: 0.000092] [G loss: 0.018814]\n",
            "[Epoch 195/200] [Batch 94/200] [D loss: 0.000137] [G loss: 0.018846]\n",
            "[Epoch 195/200] [Batch 95/200] [D loss: 0.000195] [G loss: 0.018146]\n",
            "[Epoch 195/200] [Batch 96/200] [D loss: 0.000095] [G loss: 0.013178]\n",
            "[Epoch 195/200] [Batch 97/200] [D loss: 0.000106] [G loss: 0.018797]\n",
            "[Epoch 195/200] [Batch 98/200] [D loss: 0.000119] [G loss: 0.019153]\n",
            "[Epoch 195/200] [Batch 99/200] [D loss: 0.000217] [G loss: 0.014259]\n",
            "[Epoch 195/200] [Batch 100/200] [D loss: 0.000096] [G loss: 0.015830]\n",
            "[Epoch 195/200] [Batch 101/200] [D loss: 0.000154] [G loss: 0.020174]\n",
            "[Epoch 195/200] [Batch 102/200] [D loss: 0.000223] [G loss: 0.015936]\n",
            "[Epoch 195/200] [Batch 103/200] [D loss: 0.000130] [G loss: 0.018053]\n",
            "[Epoch 195/200] [Batch 104/200] [D loss: 0.000089] [G loss: 0.017614]\n",
            "[Epoch 195/200] [Batch 105/200] [D loss: 0.000077] [G loss: 0.016888]\n",
            "[Epoch 195/200] [Batch 106/200] [D loss: 0.000119] [G loss: 0.016304]\n",
            "[Epoch 195/200] [Batch 107/200] [D loss: 0.000133] [G loss: 0.017471]\n",
            "[Epoch 195/200] [Batch 108/200] [D loss: 0.000071] [G loss: 0.020679]\n",
            "[Epoch 195/200] [Batch 109/200] [D loss: 0.000067] [G loss: 0.021408]\n",
            "[Epoch 195/200] [Batch 110/200] [D loss: 0.000115] [G loss: 0.014464]\n",
            "[Epoch 195/200] [Batch 111/200] [D loss: 0.000073] [G loss: 0.018196]\n",
            "[Epoch 195/200] [Batch 112/200] [D loss: 0.000083] [G loss: 0.023542]\n",
            "[Epoch 195/200] [Batch 113/200] [D loss: 0.000128] [G loss: 0.018828]\n",
            "[Epoch 195/200] [Batch 114/200] [D loss: 0.000120] [G loss: 0.018578]\n",
            "[Epoch 195/200] [Batch 115/200] [D loss: 0.000051] [G loss: 0.017314]\n",
            "[Epoch 195/200] [Batch 116/200] [D loss: 0.000075] [G loss: 0.019893]\n",
            "[Epoch 195/200] [Batch 117/200] [D loss: 0.000089] [G loss: 0.018203]\n",
            "[Epoch 195/200] [Batch 118/200] [D loss: 0.000059] [G loss: 0.016995]\n",
            "[Epoch 195/200] [Batch 119/200] [D loss: 0.000048] [G loss: 0.019957]\n",
            "[Epoch 195/200] [Batch 120/200] [D loss: 0.000054] [G loss: 0.016812]\n",
            "[Epoch 195/200] [Batch 121/200] [D loss: 0.000034] [G loss: 0.019205]\n",
            "[Epoch 195/200] [Batch 122/200] [D loss: 0.000036] [G loss: 0.017808]\n",
            "[Epoch 195/200] [Batch 123/200] [D loss: 0.000069] [G loss: 0.017822]\n",
            "[Epoch 195/200] [Batch 124/200] [D loss: 0.000124] [G loss: 0.019883]\n",
            "[Epoch 195/200] [Batch 125/200] [D loss: 0.000171] [G loss: 0.019097]\n",
            "[Epoch 195/200] [Batch 126/200] [D loss: 0.000062] [G loss: 0.017627]\n",
            "[Epoch 195/200] [Batch 127/200] [D loss: 0.000107] [G loss: 0.015835]\n",
            "[Epoch 195/200] [Batch 128/200] [D loss: 0.000068] [G loss: 0.016366]\n",
            "[Epoch 195/200] [Batch 129/200] [D loss: 0.000301] [G loss: 0.022595]\n",
            "[Epoch 195/200] [Batch 130/200] [D loss: 0.000442] [G loss: 0.018639]\n",
            "[Epoch 195/200] [Batch 131/200] [D loss: 0.000092] [G loss: 0.015313]\n",
            "[Epoch 195/200] [Batch 132/200] [D loss: 0.000099] [G loss: 0.017595]\n",
            "[Epoch 195/200] [Batch 133/200] [D loss: 0.000101] [G loss: 0.018756]\n",
            "[Epoch 195/200] [Batch 134/200] [D loss: 0.000154] [G loss: 0.019622]\n",
            "[Epoch 195/200] [Batch 135/200] [D loss: 0.000126] [G loss: 0.015940]\n",
            "[Epoch 195/200] [Batch 136/200] [D loss: 0.000106] [G loss: 0.017456]\n",
            "[Epoch 195/200] [Batch 137/200] [D loss: 0.000103] [G loss: 0.013463]\n",
            "[Epoch 195/200] [Batch 138/200] [D loss: 0.000081] [G loss: 0.017906]\n",
            "[Epoch 195/200] [Batch 139/200] [D loss: 0.000160] [G loss: 0.023105]\n",
            "[Epoch 195/200] [Batch 140/200] [D loss: 0.000240] [G loss: 0.018916]\n",
            "[Epoch 195/200] [Batch 141/200] [D loss: 0.000092] [G loss: 0.016488]\n",
            "[Epoch 195/200] [Batch 142/200] [D loss: 0.000109] [G loss: 0.016926]\n",
            "[Epoch 195/200] [Batch 143/200] [D loss: 0.000165] [G loss: 0.015902]\n",
            "[Epoch 195/200] [Batch 144/200] [D loss: 0.000212] [G loss: 0.019485]\n",
            "[Epoch 195/200] [Batch 145/200] [D loss: 0.000163] [G loss: 0.014744]\n",
            "[Epoch 195/200] [Batch 146/200] [D loss: 0.000177] [G loss: 0.018386]\n",
            "[Epoch 195/200] [Batch 147/200] [D loss: 0.000080] [G loss: 0.019901]\n",
            "[Epoch 195/200] [Batch 148/200] [D loss: 0.000095] [G loss: 0.015352]\n",
            "[Epoch 195/200] [Batch 149/200] [D loss: 0.000135] [G loss: 0.015331]\n",
            "[Epoch 195/200] [Batch 150/200] [D loss: 0.000178] [G loss: 0.014755]\n",
            "[Epoch 195/200] [Batch 151/200] [D loss: 0.000085] [G loss: 0.018963]\n",
            "[Epoch 195/200] [Batch 152/200] [D loss: 0.000107] [G loss: 0.016764]\n",
            "[Epoch 195/200] [Batch 153/200] [D loss: 0.000069] [G loss: 0.015200]\n",
            "[Epoch 195/200] [Batch 154/200] [D loss: 0.000067] [G loss: 0.019468]\n",
            "[Epoch 195/200] [Batch 155/200] [D loss: 0.000170] [G loss: 0.019126]\n",
            "[Epoch 195/200] [Batch 156/200] [D loss: 0.000333] [G loss: 0.017811]\n",
            "[Epoch 195/200] [Batch 157/200] [D loss: 0.000240] [G loss: 0.020806]\n",
            "[Epoch 195/200] [Batch 158/200] [D loss: 0.000358] [G loss: 0.020387]\n",
            "[Epoch 195/200] [Batch 159/200] [D loss: 0.000305] [G loss: 0.016315]\n",
            "[Epoch 195/200] [Batch 160/200] [D loss: 0.000162] [G loss: 0.016887]\n",
            "[Epoch 195/200] [Batch 161/200] [D loss: 0.000128] [G loss: 0.016753]\n",
            "[Epoch 195/200] [Batch 162/200] [D loss: 0.000125] [G loss: 0.015313]\n",
            "[Epoch 195/200] [Batch 163/200] [D loss: 0.000085] [G loss: 0.017590]\n",
            "[Epoch 195/200] [Batch 164/200] [D loss: 0.000090] [G loss: 0.016749]\n",
            "[Epoch 195/200] [Batch 165/200] [D loss: 0.000135] [G loss: 0.015855]\n",
            "[Epoch 195/200] [Batch 166/200] [D loss: 0.000111] [G loss: 0.012431]\n",
            "[Epoch 195/200] [Batch 167/200] [D loss: 0.000157] [G loss: 0.017722]\n",
            "[Epoch 195/200] [Batch 168/200] [D loss: 0.000108] [G loss: 0.020705]\n",
            "[Epoch 195/200] [Batch 169/200] [D loss: 0.000080] [G loss: 0.020576]\n",
            "[Epoch 195/200] [Batch 170/200] [D loss: 0.000162] [G loss: 0.014280]\n",
            "[Epoch 195/200] [Batch 171/200] [D loss: 0.000119] [G loss: 0.017620]\n",
            "[Epoch 195/200] [Batch 172/200] [D loss: 0.000056] [G loss: 0.015503]\n",
            "[Epoch 195/200] [Batch 173/200] [D loss: 0.000081] [G loss: 0.017404]\n",
            "[Epoch 195/200] [Batch 174/200] [D loss: 0.000075] [G loss: 0.017542]\n",
            "[Epoch 195/200] [Batch 175/200] [D loss: 0.000060] [G loss: 0.017230]\n",
            "[Epoch 195/200] [Batch 176/200] [D loss: 0.000064] [G loss: 0.019943]\n",
            "[Epoch 195/200] [Batch 177/200] [D loss: 0.000065] [G loss: 0.022612]\n",
            "[Epoch 195/200] [Batch 178/200] [D loss: 0.000070] [G loss: 0.019380]\n",
            "[Epoch 195/200] [Batch 179/200] [D loss: 0.000041] [G loss: 0.017767]\n",
            "[Epoch 195/200] [Batch 180/200] [D loss: 0.000075] [G loss: 0.018378]\n",
            "[Epoch 195/200] [Batch 181/200] [D loss: 0.000052] [G loss: 0.017337]\n",
            "[Epoch 195/200] [Batch 182/200] [D loss: 0.000058] [G loss: 0.019812]\n",
            "[Epoch 195/200] [Batch 183/200] [D loss: 0.000048] [G loss: 0.017820]\n",
            "[Epoch 195/200] [Batch 184/200] [D loss: 0.000126] [G loss: 0.012305]\n",
            "[Epoch 195/200] [Batch 185/200] [D loss: 0.000160] [G loss: 0.017209]\n",
            "[Epoch 195/200] [Batch 186/200] [D loss: 0.000076] [G loss: 0.015776]\n",
            "[Epoch 195/200] [Batch 187/200] [D loss: 0.000056] [G loss: 0.022098]\n",
            "[Epoch 195/200] [Batch 188/200] [D loss: 0.000080] [G loss: 0.019745]\n",
            "[Epoch 195/200] [Batch 189/200] [D loss: 0.000045] [G loss: 0.014407]\n",
            "[Epoch 195/200] [Batch 190/200] [D loss: 0.000040] [G loss: 0.020499]\n",
            "[Epoch 195/200] [Batch 191/200] [D loss: 0.000046] [G loss: 0.014824]\n",
            "[Epoch 195/200] [Batch 192/200] [D loss: 0.000054] [G loss: 0.018210]\n",
            "[Epoch 195/200] [Batch 193/200] [D loss: 0.000048] [G loss: 0.017365]\n",
            "[Epoch 195/200] [Batch 194/200] [D loss: 0.000040] [G loss: 0.015482]\n",
            "[Epoch 195/200] [Batch 195/200] [D loss: 0.000074] [G loss: 0.017354]\n",
            "[Epoch 195/200] [Batch 196/200] [D loss: 0.000089] [G loss: 0.014533]\n",
            "[Epoch 195/200] [Batch 197/200] [D loss: 0.000132] [G loss: 0.018751]\n",
            "[Epoch 195/200] [Batch 198/200] [D loss: 0.000180] [G loss: 0.014837]\n",
            "[Epoch 195/200] [Batch 199/200] [D loss: 0.000332] [G loss: 0.021314]\n",
            "[Epoch 196/200] [Batch 0/200] [D loss: 0.000283] [G loss: 0.017916]\n",
            "[Epoch 196/200] [Batch 1/200] [D loss: 0.000128] [G loss: 0.019000]\n",
            "[Epoch 196/200] [Batch 2/200] [D loss: 0.000077] [G loss: 0.019329]\n",
            "[Epoch 196/200] [Batch 3/200] [D loss: 0.000073] [G loss: 0.015776]\n",
            "[Epoch 196/200] [Batch 4/200] [D loss: 0.000047] [G loss: 0.017728]\n",
            "[Epoch 196/200] [Batch 5/200] [D loss: 0.000045] [G loss: 0.018177]\n",
            "[Epoch 196/200] [Batch 6/200] [D loss: 0.000044] [G loss: 0.015739]\n",
            "[Epoch 196/200] [Batch 7/200] [D loss: 0.000050] [G loss: 0.016716]\n",
            "[Epoch 196/200] [Batch 8/200] [D loss: 0.000092] [G loss: 0.020361]\n",
            "[Epoch 196/200] [Batch 9/200] [D loss: 0.000125] [G loss: 0.016849]\n",
            "[Epoch 196/200] [Batch 10/200] [D loss: 0.000111] [G loss: 0.016245]\n",
            "[Epoch 196/200] [Batch 11/200] [D loss: 0.000095] [G loss: 0.014418]\n",
            "[Epoch 196/200] [Batch 12/200] [D loss: 0.000065] [G loss: 0.017590]\n",
            "[Epoch 196/200] [Batch 13/200] [D loss: 0.000149] [G loss: 0.016310]\n",
            "[Epoch 196/200] [Batch 14/200] [D loss: 0.000124] [G loss: 0.015702]\n",
            "[Epoch 196/200] [Batch 15/200] [D loss: 0.000068] [G loss: 0.016341]\n",
            "[Epoch 196/200] [Batch 16/200] [D loss: 0.000096] [G loss: 0.018097]\n",
            "[Epoch 196/200] [Batch 17/200] [D loss: 0.000214] [G loss: 0.018207]\n",
            "[Epoch 196/200] [Batch 18/200] [D loss: 0.000178] [G loss: 0.015547]\n",
            "[Epoch 196/200] [Batch 19/200] [D loss: 0.000130] [G loss: 0.015801]\n",
            "[Epoch 196/200] [Batch 20/200] [D loss: 0.000052] [G loss: 0.021346]\n",
            "[Epoch 196/200] [Batch 21/200] [D loss: 0.000107] [G loss: 0.020160]\n",
            "[Epoch 196/200] [Batch 22/200] [D loss: 0.000112] [G loss: 0.014746]\n",
            "[Epoch 196/200] [Batch 23/200] [D loss: 0.000076] [G loss: 0.017128]\n",
            "[Epoch 196/200] [Batch 24/200] [D loss: 0.000122] [G loss: 0.021223]\n",
            "[Epoch 196/200] [Batch 25/200] [D loss: 0.000067] [G loss: 0.017380]\n",
            "[Epoch 196/200] [Batch 26/200] [D loss: 0.000100] [G loss: 0.016340]\n",
            "[Epoch 196/200] [Batch 27/200] [D loss: 0.000076] [G loss: 0.017479]\n",
            "[Epoch 196/200] [Batch 28/200] [D loss: 0.000131] [G loss: 0.019249]\n",
            "[Epoch 196/200] [Batch 29/200] [D loss: 0.000054] [G loss: 0.014907]\n",
            "[Epoch 196/200] [Batch 30/200] [D loss: 0.000132] [G loss: 0.018112]\n",
            "[Epoch 196/200] [Batch 31/200] [D loss: 0.000072] [G loss: 0.018770]\n",
            "[Epoch 196/200] [Batch 32/200] [D loss: 0.000071] [G loss: 0.019242]\n",
            "[Epoch 196/200] [Batch 33/200] [D loss: 0.000098] [G loss: 0.020202]\n",
            "[Epoch 196/200] [Batch 34/200] [D loss: 0.000036] [G loss: 0.014884]\n",
            "[Epoch 196/200] [Batch 35/200] [D loss: 0.000094] [G loss: 0.019475]\n",
            "[Epoch 196/200] [Batch 36/200] [D loss: 0.000138] [G loss: 0.017788]\n",
            "[Epoch 196/200] [Batch 37/200] [D loss: 0.000079] [G loss: 0.017140]\n",
            "[Epoch 196/200] [Batch 38/200] [D loss: 0.000077] [G loss: 0.019178]\n",
            "[Epoch 196/200] [Batch 39/200] [D loss: 0.000223] [G loss: 0.015780]\n",
            "[Epoch 196/200] [Batch 40/200] [D loss: 0.000188] [G loss: 0.014252]\n",
            "[Epoch 196/200] [Batch 41/200] [D loss: 0.000069] [G loss: 0.017015]\n",
            "[Epoch 196/200] [Batch 42/200] [D loss: 0.000038] [G loss: 0.016265]\n",
            "[Epoch 196/200] [Batch 43/200] [D loss: 0.000095] [G loss: 0.017586]\n",
            "[Epoch 196/200] [Batch 44/200] [D loss: 0.000071] [G loss: 0.020578]\n",
            "[Epoch 196/200] [Batch 45/200] [D loss: 0.000050] [G loss: 0.018413]\n",
            "[Epoch 196/200] [Batch 46/200] [D loss: 0.000069] [G loss: 0.016089]\n",
            "[Epoch 196/200] [Batch 47/200] [D loss: 0.000113] [G loss: 0.017388]\n",
            "[Epoch 196/200] [Batch 48/200] [D loss: 0.000055] [G loss: 0.014809]\n",
            "[Epoch 196/200] [Batch 49/200] [D loss: 0.000067] [G loss: 0.018674]\n",
            "[Epoch 196/200] [Batch 50/200] [D loss: 0.000113] [G loss: 0.018841]\n",
            "[Epoch 196/200] [Batch 51/200] [D loss: 0.000122] [G loss: 0.016442]\n",
            "[Epoch 196/200] [Batch 52/200] [D loss: 0.000051] [G loss: 0.016568]\n",
            "[Epoch 196/200] [Batch 53/200] [D loss: 0.000050] [G loss: 0.017511]\n",
            "[Epoch 196/200] [Batch 54/200] [D loss: 0.000056] [G loss: 0.016200]\n",
            "[Epoch 196/200] [Batch 55/200] [D loss: 0.000046] [G loss: 0.013062]\n",
            "[Epoch 196/200] [Batch 56/200] [D loss: 0.000073] [G loss: 0.015574]\n",
            "[Epoch 196/200] [Batch 57/200] [D loss: 0.000078] [G loss: 0.018974]\n",
            "[Epoch 196/200] [Batch 58/200] [D loss: 0.000041] [G loss: 0.016388]\n",
            "[Epoch 196/200] [Batch 59/200] [D loss: 0.000057] [G loss: 0.017331]\n",
            "[Epoch 196/200] [Batch 60/200] [D loss: 0.000084] [G loss: 0.020693]\n",
            "[Epoch 196/200] [Batch 61/200] [D loss: 0.000084] [G loss: 0.016579]\n",
            "[Epoch 196/200] [Batch 62/200] [D loss: 0.000092] [G loss: 0.015049]\n",
            "[Epoch 196/200] [Batch 63/200] [D loss: 0.000117] [G loss: 0.017267]\n",
            "[Epoch 196/200] [Batch 64/200] [D loss: 0.000099] [G loss: 0.017242]\n",
            "[Epoch 196/200] [Batch 65/200] [D loss: 0.000091] [G loss: 0.015981]\n",
            "[Epoch 196/200] [Batch 66/200] [D loss: 0.000224] [G loss: 0.018239]\n",
            "[Epoch 196/200] [Batch 67/200] [D loss: 0.000131] [G loss: 0.017733]\n",
            "[Epoch 196/200] [Batch 68/200] [D loss: 0.000063] [G loss: 0.019219]\n",
            "[Epoch 196/200] [Batch 69/200] [D loss: 0.000076] [G loss: 0.017754]\n",
            "[Epoch 196/200] [Batch 70/200] [D loss: 0.000076] [G loss: 0.018756]\n",
            "[Epoch 196/200] [Batch 71/200] [D loss: 0.000057] [G loss: 0.018330]\n",
            "[Epoch 196/200] [Batch 72/200] [D loss: 0.000079] [G loss: 0.019718]\n",
            "[Epoch 196/200] [Batch 73/200] [D loss: 0.000299] [G loss: 0.018042]\n",
            "[Epoch 196/200] [Batch 74/200] [D loss: 0.000358] [G loss: 0.016394]\n",
            "[Epoch 196/200] [Batch 75/200] [D loss: 0.000136] [G loss: 0.015355]\n",
            "[Epoch 196/200] [Batch 76/200] [D loss: 0.000288] [G loss: 0.018380]\n",
            "[Epoch 196/200] [Batch 77/200] [D loss: 0.000140] [G loss: 0.022097]\n",
            "[Epoch 196/200] [Batch 78/200] [D loss: 0.000497] [G loss: 0.015647]\n",
            "[Epoch 196/200] [Batch 79/200] [D loss: 0.000300] [G loss: 0.019723]\n",
            "[Epoch 196/200] [Batch 80/200] [D loss: 0.000078] [G loss: 0.021122]\n",
            "[Epoch 196/200] [Batch 81/200] [D loss: 0.000112] [G loss: 0.014507]\n",
            "[Epoch 196/200] [Batch 82/200] [D loss: 0.000115] [G loss: 0.015721]\n",
            "[Epoch 196/200] [Batch 83/200] [D loss: 0.000092] [G loss: 0.020130]\n",
            "[Epoch 196/200] [Batch 84/200] [D loss: 0.000102] [G loss: 0.015710]\n",
            "[Epoch 196/200] [Batch 85/200] [D loss: 0.000110] [G loss: 0.014348]\n",
            "[Epoch 196/200] [Batch 86/200] [D loss: 0.000253] [G loss: 0.013987]\n",
            "[Epoch 196/200] [Batch 87/200] [D loss: 0.000453] [G loss: 0.017971]\n",
            "[Epoch 196/200] [Batch 88/200] [D loss: 0.000179] [G loss: 0.014469]\n",
            "[Epoch 196/200] [Batch 89/200] [D loss: 0.000089] [G loss: 0.016498]\n",
            "[Epoch 196/200] [Batch 90/200] [D loss: 0.000127] [G loss: 0.013606]\n",
            "[Epoch 196/200] [Batch 91/200] [D loss: 0.000131] [G loss: 0.021674]\n",
            "[Epoch 196/200] [Batch 92/200] [D loss: 0.000145] [G loss: 0.016060]\n",
            "[Epoch 196/200] [Batch 93/200] [D loss: 0.000064] [G loss: 0.017804]\n",
            "[Epoch 196/200] [Batch 94/200] [D loss: 0.000078] [G loss: 0.020481]\n",
            "[Epoch 196/200] [Batch 95/200] [D loss: 0.000080] [G loss: 0.017227]\n",
            "[Epoch 196/200] [Batch 96/200] [D loss: 0.000078] [G loss: 0.017483]\n",
            "[Epoch 196/200] [Batch 97/200] [D loss: 0.000055] [G loss: 0.019856]\n",
            "[Epoch 196/200] [Batch 98/200] [D loss: 0.000057] [G loss: 0.014944]\n",
            "[Epoch 196/200] [Batch 99/200] [D loss: 0.000125] [G loss: 0.015177]\n",
            "[Epoch 196/200] [Batch 100/200] [D loss: 0.000050] [G loss: 0.019300]\n",
            "[Epoch 196/200] [Batch 101/200] [D loss: 0.000066] [G loss: 0.015121]\n",
            "[Epoch 196/200] [Batch 102/200] [D loss: 0.000089] [G loss: 0.014832]\n",
            "[Epoch 196/200] [Batch 103/200] [D loss: 0.000046] [G loss: 0.016266]\n",
            "[Epoch 196/200] [Batch 104/200] [D loss: 0.000044] [G loss: 0.017948]\n",
            "[Epoch 196/200] [Batch 105/200] [D loss: 0.000099] [G loss: 0.020236]\n",
            "[Epoch 196/200] [Batch 106/200] [D loss: 0.000253] [G loss: 0.021151]\n",
            "[Epoch 196/200] [Batch 107/200] [D loss: 0.000165] [G loss: 0.016551]\n",
            "[Epoch 196/200] [Batch 108/200] [D loss: 0.000107] [G loss: 0.017312]\n",
            "[Epoch 196/200] [Batch 109/200] [D loss: 0.000106] [G loss: 0.019214]\n",
            "[Epoch 196/200] [Batch 110/200] [D loss: 0.000091] [G loss: 0.017680]\n",
            "[Epoch 196/200] [Batch 111/200] [D loss: 0.000135] [G loss: 0.019047]\n",
            "[Epoch 196/200] [Batch 112/200] [D loss: 0.000153] [G loss: 0.021052]\n",
            "[Epoch 196/200] [Batch 113/200] [D loss: 0.000063] [G loss: 0.014546]\n",
            "[Epoch 196/200] [Batch 114/200] [D loss: 0.000109] [G loss: 0.019768]\n",
            "[Epoch 196/200] [Batch 115/200] [D loss: 0.000107] [G loss: 0.018592]\n",
            "[Epoch 196/200] [Batch 116/200] [D loss: 0.000083] [G loss: 0.018922]\n",
            "[Epoch 196/200] [Batch 117/200] [D loss: 0.000083] [G loss: 0.020445]\n",
            "[Epoch 196/200] [Batch 118/200] [D loss: 0.000056] [G loss: 0.011697]\n",
            "[Epoch 196/200] [Batch 119/200] [D loss: 0.000081] [G loss: 0.019945]\n",
            "[Epoch 196/200] [Batch 120/200] [D loss: 0.000109] [G loss: 0.016201]\n",
            "[Epoch 196/200] [Batch 121/200] [D loss: 0.000074] [G loss: 0.022042]\n",
            "[Epoch 196/200] [Batch 122/200] [D loss: 0.000102] [G loss: 0.016272]\n",
            "[Epoch 196/200] [Batch 123/200] [D loss: 0.000139] [G loss: 0.013542]\n",
            "[Epoch 196/200] [Batch 124/200] [D loss: 0.000137] [G loss: 0.021643]\n",
            "[Epoch 196/200] [Batch 125/200] [D loss: 0.000088] [G loss: 0.019313]\n",
            "[Epoch 196/200] [Batch 126/200] [D loss: 0.000179] [G loss: 0.019675]\n",
            "[Epoch 196/200] [Batch 127/200] [D loss: 0.000193] [G loss: 0.019510]\n",
            "[Epoch 196/200] [Batch 128/200] [D loss: 0.000093] [G loss: 0.018736]\n",
            "[Epoch 196/200] [Batch 129/200] [D loss: 0.000217] [G loss: 0.019088]\n",
            "[Epoch 196/200] [Batch 130/200] [D loss: 0.000134] [G loss: 0.016523]\n",
            "[Epoch 196/200] [Batch 131/200] [D loss: 0.000101] [G loss: 0.018429]\n",
            "[Epoch 196/200] [Batch 132/200] [D loss: 0.000066] [G loss: 0.016229]\n",
            "[Epoch 196/200] [Batch 133/200] [D loss: 0.000110] [G loss: 0.019069]\n",
            "[Epoch 196/200] [Batch 134/200] [D loss: 0.000095] [G loss: 0.015022]\n",
            "[Epoch 196/200] [Batch 135/200] [D loss: 0.000050] [G loss: 0.020168]\n",
            "[Epoch 196/200] [Batch 136/200] [D loss: 0.000048] [G loss: 0.020074]\n",
            "[Epoch 196/200] [Batch 137/200] [D loss: 0.000103] [G loss: 0.018005]\n",
            "[Epoch 196/200] [Batch 138/200] [D loss: 0.000110] [G loss: 0.019298]\n",
            "[Epoch 196/200] [Batch 139/200] [D loss: 0.000176] [G loss: 0.016480]\n",
            "[Epoch 196/200] [Batch 140/200] [D loss: 0.000125] [G loss: 0.017083]\n",
            "[Epoch 196/200] [Batch 141/200] [D loss: 0.000104] [G loss: 0.014109]\n",
            "[Epoch 196/200] [Batch 142/200] [D loss: 0.000036] [G loss: 0.016828]\n",
            "[Epoch 196/200] [Batch 143/200] [D loss: 0.000041] [G loss: 0.017724]\n",
            "[Epoch 196/200] [Batch 144/200] [D loss: 0.000059] [G loss: 0.016084]\n",
            "[Epoch 196/200] [Batch 145/200] [D loss: 0.000185] [G loss: 0.019594]\n",
            "[Epoch 196/200] [Batch 146/200] [D loss: 0.000117] [G loss: 0.019571]\n",
            "[Epoch 196/200] [Batch 147/200] [D loss: 0.000110] [G loss: 0.020007]\n",
            "[Epoch 196/200] [Batch 148/200] [D loss: 0.000055] [G loss: 0.019966]\n",
            "[Epoch 196/200] [Batch 149/200] [D loss: 0.000063] [G loss: 0.019164]\n",
            "[Epoch 196/200] [Batch 150/200] [D loss: 0.000069] [G loss: 0.018441]\n",
            "[Epoch 196/200] [Batch 151/200] [D loss: 0.000077] [G loss: 0.018555]\n",
            "[Epoch 196/200] [Batch 152/200] [D loss: 0.000071] [G loss: 0.016772]\n",
            "[Epoch 196/200] [Batch 153/200] [D loss: 0.000124] [G loss: 0.017950]\n",
            "[Epoch 196/200] [Batch 154/200] [D loss: 0.000280] [G loss: 0.015255]\n",
            "[Epoch 196/200] [Batch 155/200] [D loss: 0.000098] [G loss: 0.017325]\n",
            "[Epoch 196/200] [Batch 156/200] [D loss: 0.000104] [G loss: 0.018890]\n",
            "[Epoch 196/200] [Batch 157/200] [D loss: 0.000059] [G loss: 0.020574]\n",
            "[Epoch 196/200] [Batch 158/200] [D loss: 0.000097] [G loss: 0.017460]\n",
            "[Epoch 196/200] [Batch 159/200] [D loss: 0.000074] [G loss: 0.020705]\n",
            "[Epoch 196/200] [Batch 160/200] [D loss: 0.000079] [G loss: 0.018547]\n",
            "[Epoch 196/200] [Batch 161/200] [D loss: 0.000237] [G loss: 0.015416]\n",
            "[Epoch 196/200] [Batch 162/200] [D loss: 0.000084] [G loss: 0.018378]\n",
            "[Epoch 196/200] [Batch 163/200] [D loss: 0.000044] [G loss: 0.018301]\n",
            "[Epoch 196/200] [Batch 164/200] [D loss: 0.000091] [G loss: 0.016883]\n",
            "[Epoch 196/200] [Batch 165/200] [D loss: 0.000044] [G loss: 0.015420]\n",
            "[Epoch 196/200] [Batch 166/200] [D loss: 0.000076] [G loss: 0.013427]\n",
            "[Epoch 196/200] [Batch 167/200] [D loss: 0.000115] [G loss: 0.016871]\n",
            "[Epoch 196/200] [Batch 168/200] [D loss: 0.000133] [G loss: 0.018448]\n",
            "[Epoch 196/200] [Batch 169/200] [D loss: 0.000157] [G loss: 0.016635]\n",
            "[Epoch 196/200] [Batch 170/200] [D loss: 0.000361] [G loss: 0.020112]\n",
            "[Epoch 196/200] [Batch 171/200] [D loss: 0.000169] [G loss: 0.017843]\n",
            "[Epoch 196/200] [Batch 172/200] [D loss: 0.000103] [G loss: 0.019343]\n",
            "[Epoch 196/200] [Batch 173/200] [D loss: 0.000099] [G loss: 0.017739]\n",
            "[Epoch 196/200] [Batch 174/200] [D loss: 0.000111] [G loss: 0.018500]\n",
            "[Epoch 196/200] [Batch 175/200] [D loss: 0.000074] [G loss: 0.016371]\n",
            "[Epoch 196/200] [Batch 176/200] [D loss: 0.000065] [G loss: 0.014592]\n",
            "[Epoch 196/200] [Batch 177/200] [D loss: 0.000074] [G loss: 0.016636]\n",
            "[Epoch 196/200] [Batch 178/200] [D loss: 0.000063] [G loss: 0.016396]\n",
            "[Epoch 196/200] [Batch 179/200] [D loss: 0.000139] [G loss: 0.019589]\n",
            "[Epoch 196/200] [Batch 180/200] [D loss: 0.000232] [G loss: 0.014187]\n",
            "[Epoch 196/200] [Batch 181/200] [D loss: 0.000080] [G loss: 0.018869]\n",
            "[Epoch 196/200] [Batch 182/200] [D loss: 0.000086] [G loss: 0.017465]\n",
            "[Epoch 196/200] [Batch 183/200] [D loss: 0.000145] [G loss: 0.014543]\n",
            "[Epoch 196/200] [Batch 184/200] [D loss: 0.000265] [G loss: 0.016368]\n",
            "[Epoch 196/200] [Batch 185/200] [D loss: 0.000470] [G loss: 0.016436]\n",
            "[Epoch 196/200] [Batch 186/200] [D loss: 0.000285] [G loss: 0.019214]\n",
            "[Epoch 196/200] [Batch 187/200] [D loss: 0.000115] [G loss: 0.016183]\n",
            "[Epoch 196/200] [Batch 188/200] [D loss: 0.000296] [G loss: 0.016027]\n",
            "[Epoch 196/200] [Batch 189/200] [D loss: 0.000197] [G loss: 0.017538]\n",
            "[Epoch 196/200] [Batch 190/200] [D loss: 0.000194] [G loss: 0.018125]\n",
            "[Epoch 196/200] [Batch 191/200] [D loss: 0.000772] [G loss: 0.017501]\n",
            "[Epoch 196/200] [Batch 192/200] [D loss: 0.000739] [G loss: 0.015827]\n",
            "[Epoch 196/200] [Batch 193/200] [D loss: 0.000691] [G loss: 0.013175]\n",
            "[Epoch 196/200] [Batch 194/200] [D loss: 0.001482] [G loss: 0.016379]\n",
            "[Epoch 196/200] [Batch 195/200] [D loss: 0.001216] [G loss: 0.017722]\n",
            "[Epoch 196/200] [Batch 196/200] [D loss: 0.001435] [G loss: 0.019603]\n",
            "[Epoch 196/200] [Batch 197/200] [D loss: 0.001525] [G loss: 0.023445]\n",
            "[Epoch 196/200] [Batch 198/200] [D loss: 0.001594] [G loss: 0.023745]\n",
            "[Epoch 196/200] [Batch 199/200] [D loss: 0.000517] [G loss: 0.015345]\n",
            "[Epoch 197/200] [Batch 0/200] [D loss: 0.000530] [G loss: 0.015957]\n",
            "[Epoch 197/200] [Batch 1/200] [D loss: 0.000695] [G loss: 0.018260]\n",
            "[Epoch 197/200] [Batch 2/200] [D loss: 0.000223] [G loss: 0.017434]\n",
            "[Epoch 197/200] [Batch 3/200] [D loss: 0.000460] [G loss: 0.017309]\n",
            "[Epoch 197/200] [Batch 4/200] [D loss: 0.000399] [G loss: 0.015901]\n",
            "[Epoch 197/200] [Batch 5/200] [D loss: 0.000286] [G loss: 0.021521]\n",
            "[Epoch 197/200] [Batch 6/200] [D loss: 0.000188] [G loss: 0.017579]\n",
            "[Epoch 197/200] [Batch 7/200] [D loss: 0.000099] [G loss: 0.021179]\n",
            "[Epoch 197/200] [Batch 8/200] [D loss: 0.000146] [G loss: 0.017187]\n",
            "[Epoch 197/200] [Batch 9/200] [D loss: 0.000213] [G loss: 0.019707]\n",
            "[Epoch 197/200] [Batch 10/200] [D loss: 0.000386] [G loss: 0.014300]\n",
            "[Epoch 197/200] [Batch 11/200] [D loss: 0.000460] [G loss: 0.019714]\n",
            "[Epoch 197/200] [Batch 12/200] [D loss: 0.000942] [G loss: 0.018611]\n",
            "[Epoch 197/200] [Batch 13/200] [D loss: 0.000473] [G loss: 0.016589]\n",
            "[Epoch 197/200] [Batch 14/200] [D loss: 0.000178] [G loss: 0.015368]\n",
            "[Epoch 197/200] [Batch 15/200] [D loss: 0.000539] [G loss: 0.016712]\n",
            "[Epoch 197/200] [Batch 16/200] [D loss: 0.000425] [G loss: 0.014517]\n",
            "[Epoch 197/200] [Batch 17/200] [D loss: 0.002470] [G loss: 0.018948]\n",
            "[Epoch 197/200] [Batch 18/200] [D loss: 0.009322] [G loss: 0.016456]\n",
            "[Epoch 197/200] [Batch 19/200] [D loss: 0.012341] [G loss: 0.018782]\n",
            "[Epoch 197/200] [Batch 20/200] [D loss: 0.035817] [G loss: 0.022540]\n",
            "[Epoch 197/200] [Batch 21/200] [D loss: 0.056651] [G loss: 0.015628]\n",
            "[Epoch 197/200] [Batch 22/200] [D loss: 0.075246] [G loss: 0.014300]\n",
            "[Epoch 197/200] [Batch 23/200] [D loss: 0.210701] [G loss: 0.013234]\n",
            "[Epoch 197/200] [Batch 24/200] [D loss: 0.244342] [G loss: 0.016394]\n",
            "[Epoch 197/200] [Batch 25/200] [D loss: 0.610034] [G loss: 0.018030]\n",
            "[Epoch 197/200] [Batch 26/200] [D loss: 0.138004] [G loss: 0.014795]\n",
            "[Epoch 197/200] [Batch 27/200] [D loss: 0.168479] [G loss: 0.017875]\n",
            "[Epoch 197/200] [Batch 28/200] [D loss: 0.043807] [G loss: 0.018325]\n",
            "[Epoch 197/200] [Batch 29/200] [D loss: 0.028365] [G loss: 0.016944]\n",
            "[Epoch 197/200] [Batch 30/200] [D loss: 0.019702] [G loss: 0.019668]\n",
            "[Epoch 197/200] [Batch 31/200] [D loss: 0.014267] [G loss: 0.017603]\n",
            "[Epoch 197/200] [Batch 32/200] [D loss: 0.013266] [G loss: 0.020575]\n",
            "[Epoch 197/200] [Batch 33/200] [D loss: 0.005639] [G loss: 0.016106]\n",
            "[Epoch 197/200] [Batch 34/200] [D loss: 0.003995] [G loss: 0.023042]\n",
            "[Epoch 197/200] [Batch 35/200] [D loss: 0.012757] [G loss: 0.022768]\n",
            "[Epoch 197/200] [Batch 36/200] [D loss: 0.004771] [G loss: 0.020586]\n",
            "[Epoch 197/200] [Batch 37/200] [D loss: 0.002397] [G loss: 0.015885]\n",
            "[Epoch 197/200] [Batch 38/200] [D loss: 0.004319] [G loss: 0.019881]\n",
            "[Epoch 197/200] [Batch 39/200] [D loss: 0.002817] [G loss: 0.017187]\n",
            "[Epoch 197/200] [Batch 40/200] [D loss: 0.003439] [G loss: 0.018003]\n",
            "[Epoch 197/200] [Batch 41/200] [D loss: 0.001659] [G loss: 0.017575]\n",
            "[Epoch 197/200] [Batch 42/200] [D loss: 0.002650] [G loss: 0.016148]\n",
            "[Epoch 197/200] [Batch 43/200] [D loss: 0.002557] [G loss: 0.018692]\n",
            "[Epoch 197/200] [Batch 44/200] [D loss: 0.001047] [G loss: 0.017266]\n",
            "[Epoch 197/200] [Batch 45/200] [D loss: 0.001700] [G loss: 0.014192]\n",
            "[Epoch 197/200] [Batch 46/200] [D loss: 0.002558] [G loss: 0.017974]\n",
            "[Epoch 197/200] [Batch 47/200] [D loss: 0.004949] [G loss: 0.016787]\n",
            "[Epoch 197/200] [Batch 48/200] [D loss: 0.009260] [G loss: 0.016655]\n",
            "[Epoch 197/200] [Batch 49/200] [D loss: 0.006139] [G loss: 0.015745]\n",
            "[Epoch 197/200] [Batch 50/200] [D loss: 0.001224] [G loss: 0.016943]\n",
            "[Epoch 197/200] [Batch 51/200] [D loss: 0.001913] [G loss: 0.015306]\n",
            "[Epoch 197/200] [Batch 52/200] [D loss: 0.001284] [G loss: 0.013915]\n",
            "[Epoch 197/200] [Batch 53/200] [D loss: 0.001062] [G loss: 0.016969]\n",
            "[Epoch 197/200] [Batch 54/200] [D loss: 0.000778] [G loss: 0.022019]\n",
            "[Epoch 197/200] [Batch 55/200] [D loss: 0.003271] [G loss: 0.019625]\n",
            "[Epoch 197/200] [Batch 56/200] [D loss: 0.001331] [G loss: 0.018755]\n",
            "[Epoch 197/200] [Batch 57/200] [D loss: 0.003611] [G loss: 0.015393]\n",
            "[Epoch 197/200] [Batch 58/200] [D loss: 0.003918] [G loss: 0.016683]\n",
            "[Epoch 197/200] [Batch 59/200] [D loss: 0.002192] [G loss: 0.018860]\n",
            "[Epoch 197/200] [Batch 60/200] [D loss: 0.001583] [G loss: 0.018133]\n",
            "[Epoch 197/200] [Batch 61/200] [D loss: 0.000563] [G loss: 0.015649]\n",
            "[Epoch 197/200] [Batch 62/200] [D loss: 0.001673] [G loss: 0.018975]\n",
            "[Epoch 197/200] [Batch 63/200] [D loss: 0.001344] [G loss: 0.020806]\n",
            "[Epoch 197/200] [Batch 64/200] [D loss: 0.001308] [G loss: 0.019342]\n",
            "[Epoch 197/200] [Batch 65/200] [D loss: 0.001250] [G loss: 0.016603]\n",
            "[Epoch 197/200] [Batch 66/200] [D loss: 0.000857] [G loss: 0.017281]\n",
            "[Epoch 197/200] [Batch 67/200] [D loss: 0.000487] [G loss: 0.020883]\n",
            "[Epoch 197/200] [Batch 68/200] [D loss: 0.000533] [G loss: 0.016812]\n",
            "[Epoch 197/200] [Batch 69/200] [D loss: 0.000487] [G loss: 0.014962]\n",
            "[Epoch 197/200] [Batch 70/200] [D loss: 0.001444] [G loss: 0.016947]\n",
            "[Epoch 197/200] [Batch 71/200] [D loss: 0.001928] [G loss: 0.017166]\n",
            "[Epoch 197/200] [Batch 72/200] [D loss: 0.001190] [G loss: 0.019235]\n",
            "[Epoch 197/200] [Batch 73/200] [D loss: 0.001802] [G loss: 0.019170]\n",
            "[Epoch 197/200] [Batch 74/200] [D loss: 0.000664] [G loss: 0.017014]\n",
            "[Epoch 197/200] [Batch 75/200] [D loss: 0.001019] [G loss: 0.017034]\n",
            "[Epoch 197/200] [Batch 76/200] [D loss: 0.000580] [G loss: 0.016858]\n",
            "[Epoch 197/200] [Batch 77/200] [D loss: 0.000497] [G loss: 0.016898]\n",
            "[Epoch 197/200] [Batch 78/200] [D loss: 0.001629] [G loss: 0.017682]\n",
            "[Epoch 197/200] [Batch 79/200] [D loss: 0.001727] [G loss: 0.015884]\n",
            "[Epoch 197/200] [Batch 80/200] [D loss: 0.000742] [G loss: 0.021994]\n",
            "[Epoch 197/200] [Batch 81/200] [D loss: 0.000706] [G loss: 0.016063]\n",
            "[Epoch 197/200] [Batch 82/200] [D loss: 0.000914] [G loss: 0.015167]\n",
            "[Epoch 197/200] [Batch 83/200] [D loss: 0.000761] [G loss: 0.017979]\n",
            "[Epoch 197/200] [Batch 84/200] [D loss: 0.000974] [G loss: 0.015497]\n",
            "[Epoch 197/200] [Batch 85/200] [D loss: 0.000449] [G loss: 0.016881]\n",
            "[Epoch 197/200] [Batch 86/200] [D loss: 0.000492] [G loss: 0.015536]\n",
            "[Epoch 197/200] [Batch 87/200] [D loss: 0.000595] [G loss: 0.013200]\n",
            "[Epoch 197/200] [Batch 88/200] [D loss: 0.000487] [G loss: 0.018204]\n",
            "[Epoch 197/200] [Batch 89/200] [D loss: 0.000635] [G loss: 0.014578]\n",
            "[Epoch 197/200] [Batch 90/200] [D loss: 0.000629] [G loss: 0.014712]\n",
            "[Epoch 197/200] [Batch 91/200] [D loss: 0.000373] [G loss: 0.015526]\n",
            "[Epoch 197/200] [Batch 92/200] [D loss: 0.000966] [G loss: 0.021391]\n",
            "[Epoch 197/200] [Batch 93/200] [D loss: 0.000750] [G loss: 0.015824]\n",
            "[Epoch 197/200] [Batch 94/200] [D loss: 0.000320] [G loss: 0.017850]\n",
            "[Epoch 197/200] [Batch 95/200] [D loss: 0.001048] [G loss: 0.020303]\n",
            "[Epoch 197/200] [Batch 96/200] [D loss: 0.000627] [G loss: 0.013959]\n",
            "[Epoch 197/200] [Batch 97/200] [D loss: 0.000629] [G loss: 0.019171]\n",
            "[Epoch 197/200] [Batch 98/200] [D loss: 0.000640] [G loss: 0.016989]\n",
            "[Epoch 197/200] [Batch 99/200] [D loss: 0.001457] [G loss: 0.020456]\n",
            "[Epoch 197/200] [Batch 100/200] [D loss: 0.000394] [G loss: 0.018444]\n",
            "[Epoch 197/200] [Batch 101/200] [D loss: 0.000642] [G loss: 0.017435]\n",
            "[Epoch 197/200] [Batch 102/200] [D loss: 0.000386] [G loss: 0.019011]\n",
            "[Epoch 197/200] [Batch 103/200] [D loss: 0.000342] [G loss: 0.016405]\n",
            "[Epoch 197/200] [Batch 104/200] [D loss: 0.000775] [G loss: 0.018373]\n",
            "[Epoch 197/200] [Batch 105/200] [D loss: 0.000573] [G loss: 0.018996]\n",
            "[Epoch 197/200] [Batch 106/200] [D loss: 0.000498] [G loss: 0.017412]\n",
            "[Epoch 197/200] [Batch 107/200] [D loss: 0.000571] [G loss: 0.016701]\n",
            "[Epoch 197/200] [Batch 108/200] [D loss: 0.000825] [G loss: 0.020169]\n",
            "[Epoch 197/200] [Batch 109/200] [D loss: 0.000951] [G loss: 0.015450]\n",
            "[Epoch 197/200] [Batch 110/200] [D loss: 0.000425] [G loss: 0.019558]\n",
            "[Epoch 197/200] [Batch 111/200] [D loss: 0.001456] [G loss: 0.018467]\n",
            "[Epoch 197/200] [Batch 112/200] [D loss: 0.001476] [G loss: 0.018196]\n",
            "[Epoch 197/200] [Batch 113/200] [D loss: 0.000827] [G loss: 0.017616]\n",
            "[Epoch 197/200] [Batch 114/200] [D loss: 0.001158] [G loss: 0.018549]\n",
            "[Epoch 197/200] [Batch 115/200] [D loss: 0.000532] [G loss: 0.019681]\n",
            "[Epoch 197/200] [Batch 116/200] [D loss: 0.000650] [G loss: 0.017546]\n",
            "[Epoch 197/200] [Batch 117/200] [D loss: 0.000588] [G loss: 0.016919]\n",
            "[Epoch 197/200] [Batch 118/200] [D loss: 0.000479] [G loss: 0.016613]\n",
            "[Epoch 197/200] [Batch 119/200] [D loss: 0.000286] [G loss: 0.016185]\n",
            "[Epoch 197/200] [Batch 120/200] [D loss: 0.000400] [G loss: 0.014519]\n",
            "[Epoch 197/200] [Batch 121/200] [D loss: 0.001181] [G loss: 0.020805]\n",
            "[Epoch 197/200] [Batch 122/200] [D loss: 0.000882] [G loss: 0.014372]\n",
            "[Epoch 197/200] [Batch 123/200] [D loss: 0.000730] [G loss: 0.022088]\n",
            "[Epoch 197/200] [Batch 124/200] [D loss: 0.000675] [G loss: 0.020377]\n",
            "[Epoch 197/200] [Batch 125/200] [D loss: 0.000922] [G loss: 0.019095]\n",
            "[Epoch 197/200] [Batch 126/200] [D loss: 0.000947] [G loss: 0.020687]\n",
            "[Epoch 197/200] [Batch 127/200] [D loss: 0.000316] [G loss: 0.018832]\n",
            "[Epoch 197/200] [Batch 128/200] [D loss: 0.000367] [G loss: 0.016244]\n",
            "[Epoch 197/200] [Batch 129/200] [D loss: 0.000461] [G loss: 0.015884]\n",
            "[Epoch 197/200] [Batch 130/200] [D loss: 0.000319] [G loss: 0.016596]\n",
            "[Epoch 197/200] [Batch 131/200] [D loss: 0.000306] [G loss: 0.020926]\n",
            "[Epoch 197/200] [Batch 132/200] [D loss: 0.000375] [G loss: 0.017410]\n",
            "[Epoch 197/200] [Batch 133/200] [D loss: 0.000517] [G loss: 0.019811]\n",
            "[Epoch 197/200] [Batch 134/200] [D loss: 0.000712] [G loss: 0.012325]\n",
            "[Epoch 197/200] [Batch 135/200] [D loss: 0.000487] [G loss: 0.019446]\n",
            "[Epoch 197/200] [Batch 136/200] [D loss: 0.000317] [G loss: 0.021167]\n",
            "[Epoch 197/200] [Batch 137/200] [D loss: 0.000398] [G loss: 0.020167]\n",
            "[Epoch 197/200] [Batch 138/200] [D loss: 0.000591] [G loss: 0.015794]\n",
            "[Epoch 197/200] [Batch 139/200] [D loss: 0.000780] [G loss: 0.023242]\n",
            "[Epoch 197/200] [Batch 140/200] [D loss: 0.000329] [G loss: 0.018604]\n",
            "[Epoch 197/200] [Batch 141/200] [D loss: 0.000298] [G loss: 0.015511]\n",
            "[Epoch 197/200] [Batch 142/200] [D loss: 0.000574] [G loss: 0.020612]\n",
            "[Epoch 197/200] [Batch 143/200] [D loss: 0.000275] [G loss: 0.016980]\n",
            "[Epoch 197/200] [Batch 144/200] [D loss: 0.000217] [G loss: 0.017023]\n",
            "[Epoch 197/200] [Batch 145/200] [D loss: 0.000312] [G loss: 0.013879]\n",
            "[Epoch 197/200] [Batch 146/200] [D loss: 0.000374] [G loss: 0.017315]\n",
            "[Epoch 197/200] [Batch 147/200] [D loss: 0.000508] [G loss: 0.022462]\n",
            "[Epoch 197/200] [Batch 148/200] [D loss: 0.000250] [G loss: 0.015602]\n",
            "[Epoch 197/200] [Batch 149/200] [D loss: 0.000297] [G loss: 0.020183]\n",
            "[Epoch 197/200] [Batch 150/200] [D loss: 0.000282] [G loss: 0.014174]\n",
            "[Epoch 197/200] [Batch 151/200] [D loss: 0.000360] [G loss: 0.016748]\n",
            "[Epoch 197/200] [Batch 152/200] [D loss: 0.000303] [G loss: 0.018487]\n",
            "[Epoch 197/200] [Batch 153/200] [D loss: 0.000262] [G loss: 0.017192]\n",
            "[Epoch 197/200] [Batch 154/200] [D loss: 0.000316] [G loss: 0.016614]\n",
            "[Epoch 197/200] [Batch 155/200] [D loss: 0.000332] [G loss: 0.016150]\n",
            "[Epoch 197/200] [Batch 156/200] [D loss: 0.000691] [G loss: 0.015339]\n",
            "[Epoch 197/200] [Batch 157/200] [D loss: 0.000460] [G loss: 0.018288]\n",
            "[Epoch 197/200] [Batch 158/200] [D loss: 0.000281] [G loss: 0.017903]\n",
            "[Epoch 197/200] [Batch 159/200] [D loss: 0.000427] [G loss: 0.020697]\n",
            "[Epoch 197/200] [Batch 160/200] [D loss: 0.000381] [G loss: 0.018495]\n",
            "[Epoch 197/200] [Batch 161/200] [D loss: 0.000259] [G loss: 0.017312]\n",
            "[Epoch 197/200] [Batch 162/200] [D loss: 0.000346] [G loss: 0.016095]\n",
            "[Epoch 197/200] [Batch 163/200] [D loss: 0.000591] [G loss: 0.018690]\n",
            "[Epoch 197/200] [Batch 164/200] [D loss: 0.000545] [G loss: 0.013797]\n",
            "[Epoch 197/200] [Batch 165/200] [D loss: 0.000513] [G loss: 0.019877]\n",
            "[Epoch 197/200] [Batch 166/200] [D loss: 0.000473] [G loss: 0.020900]\n",
            "[Epoch 197/200] [Batch 167/200] [D loss: 0.000218] [G loss: 0.014334]\n",
            "[Epoch 197/200] [Batch 168/200] [D loss: 0.000376] [G loss: 0.016963]\n",
            "[Epoch 197/200] [Batch 169/200] [D loss: 0.000594] [G loss: 0.018682]\n",
            "[Epoch 197/200] [Batch 170/200] [D loss: 0.000171] [G loss: 0.015173]\n",
            "[Epoch 197/200] [Batch 171/200] [D loss: 0.000566] [G loss: 0.017053]\n",
            "[Epoch 197/200] [Batch 172/200] [D loss: 0.000414] [G loss: 0.016441]\n",
            "[Epoch 197/200] [Batch 173/200] [D loss: 0.000401] [G loss: 0.016742]\n",
            "[Epoch 197/200] [Batch 174/200] [D loss: 0.000555] [G loss: 0.021005]\n",
            "[Epoch 197/200] [Batch 175/200] [D loss: 0.000236] [G loss: 0.020185]\n",
            "[Epoch 197/200] [Batch 176/200] [D loss: 0.000629] [G loss: 0.016393]\n",
            "[Epoch 197/200] [Batch 177/200] [D loss: 0.000302] [G loss: 0.020964]\n",
            "[Epoch 197/200] [Batch 178/200] [D loss: 0.000252] [G loss: 0.017677]\n",
            "[Epoch 197/200] [Batch 179/200] [D loss: 0.000242] [G loss: 0.016929]\n",
            "[Epoch 197/200] [Batch 180/200] [D loss: 0.000398] [G loss: 0.014858]\n",
            "[Epoch 197/200] [Batch 181/200] [D loss: 0.000474] [G loss: 0.017295]\n",
            "[Epoch 197/200] [Batch 182/200] [D loss: 0.000290] [G loss: 0.016401]\n",
            "[Epoch 197/200] [Batch 183/200] [D loss: 0.000766] [G loss: 0.017590]\n",
            "[Epoch 197/200] [Batch 184/200] [D loss: 0.000368] [G loss: 0.019341]\n",
            "[Epoch 197/200] [Batch 185/200] [D loss: 0.000319] [G loss: 0.015148]\n",
            "[Epoch 197/200] [Batch 186/200] [D loss: 0.000323] [G loss: 0.015902]\n",
            "[Epoch 197/200] [Batch 187/200] [D loss: 0.000553] [G loss: 0.015292]\n",
            "[Epoch 197/200] [Batch 188/200] [D loss: 0.000272] [G loss: 0.016672]\n",
            "[Epoch 197/200] [Batch 189/200] [D loss: 0.000560] [G loss: 0.017047]\n",
            "[Epoch 197/200] [Batch 190/200] [D loss: 0.001234] [G loss: 0.021504]\n",
            "[Epoch 197/200] [Batch 191/200] [D loss: 0.000340] [G loss: 0.015889]\n",
            "[Epoch 197/200] [Batch 192/200] [D loss: 0.000497] [G loss: 0.021196]\n",
            "[Epoch 197/200] [Batch 193/200] [D loss: 0.000429] [G loss: 0.019160]\n",
            "[Epoch 197/200] [Batch 194/200] [D loss: 0.000648] [G loss: 0.017628]\n",
            "[Epoch 197/200] [Batch 195/200] [D loss: 0.000301] [G loss: 0.014679]\n",
            "[Epoch 197/200] [Batch 196/200] [D loss: 0.000285] [G loss: 0.015324]\n",
            "[Epoch 197/200] [Batch 197/200] [D loss: 0.000346] [G loss: 0.020881]\n",
            "[Epoch 197/200] [Batch 198/200] [D loss: 0.000470] [G loss: 0.014417]\n",
            "[Epoch 197/200] [Batch 199/200] [D loss: 0.000208] [G loss: 0.017295]\n",
            "[Epoch 198/200] [Batch 0/200] [D loss: 0.000666] [G loss: 0.019709]\n",
            "[Epoch 198/200] [Batch 1/200] [D loss: 0.000442] [G loss: 0.020205]\n",
            "[Epoch 198/200] [Batch 2/200] [D loss: 0.000325] [G loss: 0.020141]\n",
            "[Epoch 198/200] [Batch 3/200] [D loss: 0.000485] [G loss: 0.013911]\n",
            "[Epoch 198/200] [Batch 4/200] [D loss: 0.001022] [G loss: 0.019629]\n",
            "[Epoch 198/200] [Batch 5/200] [D loss: 0.000426] [G loss: 0.013825]\n",
            "[Epoch 198/200] [Batch 6/200] [D loss: 0.000162] [G loss: 0.019560]\n",
            "[Epoch 198/200] [Batch 7/200] [D loss: 0.000310] [G loss: 0.018495]\n",
            "[Epoch 198/200] [Batch 8/200] [D loss: 0.000492] [G loss: 0.018779]\n",
            "[Epoch 198/200] [Batch 9/200] [D loss: 0.000336] [G loss: 0.018621]\n",
            "[Epoch 198/200] [Batch 10/200] [D loss: 0.000220] [G loss: 0.016159]\n",
            "[Epoch 198/200] [Batch 11/200] [D loss: 0.000266] [G loss: 0.016979]\n",
            "[Epoch 198/200] [Batch 12/200] [D loss: 0.000438] [G loss: 0.015544]\n",
            "[Epoch 198/200] [Batch 13/200] [D loss: 0.000330] [G loss: 0.018242]\n",
            "[Epoch 198/200] [Batch 14/200] [D loss: 0.000251] [G loss: 0.016722]\n",
            "[Epoch 198/200] [Batch 15/200] [D loss: 0.000278] [G loss: 0.015061]\n",
            "[Epoch 198/200] [Batch 16/200] [D loss: 0.000296] [G loss: 0.017620]\n",
            "[Epoch 198/200] [Batch 17/200] [D loss: 0.000258] [G loss: 0.018616]\n",
            "[Epoch 198/200] [Batch 18/200] [D loss: 0.001160] [G loss: 0.019596]\n",
            "[Epoch 198/200] [Batch 19/200] [D loss: 0.000790] [G loss: 0.016639]\n",
            "[Epoch 198/200] [Batch 20/200] [D loss: 0.000277] [G loss: 0.020548]\n",
            "[Epoch 198/200] [Batch 21/200] [D loss: 0.000337] [G loss: 0.018308]\n",
            "[Epoch 198/200] [Batch 22/200] [D loss: 0.000540] [G loss: 0.016625]\n",
            "[Epoch 198/200] [Batch 23/200] [D loss: 0.000350] [G loss: 0.015077]\n",
            "[Epoch 198/200] [Batch 24/200] [D loss: 0.000195] [G loss: 0.017906]\n",
            "[Epoch 198/200] [Batch 25/200] [D loss: 0.000178] [G loss: 0.018201]\n",
            "[Epoch 198/200] [Batch 26/200] [D loss: 0.000339] [G loss: 0.016213]\n",
            "[Epoch 198/200] [Batch 27/200] [D loss: 0.000152] [G loss: 0.014889]\n",
            "[Epoch 198/200] [Batch 28/200] [D loss: 0.000202] [G loss: 0.015379]\n",
            "[Epoch 198/200] [Batch 29/200] [D loss: 0.000166] [G loss: 0.017791]\n",
            "[Epoch 198/200] [Batch 30/200] [D loss: 0.000181] [G loss: 0.012556]\n",
            "[Epoch 198/200] [Batch 31/200] [D loss: 0.000205] [G loss: 0.015617]\n",
            "[Epoch 198/200] [Batch 32/200] [D loss: 0.000372] [G loss: 0.016564]\n",
            "[Epoch 198/200] [Batch 33/200] [D loss: 0.000247] [G loss: 0.020294]\n",
            "[Epoch 198/200] [Batch 34/200] [D loss: 0.000162] [G loss: 0.014886]\n",
            "[Epoch 198/200] [Batch 35/200] [D loss: 0.000141] [G loss: 0.018543]\n",
            "[Epoch 198/200] [Batch 36/200] [D loss: 0.001002] [G loss: 0.019576]\n",
            "[Epoch 198/200] [Batch 37/200] [D loss: 0.000210] [G loss: 0.019956]\n",
            "[Epoch 198/200] [Batch 38/200] [D loss: 0.000252] [G loss: 0.014701]\n",
            "[Epoch 198/200] [Batch 39/200] [D loss: 0.000305] [G loss: 0.018289]\n",
            "[Epoch 198/200] [Batch 40/200] [D loss: 0.000308] [G loss: 0.014812]\n",
            "[Epoch 198/200] [Batch 41/200] [D loss: 0.000378] [G loss: 0.018602]\n",
            "[Epoch 198/200] [Batch 42/200] [D loss: 0.000233] [G loss: 0.018124]\n",
            "[Epoch 198/200] [Batch 43/200] [D loss: 0.000435] [G loss: 0.019162]\n",
            "[Epoch 198/200] [Batch 44/200] [D loss: 0.000379] [G loss: 0.016283]\n",
            "[Epoch 198/200] [Batch 45/200] [D loss: 0.000365] [G loss: 0.016161]\n",
            "[Epoch 198/200] [Batch 46/200] [D loss: 0.000404] [G loss: 0.015288]\n",
            "[Epoch 198/200] [Batch 47/200] [D loss: 0.000256] [G loss: 0.018481]\n",
            "[Epoch 198/200] [Batch 48/200] [D loss: 0.000578] [G loss: 0.018812]\n",
            "[Epoch 198/200] [Batch 49/200] [D loss: 0.000154] [G loss: 0.017842]\n",
            "[Epoch 198/200] [Batch 50/200] [D loss: 0.000195] [G loss: 0.015480]\n",
            "[Epoch 198/200] [Batch 51/200] [D loss: 0.000554] [G loss: 0.019985]\n",
            "[Epoch 198/200] [Batch 52/200] [D loss: 0.000190] [G loss: 0.023190]\n",
            "[Epoch 198/200] [Batch 53/200] [D loss: 0.000285] [G loss: 0.020346]\n",
            "[Epoch 198/200] [Batch 54/200] [D loss: 0.000236] [G loss: 0.019218]\n",
            "[Epoch 198/200] [Batch 55/200] [D loss: 0.000218] [G loss: 0.017469]\n",
            "[Epoch 198/200] [Batch 56/200] [D loss: 0.000227] [G loss: 0.017296]\n",
            "[Epoch 198/200] [Batch 57/200] [D loss: 0.000170] [G loss: 0.016754]\n",
            "[Epoch 198/200] [Batch 58/200] [D loss: 0.000155] [G loss: 0.016667]\n",
            "[Epoch 198/200] [Batch 59/200] [D loss: 0.000425] [G loss: 0.020620]\n",
            "[Epoch 198/200] [Batch 60/200] [D loss: 0.000455] [G loss: 0.017393]\n",
            "[Epoch 198/200] [Batch 61/200] [D loss: 0.000367] [G loss: 0.020797]\n",
            "[Epoch 198/200] [Batch 62/200] [D loss: 0.000366] [G loss: 0.015910]\n",
            "[Epoch 198/200] [Batch 63/200] [D loss: 0.000397] [G loss: 0.017360]\n",
            "[Epoch 198/200] [Batch 64/200] [D loss: 0.000330] [G loss: 0.019517]\n",
            "[Epoch 198/200] [Batch 65/200] [D loss: 0.000374] [G loss: 0.014214]\n",
            "[Epoch 198/200] [Batch 66/200] [D loss: 0.000197] [G loss: 0.018700]\n",
            "[Epoch 198/200] [Batch 67/200] [D loss: 0.000106] [G loss: 0.018066]\n",
            "[Epoch 198/200] [Batch 68/200] [D loss: 0.000181] [G loss: 0.024243]\n",
            "[Epoch 198/200] [Batch 69/200] [D loss: 0.000560] [G loss: 0.017433]\n",
            "[Epoch 198/200] [Batch 70/200] [D loss: 0.000267] [G loss: 0.014431]\n",
            "[Epoch 198/200] [Batch 71/200] [D loss: 0.000260] [G loss: 0.018447]\n",
            "[Epoch 198/200] [Batch 72/200] [D loss: 0.000548] [G loss: 0.019364]\n",
            "[Epoch 198/200] [Batch 73/200] [D loss: 0.000151] [G loss: 0.020283]\n",
            "[Epoch 198/200] [Batch 74/200] [D loss: 0.000248] [G loss: 0.019214]\n",
            "[Epoch 198/200] [Batch 75/200] [D loss: 0.000593] [G loss: 0.015209]\n",
            "[Epoch 198/200] [Batch 76/200] [D loss: 0.000468] [G loss: 0.022326]\n",
            "[Epoch 198/200] [Batch 77/200] [D loss: 0.000259] [G loss: 0.017510]\n",
            "[Epoch 198/200] [Batch 78/200] [D loss: 0.000164] [G loss: 0.015004]\n",
            "[Epoch 198/200] [Batch 79/200] [D loss: 0.000397] [G loss: 0.021006]\n",
            "[Epoch 198/200] [Batch 80/200] [D loss: 0.000116] [G loss: 0.017239]\n",
            "[Epoch 198/200] [Batch 81/200] [D loss: 0.000197] [G loss: 0.015653]\n",
            "[Epoch 198/200] [Batch 82/200] [D loss: 0.000266] [G loss: 0.016912]\n",
            "[Epoch 198/200] [Batch 83/200] [D loss: 0.000120] [G loss: 0.016613]\n",
            "[Epoch 198/200] [Batch 84/200] [D loss: 0.000201] [G loss: 0.016497]\n",
            "[Epoch 198/200] [Batch 85/200] [D loss: 0.000291] [G loss: 0.018930]\n",
            "[Epoch 198/200] [Batch 86/200] [D loss: 0.000229] [G loss: 0.021650]\n",
            "[Epoch 198/200] [Batch 87/200] [D loss: 0.000346] [G loss: 0.015605]\n",
            "[Epoch 198/200] [Batch 88/200] [D loss: 0.000639] [G loss: 0.017098]\n",
            "[Epoch 198/200] [Batch 89/200] [D loss: 0.000405] [G loss: 0.019561]\n",
            "[Epoch 198/200] [Batch 90/200] [D loss: 0.000291] [G loss: 0.017061]\n",
            "[Epoch 198/200] [Batch 91/200] [D loss: 0.000404] [G loss: 0.019130]\n",
            "[Epoch 198/200] [Batch 92/200] [D loss: 0.000264] [G loss: 0.017387]\n",
            "[Epoch 198/200] [Batch 93/200] [D loss: 0.000246] [G loss: 0.018441]\n",
            "[Epoch 198/200] [Batch 94/200] [D loss: 0.000211] [G loss: 0.018369]\n",
            "[Epoch 198/200] [Batch 95/200] [D loss: 0.000333] [G loss: 0.016715]\n",
            "[Epoch 198/200] [Batch 96/200] [D loss: 0.000450] [G loss: 0.016667]\n",
            "[Epoch 198/200] [Batch 97/200] [D loss: 0.000181] [G loss: 0.015963]\n",
            "[Epoch 198/200] [Batch 98/200] [D loss: 0.000309] [G loss: 0.018665]\n",
            "[Epoch 198/200] [Batch 99/200] [D loss: 0.000147] [G loss: 0.018202]\n",
            "[Epoch 198/200] [Batch 100/200] [D loss: 0.000186] [G loss: 0.017123]\n",
            "[Epoch 198/200] [Batch 101/200] [D loss: 0.000271] [G loss: 0.019393]\n",
            "[Epoch 198/200] [Batch 102/200] [D loss: 0.000157] [G loss: 0.016249]\n",
            "[Epoch 198/200] [Batch 103/200] [D loss: 0.000160] [G loss: 0.017667]\n",
            "[Epoch 198/200] [Batch 104/200] [D loss: 0.000115] [G loss: 0.016628]\n",
            "[Epoch 198/200] [Batch 105/200] [D loss: 0.000127] [G loss: 0.013807]\n",
            "[Epoch 198/200] [Batch 106/200] [D loss: 0.000400] [G loss: 0.021253]\n",
            "[Epoch 198/200] [Batch 107/200] [D loss: 0.000237] [G loss: 0.019160]\n",
            "[Epoch 198/200] [Batch 108/200] [D loss: 0.000308] [G loss: 0.019535]\n",
            "[Epoch 198/200] [Batch 109/200] [D loss: 0.000456] [G loss: 0.018827]\n",
            "[Epoch 198/200] [Batch 110/200] [D loss: 0.000644] [G loss: 0.020010]\n",
            "[Epoch 198/200] [Batch 111/200] [D loss: 0.000381] [G loss: 0.016212]\n",
            "[Epoch 198/200] [Batch 112/200] [D loss: 0.000426] [G loss: 0.017139]\n",
            "[Epoch 198/200] [Batch 113/200] [D loss: 0.000187] [G loss: 0.021986]\n",
            "[Epoch 198/200] [Batch 114/200] [D loss: 0.000184] [G loss: 0.020278]\n",
            "[Epoch 198/200] [Batch 115/200] [D loss: 0.000164] [G loss: 0.014012]\n",
            "[Epoch 198/200] [Batch 116/200] [D loss: 0.000237] [G loss: 0.013609]\n",
            "[Epoch 198/200] [Batch 117/200] [D loss: 0.000323] [G loss: 0.017590]\n",
            "[Epoch 198/200] [Batch 118/200] [D loss: 0.000229] [G loss: 0.016211]\n",
            "[Epoch 198/200] [Batch 119/200] [D loss: 0.000270] [G loss: 0.016699]\n",
            "[Epoch 198/200] [Batch 120/200] [D loss: 0.000163] [G loss: 0.017724]\n",
            "[Epoch 198/200] [Batch 121/200] [D loss: 0.000168] [G loss: 0.016166]\n",
            "[Epoch 198/200] [Batch 122/200] [D loss: 0.000353] [G loss: 0.018406]\n",
            "[Epoch 198/200] [Batch 123/200] [D loss: 0.000417] [G loss: 0.018939]\n",
            "[Epoch 198/200] [Batch 124/200] [D loss: 0.000206] [G loss: 0.016205]\n",
            "[Epoch 198/200] [Batch 125/200] [D loss: 0.000111] [G loss: 0.016761]\n",
            "[Epoch 198/200] [Batch 126/200] [D loss: 0.000146] [G loss: 0.015283]\n",
            "[Epoch 198/200] [Batch 127/200] [D loss: 0.000178] [G loss: 0.015216]\n",
            "[Epoch 198/200] [Batch 128/200] [D loss: 0.000131] [G loss: 0.014468]\n",
            "[Epoch 198/200] [Batch 129/200] [D loss: 0.000102] [G loss: 0.016561]\n",
            "[Epoch 198/200] [Batch 130/200] [D loss: 0.000184] [G loss: 0.016169]\n",
            "[Epoch 198/200] [Batch 131/200] [D loss: 0.000138] [G loss: 0.017631]\n",
            "[Epoch 198/200] [Batch 132/200] [D loss: 0.000162] [G loss: 0.016786]\n",
            "[Epoch 198/200] [Batch 133/200] [D loss: 0.000134] [G loss: 0.016868]\n",
            "[Epoch 198/200] [Batch 134/200] [D loss: 0.000267] [G loss: 0.017530]\n",
            "[Epoch 198/200] [Batch 135/200] [D loss: 0.000161] [G loss: 0.016512]\n",
            "[Epoch 198/200] [Batch 136/200] [D loss: 0.000188] [G loss: 0.018474]\n",
            "[Epoch 198/200] [Batch 137/200] [D loss: 0.000293] [G loss: 0.021078]\n",
            "[Epoch 198/200] [Batch 138/200] [D loss: 0.000225] [G loss: 0.016658]\n",
            "[Epoch 198/200] [Batch 139/200] [D loss: 0.000170] [G loss: 0.013243]\n",
            "[Epoch 198/200] [Batch 140/200] [D loss: 0.000344] [G loss: 0.020611]\n",
            "[Epoch 198/200] [Batch 141/200] [D loss: 0.000252] [G loss: 0.014377]\n",
            "[Epoch 198/200] [Batch 142/200] [D loss: 0.000193] [G loss: 0.015986]\n",
            "[Epoch 198/200] [Batch 143/200] [D loss: 0.000332] [G loss: 0.019556]\n",
            "[Epoch 198/200] [Batch 144/200] [D loss: 0.000219] [G loss: 0.016570]\n",
            "[Epoch 198/200] [Batch 145/200] [D loss: 0.000274] [G loss: 0.017354]\n",
            "[Epoch 198/200] [Batch 146/200] [D loss: 0.000347] [G loss: 0.019939]\n",
            "[Epoch 198/200] [Batch 147/200] [D loss: 0.000440] [G loss: 0.019992]\n",
            "[Epoch 198/200] [Batch 148/200] [D loss: 0.000243] [G loss: 0.015812]\n",
            "[Epoch 198/200] [Batch 149/200] [D loss: 0.000305] [G loss: 0.020403]\n",
            "[Epoch 198/200] [Batch 150/200] [D loss: 0.000132] [G loss: 0.018361]\n",
            "[Epoch 198/200] [Batch 151/200] [D loss: 0.000332] [G loss: 0.021477]\n",
            "[Epoch 198/200] [Batch 152/200] [D loss: 0.000213] [G loss: 0.018545]\n",
            "[Epoch 198/200] [Batch 153/200] [D loss: 0.000144] [G loss: 0.015709]\n",
            "[Epoch 198/200] [Batch 154/200] [D loss: 0.000254] [G loss: 0.016620]\n",
            "[Epoch 198/200] [Batch 155/200] [D loss: 0.000174] [G loss: 0.020792]\n",
            "[Epoch 198/200] [Batch 156/200] [D loss: 0.000171] [G loss: 0.014447]\n",
            "[Epoch 198/200] [Batch 157/200] [D loss: 0.000138] [G loss: 0.017313]\n",
            "[Epoch 198/200] [Batch 158/200] [D loss: 0.000136] [G loss: 0.020556]\n",
            "[Epoch 198/200] [Batch 159/200] [D loss: 0.000164] [G loss: 0.019013]\n",
            "[Epoch 198/200] [Batch 160/200] [D loss: 0.000200] [G loss: 0.019326]\n",
            "[Epoch 198/200] [Batch 161/200] [D loss: 0.000304] [G loss: 0.018174]\n",
            "[Epoch 198/200] [Batch 162/200] [D loss: 0.000321] [G loss: 0.018005]\n",
            "[Epoch 198/200] [Batch 163/200] [D loss: 0.000231] [G loss: 0.017061]\n",
            "[Epoch 198/200] [Batch 164/200] [D loss: 0.000176] [G loss: 0.015040]\n",
            "[Epoch 198/200] [Batch 165/200] [D loss: 0.000267] [G loss: 0.016248]\n",
            "[Epoch 198/200] [Batch 166/200] [D loss: 0.000214] [G loss: 0.016871]\n",
            "[Epoch 198/200] [Batch 167/200] [D loss: 0.000397] [G loss: 0.018795]\n",
            "[Epoch 198/200] [Batch 168/200] [D loss: 0.000182] [G loss: 0.017219]\n",
            "[Epoch 198/200] [Batch 169/200] [D loss: 0.000207] [G loss: 0.016531]\n",
            "[Epoch 198/200] [Batch 170/200] [D loss: 0.000368] [G loss: 0.017403]\n",
            "[Epoch 198/200] [Batch 171/200] [D loss: 0.000241] [G loss: 0.014104]\n",
            "[Epoch 198/200] [Batch 172/200] [D loss: 0.000124] [G loss: 0.016673]\n",
            "[Epoch 198/200] [Batch 173/200] [D loss: 0.000708] [G loss: 0.021720]\n",
            "[Epoch 198/200] [Batch 174/200] [D loss: 0.000151] [G loss: 0.015081]\n",
            "[Epoch 198/200] [Batch 175/200] [D loss: 0.000287] [G loss: 0.016203]\n",
            "[Epoch 198/200] [Batch 176/200] [D loss: 0.000292] [G loss: 0.019711]\n",
            "[Epoch 198/200] [Batch 177/200] [D loss: 0.000127] [G loss: 0.020272]\n",
            "[Epoch 198/200] [Batch 178/200] [D loss: 0.000209] [G loss: 0.017681]\n",
            "[Epoch 198/200] [Batch 179/200] [D loss: 0.000187] [G loss: 0.016159]\n",
            "[Epoch 198/200] [Batch 180/200] [D loss: 0.000199] [G loss: 0.018432]\n",
            "[Epoch 198/200] [Batch 181/200] [D loss: 0.000231] [G loss: 0.016862]\n",
            "[Epoch 198/200] [Batch 182/200] [D loss: 0.000120] [G loss: 0.017328]\n",
            "[Epoch 198/200] [Batch 183/200] [D loss: 0.000138] [G loss: 0.018882]\n",
            "[Epoch 198/200] [Batch 184/200] [D loss: 0.000163] [G loss: 0.014023]\n",
            "[Epoch 198/200] [Batch 185/200] [D loss: 0.000184] [G loss: 0.019703]\n",
            "[Epoch 198/200] [Batch 186/200] [D loss: 0.000147] [G loss: 0.016220]\n",
            "[Epoch 198/200] [Batch 187/200] [D loss: 0.000205] [G loss: 0.015767]\n",
            "[Epoch 198/200] [Batch 188/200] [D loss: 0.000109] [G loss: 0.015203]\n",
            "[Epoch 198/200] [Batch 189/200] [D loss: 0.000138] [G loss: 0.019559]\n",
            "[Epoch 198/200] [Batch 190/200] [D loss: 0.000140] [G loss: 0.019715]\n",
            "[Epoch 198/200] [Batch 191/200] [D loss: 0.000160] [G loss: 0.015935]\n",
            "[Epoch 198/200] [Batch 192/200] [D loss: 0.000111] [G loss: 0.017166]\n",
            "[Epoch 198/200] [Batch 193/200] [D loss: 0.000218] [G loss: 0.015294]\n",
            "[Epoch 198/200] [Batch 194/200] [D loss: 0.000125] [G loss: 0.019560]\n",
            "[Epoch 198/200] [Batch 195/200] [D loss: 0.000131] [G loss: 0.019296]\n",
            "[Epoch 198/200] [Batch 196/200] [D loss: 0.000141] [G loss: 0.016059]\n",
            "[Epoch 198/200] [Batch 197/200] [D loss: 0.000738] [G loss: 0.018425]\n",
            "[Epoch 198/200] [Batch 198/200] [D loss: 0.000237] [G loss: 0.018634]\n",
            "[Epoch 198/200] [Batch 199/200] [D loss: 0.000235] [G loss: 0.016719]\n",
            "[Epoch 199/200] [Batch 0/200] [D loss: 0.000162] [G loss: 0.017680]\n",
            "[Epoch 199/200] [Batch 1/200] [D loss: 0.000404] [G loss: 0.015205]\n",
            "[Epoch 199/200] [Batch 2/200] [D loss: 0.000165] [G loss: 0.017363]\n",
            "[Epoch 199/200] [Batch 3/200] [D loss: 0.000227] [G loss: 0.018195]\n",
            "[Epoch 199/200] [Batch 4/200] [D loss: 0.000184] [G loss: 0.016668]\n",
            "[Epoch 199/200] [Batch 5/200] [D loss: 0.000183] [G loss: 0.013592]\n",
            "[Epoch 199/200] [Batch 6/200] [D loss: 0.000133] [G loss: 0.019969]\n",
            "[Epoch 199/200] [Batch 7/200] [D loss: 0.000115] [G loss: 0.021665]\n",
            "[Epoch 199/200] [Batch 8/200] [D loss: 0.000144] [G loss: 0.020374]\n",
            "[Epoch 199/200] [Batch 9/200] [D loss: 0.000212] [G loss: 0.020529]\n",
            "[Epoch 199/200] [Batch 10/200] [D loss: 0.000223] [G loss: 0.017931]\n",
            "[Epoch 199/200] [Batch 11/200] [D loss: 0.000119] [G loss: 0.018725]\n",
            "[Epoch 199/200] [Batch 12/200] [D loss: 0.000204] [G loss: 0.017695]\n",
            "[Epoch 199/200] [Batch 13/200] [D loss: 0.000284] [G loss: 0.017618]\n",
            "[Epoch 199/200] [Batch 14/200] [D loss: 0.000143] [G loss: 0.018176]\n",
            "[Epoch 199/200] [Batch 15/200] [D loss: 0.000184] [G loss: 0.016153]\n",
            "[Epoch 199/200] [Batch 16/200] [D loss: 0.000216] [G loss: 0.017512]\n",
            "[Epoch 199/200] [Batch 17/200] [D loss: 0.000298] [G loss: 0.017628]\n",
            "[Epoch 199/200] [Batch 18/200] [D loss: 0.000175] [G loss: 0.017647]\n",
            "[Epoch 199/200] [Batch 19/200] [D loss: 0.000418] [G loss: 0.016491]\n",
            "[Epoch 199/200] [Batch 20/200] [D loss: 0.000585] [G loss: 0.020723]\n",
            "[Epoch 199/200] [Batch 21/200] [D loss: 0.000235] [G loss: 0.020263]\n",
            "[Epoch 199/200] [Batch 22/200] [D loss: 0.000431] [G loss: 0.015687]\n",
            "[Epoch 199/200] [Batch 23/200] [D loss: 0.000184] [G loss: 0.018662]\n",
            "[Epoch 199/200] [Batch 24/200] [D loss: 0.000157] [G loss: 0.015164]\n",
            "[Epoch 199/200] [Batch 25/200] [D loss: 0.000112] [G loss: 0.017283]\n",
            "[Epoch 199/200] [Batch 26/200] [D loss: 0.000164] [G loss: 0.015906]\n",
            "[Epoch 199/200] [Batch 27/200] [D loss: 0.000322] [G loss: 0.020086]\n",
            "[Epoch 199/200] [Batch 28/200] [D loss: 0.000203] [G loss: 0.015026]\n",
            "[Epoch 199/200] [Batch 29/200] [D loss: 0.000261] [G loss: 0.018496]\n",
            "[Epoch 199/200] [Batch 30/200] [D loss: 0.000220] [G loss: 0.016978]\n",
            "[Epoch 199/200] [Batch 31/200] [D loss: 0.000199] [G loss: 0.018761]\n",
            "[Epoch 199/200] [Batch 32/200] [D loss: 0.000308] [G loss: 0.017359]\n",
            "[Epoch 199/200] [Batch 33/200] [D loss: 0.000201] [G loss: 0.017543]\n",
            "[Epoch 199/200] [Batch 34/200] [D loss: 0.000558] [G loss: 0.018709]\n",
            "[Epoch 199/200] [Batch 35/200] [D loss: 0.000313] [G loss: 0.020273]\n",
            "[Epoch 199/200] [Batch 36/200] [D loss: 0.000259] [G loss: 0.017992]\n",
            "[Epoch 199/200] [Batch 37/200] [D loss: 0.000164] [G loss: 0.017337]\n",
            "[Epoch 199/200] [Batch 38/200] [D loss: 0.000123] [G loss: 0.018786]\n",
            "[Epoch 199/200] [Batch 39/200] [D loss: 0.000155] [G loss: 0.021068]\n",
            "[Epoch 199/200] [Batch 40/200] [D loss: 0.000097] [G loss: 0.016011]\n",
            "[Epoch 199/200] [Batch 41/200] [D loss: 0.000181] [G loss: 0.018216]\n",
            "[Epoch 199/200] [Batch 42/200] [D loss: 0.000181] [G loss: 0.015984]\n",
            "[Epoch 199/200] [Batch 43/200] [D loss: 0.000133] [G loss: 0.018841]\n",
            "[Epoch 199/200] [Batch 44/200] [D loss: 0.000104] [G loss: 0.016851]\n",
            "[Epoch 199/200] [Batch 45/200] [D loss: 0.000133] [G loss: 0.018524]\n",
            "[Epoch 199/200] [Batch 46/200] [D loss: 0.000092] [G loss: 0.019170]\n",
            "[Epoch 199/200] [Batch 47/200] [D loss: 0.000131] [G loss: 0.016342]\n",
            "[Epoch 199/200] [Batch 48/200] [D loss: 0.000147] [G loss: 0.018644]\n",
            "[Epoch 199/200] [Batch 49/200] [D loss: 0.000340] [G loss: 0.017509]\n",
            "[Epoch 199/200] [Batch 50/200] [D loss: 0.000214] [G loss: 0.020002]\n",
            "[Epoch 199/200] [Batch 51/200] [D loss: 0.000230] [G loss: 0.015620]\n",
            "[Epoch 199/200] [Batch 52/200] [D loss: 0.000286] [G loss: 0.019806]\n",
            "[Epoch 199/200] [Batch 53/200] [D loss: 0.000120] [G loss: 0.013720]\n",
            "[Epoch 199/200] [Batch 54/200] [D loss: 0.000130] [G loss: 0.018244]\n",
            "[Epoch 199/200] [Batch 55/200] [D loss: 0.000856] [G loss: 0.018611]\n",
            "[Epoch 199/200] [Batch 56/200] [D loss: 0.000208] [G loss: 0.018405]\n",
            "[Epoch 199/200] [Batch 57/200] [D loss: 0.000197] [G loss: 0.015769]\n",
            "[Epoch 199/200] [Batch 58/200] [D loss: 0.000161] [G loss: 0.015722]\n",
            "[Epoch 199/200] [Batch 59/200] [D loss: 0.000118] [G loss: 0.014031]\n",
            "[Epoch 199/200] [Batch 60/200] [D loss: 0.000199] [G loss: 0.021144]\n",
            "[Epoch 199/200] [Batch 61/200] [D loss: 0.000301] [G loss: 0.023208]\n",
            "[Epoch 199/200] [Batch 62/200] [D loss: 0.000137] [G loss: 0.019010]\n",
            "[Epoch 199/200] [Batch 63/200] [D loss: 0.000099] [G loss: 0.019504]\n",
            "[Epoch 199/200] [Batch 64/200] [D loss: 0.000241] [G loss: 0.019323]\n",
            "[Epoch 199/200] [Batch 65/200] [D loss: 0.000175] [G loss: 0.021778]\n",
            "[Epoch 199/200] [Batch 66/200] [D loss: 0.000167] [G loss: 0.020551]\n",
            "[Epoch 199/200] [Batch 67/200] [D loss: 0.000100] [G loss: 0.016688]\n",
            "[Epoch 199/200] [Batch 68/200] [D loss: 0.000285] [G loss: 0.017802]\n",
            "[Epoch 199/200] [Batch 69/200] [D loss: 0.000152] [G loss: 0.018094]\n",
            "[Epoch 199/200] [Batch 70/200] [D loss: 0.000182] [G loss: 0.017705]\n",
            "[Epoch 199/200] [Batch 71/200] [D loss: 0.000335] [G loss: 0.018580]\n",
            "[Epoch 199/200] [Batch 72/200] [D loss: 0.000172] [G loss: 0.019054]\n",
            "[Epoch 199/200] [Batch 73/200] [D loss: 0.000154] [G loss: 0.016808]\n",
            "[Epoch 199/200] [Batch 74/200] [D loss: 0.000148] [G loss: 0.018816]\n",
            "[Epoch 199/200] [Batch 75/200] [D loss: 0.000156] [G loss: 0.013923]\n",
            "[Epoch 199/200] [Batch 76/200] [D loss: 0.000120] [G loss: 0.015405]\n",
            "[Epoch 199/200] [Batch 77/200] [D loss: 0.000651] [G loss: 0.022070]\n",
            "[Epoch 199/200] [Batch 78/200] [D loss: 0.000365] [G loss: 0.015414]\n",
            "[Epoch 199/200] [Batch 79/200] [D loss: 0.000637] [G loss: 0.013840]\n",
            "[Epoch 199/200] [Batch 80/200] [D loss: 0.000577] [G loss: 0.013499]\n",
            "[Epoch 199/200] [Batch 81/200] [D loss: 0.000193] [G loss: 0.018214]\n",
            "[Epoch 199/200] [Batch 82/200] [D loss: 0.000110] [G loss: 0.015978]\n",
            "[Epoch 199/200] [Batch 83/200] [D loss: 0.000225] [G loss: 0.020841]\n",
            "[Epoch 199/200] [Batch 84/200] [D loss: 0.000129] [G loss: 0.020345]\n",
            "[Epoch 199/200] [Batch 85/200] [D loss: 0.000116] [G loss: 0.017554]\n",
            "[Epoch 199/200] [Batch 86/200] [D loss: 0.000124] [G loss: 0.014962]\n",
            "[Epoch 199/200] [Batch 87/200] [D loss: 0.000148] [G loss: 0.017159]\n",
            "[Epoch 199/200] [Batch 88/200] [D loss: 0.000112] [G loss: 0.016886]\n",
            "[Epoch 199/200] [Batch 89/200] [D loss: 0.000166] [G loss: 0.015693]\n",
            "[Epoch 199/200] [Batch 90/200] [D loss: 0.000091] [G loss: 0.019220]\n",
            "[Epoch 199/200] [Batch 91/200] [D loss: 0.000231] [G loss: 0.018350]\n",
            "[Epoch 199/200] [Batch 92/200] [D loss: 0.000345] [G loss: 0.013510]\n",
            "[Epoch 199/200] [Batch 93/200] [D loss: 0.000149] [G loss: 0.020556]\n",
            "[Epoch 199/200] [Batch 94/200] [D loss: 0.000159] [G loss: 0.013814]\n",
            "[Epoch 199/200] [Batch 95/200] [D loss: 0.000192] [G loss: 0.019361]\n",
            "[Epoch 199/200] [Batch 96/200] [D loss: 0.000248] [G loss: 0.019462]\n",
            "[Epoch 199/200] [Batch 97/200] [D loss: 0.000171] [G loss: 0.013754]\n",
            "[Epoch 199/200] [Batch 98/200] [D loss: 0.000339] [G loss: 0.018563]\n",
            "[Epoch 199/200] [Batch 99/200] [D loss: 0.000720] [G loss: 0.019730]\n",
            "[Epoch 199/200] [Batch 100/200] [D loss: 0.000475] [G loss: 0.012778]\n",
            "[Epoch 199/200] [Batch 101/200] [D loss: 0.000325] [G loss: 0.016809]\n",
            "[Epoch 199/200] [Batch 102/200] [D loss: 0.000152] [G loss: 0.015359]\n",
            "[Epoch 199/200] [Batch 103/200] [D loss: 0.000255] [G loss: 0.020832]\n",
            "[Epoch 199/200] [Batch 104/200] [D loss: 0.000525] [G loss: 0.017580]\n",
            "[Epoch 199/200] [Batch 105/200] [D loss: 0.000350] [G loss: 0.014952]\n",
            "[Epoch 199/200] [Batch 106/200] [D loss: 0.000299] [G loss: 0.015886]\n",
            "[Epoch 199/200] [Batch 107/200] [D loss: 0.000294] [G loss: 0.017763]\n",
            "[Epoch 199/200] [Batch 108/200] [D loss: 0.000241] [G loss: 0.015361]\n",
            "[Epoch 199/200] [Batch 109/200] [D loss: 0.000256] [G loss: 0.018247]\n",
            "[Epoch 199/200] [Batch 110/200] [D loss: 0.000281] [G loss: 0.014253]\n",
            "[Epoch 199/200] [Batch 111/200] [D loss: 0.000319] [G loss: 0.016000]\n",
            "[Epoch 199/200] [Batch 112/200] [D loss: 0.000256] [G loss: 0.013761]\n",
            "[Epoch 199/200] [Batch 113/200] [D loss: 0.000172] [G loss: 0.013213]\n",
            "[Epoch 199/200] [Batch 114/200] [D loss: 0.000139] [G loss: 0.016829]\n",
            "[Epoch 199/200] [Batch 115/200] [D loss: 0.000131] [G loss: 0.016734]\n",
            "[Epoch 199/200] [Batch 116/200] [D loss: 0.000136] [G loss: 0.019787]\n",
            "[Epoch 199/200] [Batch 117/200] [D loss: 0.000139] [G loss: 0.017899]\n",
            "[Epoch 199/200] [Batch 118/200] [D loss: 0.000133] [G loss: 0.019084]\n",
            "[Epoch 199/200] [Batch 119/200] [D loss: 0.000318] [G loss: 0.017816]\n",
            "[Epoch 199/200] [Batch 120/200] [D loss: 0.000154] [G loss: 0.018216]\n",
            "[Epoch 199/200] [Batch 121/200] [D loss: 0.000317] [G loss: 0.019010]\n",
            "[Epoch 199/200] [Batch 122/200] [D loss: 0.000157] [G loss: 0.018706]\n",
            "[Epoch 199/200] [Batch 123/200] [D loss: 0.000192] [G loss: 0.018309]\n",
            "[Epoch 199/200] [Batch 124/200] [D loss: 0.000182] [G loss: 0.015837]\n",
            "[Epoch 199/200] [Batch 125/200] [D loss: 0.000129] [G loss: 0.019775]\n",
            "[Epoch 199/200] [Batch 126/200] [D loss: 0.000121] [G loss: 0.013146]\n",
            "[Epoch 199/200] [Batch 127/200] [D loss: 0.000169] [G loss: 0.022349]\n",
            "[Epoch 199/200] [Batch 128/200] [D loss: 0.000128] [G loss: 0.021416]\n",
            "[Epoch 199/200] [Batch 129/200] [D loss: 0.000116] [G loss: 0.016561]\n",
            "[Epoch 199/200] [Batch 130/200] [D loss: 0.000083] [G loss: 0.017344]\n",
            "[Epoch 199/200] [Batch 131/200] [D loss: 0.000085] [G loss: 0.013111]\n",
            "[Epoch 199/200] [Batch 132/200] [D loss: 0.000109] [G loss: 0.012999]\n",
            "[Epoch 199/200] [Batch 133/200] [D loss: 0.000082] [G loss: 0.016807]\n",
            "[Epoch 199/200] [Batch 134/200] [D loss: 0.000156] [G loss: 0.017196]\n",
            "[Epoch 199/200] [Batch 135/200] [D loss: 0.000111] [G loss: 0.015443]\n",
            "[Epoch 199/200] [Batch 136/200] [D loss: 0.000173] [G loss: 0.018825]\n",
            "[Epoch 199/200] [Batch 137/200] [D loss: 0.000284] [G loss: 0.020011]\n",
            "[Epoch 199/200] [Batch 138/200] [D loss: 0.000158] [G loss: 0.019653]\n",
            "[Epoch 199/200] [Batch 139/200] [D loss: 0.000157] [G loss: 0.017751]\n",
            "[Epoch 199/200] [Batch 140/200] [D loss: 0.000102] [G loss: 0.017050]\n",
            "[Epoch 199/200] [Batch 141/200] [D loss: 0.000255] [G loss: 0.020078]\n",
            "[Epoch 199/200] [Batch 142/200] [D loss: 0.000178] [G loss: 0.017666]\n",
            "[Epoch 199/200] [Batch 143/200] [D loss: 0.000270] [G loss: 0.017551]\n",
            "[Epoch 199/200] [Batch 144/200] [D loss: 0.000110] [G loss: 0.018680]\n",
            "[Epoch 199/200] [Batch 145/200] [D loss: 0.000154] [G loss: 0.016191]\n",
            "[Epoch 199/200] [Batch 146/200] [D loss: 0.000664] [G loss: 0.019142]\n",
            "[Epoch 199/200] [Batch 147/200] [D loss: 0.000152] [G loss: 0.017782]\n",
            "[Epoch 199/200] [Batch 148/200] [D loss: 0.000274] [G loss: 0.015110]\n",
            "[Epoch 199/200] [Batch 149/200] [D loss: 0.000177] [G loss: 0.018940]\n",
            "[Epoch 199/200] [Batch 150/200] [D loss: 0.000201] [G loss: 0.021942]\n",
            "[Epoch 199/200] [Batch 151/200] [D loss: 0.000152] [G loss: 0.017450]\n",
            "[Epoch 199/200] [Batch 152/200] [D loss: 0.000140] [G loss: 0.014609]\n",
            "[Epoch 199/200] [Batch 153/200] [D loss: 0.000178] [G loss: 0.018460]\n",
            "[Epoch 199/200] [Batch 154/200] [D loss: 0.000222] [G loss: 0.015650]\n",
            "[Epoch 199/200] [Batch 155/200] [D loss: 0.000086] [G loss: 0.017444]\n",
            "[Epoch 199/200] [Batch 156/200] [D loss: 0.000226] [G loss: 0.015957]\n",
            "[Epoch 199/200] [Batch 157/200] [D loss: 0.000270] [G loss: 0.018565]\n",
            "[Epoch 199/200] [Batch 158/200] [D loss: 0.000375] [G loss: 0.017747]\n",
            "[Epoch 199/200] [Batch 159/200] [D loss: 0.000193] [G loss: 0.017049]\n",
            "[Epoch 199/200] [Batch 160/200] [D loss: 0.000339] [G loss: 0.014780]\n",
            "[Epoch 199/200] [Batch 161/200] [D loss: 0.000136] [G loss: 0.019025]\n",
            "[Epoch 199/200] [Batch 162/200] [D loss: 0.000141] [G loss: 0.013967]\n",
            "[Epoch 199/200] [Batch 163/200] [D loss: 0.000110] [G loss: 0.015488]\n",
            "[Epoch 199/200] [Batch 164/200] [D loss: 0.000099] [G loss: 0.015913]\n",
            "[Epoch 199/200] [Batch 165/200] [D loss: 0.000141] [G loss: 0.019342]\n",
            "[Epoch 199/200] [Batch 166/200] [D loss: 0.000119] [G loss: 0.016897]\n",
            "[Epoch 199/200] [Batch 167/200] [D loss: 0.000142] [G loss: 0.018029]\n",
            "[Epoch 199/200] [Batch 168/200] [D loss: 0.000231] [G loss: 0.017341]\n",
            "[Epoch 199/200] [Batch 169/200] [D loss: 0.000277] [G loss: 0.018591]\n",
            "[Epoch 199/200] [Batch 170/200] [D loss: 0.000156] [G loss: 0.017208]\n",
            "[Epoch 199/200] [Batch 171/200] [D loss: 0.000161] [G loss: 0.018378]\n",
            "[Epoch 199/200] [Batch 172/200] [D loss: 0.000141] [G loss: 0.017193]\n",
            "[Epoch 199/200] [Batch 173/200] [D loss: 0.000079] [G loss: 0.014418]\n",
            "[Epoch 199/200] [Batch 174/200] [D loss: 0.000083] [G loss: 0.018376]\n",
            "[Epoch 199/200] [Batch 175/200] [D loss: 0.000221] [G loss: 0.019878]\n",
            "[Epoch 199/200] [Batch 176/200] [D loss: 0.000239] [G loss: 0.017831]\n",
            "[Epoch 199/200] [Batch 177/200] [D loss: 0.000089] [G loss: 0.016595]\n",
            "[Epoch 199/200] [Batch 178/200] [D loss: 0.000227] [G loss: 0.014341]\n",
            "[Epoch 199/200] [Batch 179/200] [D loss: 0.000105] [G loss: 0.017952]\n",
            "[Epoch 199/200] [Batch 180/200] [D loss: 0.000084] [G loss: 0.019282]\n",
            "[Epoch 199/200] [Batch 181/200] [D loss: 0.000109] [G loss: 0.016790]\n",
            "[Epoch 199/200] [Batch 182/200] [D loss: 0.000093] [G loss: 0.019088]\n",
            "[Epoch 199/200] [Batch 183/200] [D loss: 0.000113] [G loss: 0.017618]\n",
            "[Epoch 199/200] [Batch 184/200] [D loss: 0.000144] [G loss: 0.023730]\n",
            "[Epoch 199/200] [Batch 185/200] [D loss: 0.000159] [G loss: 0.015131]\n",
            "[Epoch 199/200] [Batch 186/200] [D loss: 0.000112] [G loss: 0.019655]\n",
            "[Epoch 199/200] [Batch 187/200] [D loss: 0.000173] [G loss: 0.012706]\n",
            "[Epoch 199/200] [Batch 188/200] [D loss: 0.000136] [G loss: 0.017736]\n",
            "[Epoch 199/200] [Batch 189/200] [D loss: 0.000154] [G loss: 0.016691]\n",
            "[Epoch 199/200] [Batch 190/200] [D loss: 0.000263] [G loss: 0.016645]\n",
            "[Epoch 199/200] [Batch 191/200] [D loss: 0.000397] [G loss: 0.020955]\n",
            "[Epoch 199/200] [Batch 192/200] [D loss: 0.000283] [G loss: 0.017477]\n",
            "[Epoch 199/200] [Batch 193/200] [D loss: 0.000199] [G loss: 0.018923]\n",
            "[Epoch 199/200] [Batch 194/200] [D loss: 0.000226] [G loss: 0.015797]\n",
            "[Epoch 199/200] [Batch 195/200] [D loss: 0.000323] [G loss: 0.020210]\n",
            "[Epoch 199/200] [Batch 196/200] [D loss: 0.000113] [G loss: 0.016746]\n",
            "[Epoch 199/200] [Batch 197/200] [D loss: 0.000124] [G loss: 0.019099]\n",
            "[Epoch 199/200] [Batch 198/200] [D loss: 0.000084] [G loss: 0.019074]\n",
            "[Epoch 199/200] [Batch 199/200] [D loss: 0.000084] [G loss: 0.016631]\n",
            "Generator model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(epoch, n_epochs):\n",
        "    for i, imgs in enumerate(dataloader):\n",
        "\n",
        "        # Configure model input\n",
        "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
        "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Generate a high resolution image from low resolution input\n",
        "        gen_hr = generator(imgs_lr)\n",
        "\n",
        "        # Adversarial loss\n",
        "        loss_GAN = criterion_GAN(discriminator(gen_hr), valid)\n",
        "\n",
        "        # Content loss\n",
        "        gen_features = feature_extractor(gen_hr)\n",
        "        real_features = feature_extractor(imgs_hr)\n",
        "        loss_content = criterion_content(gen_features, real_features.detach())\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = loss_content + 1e-3 * loss_GAN\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss of real and fake images\n",
        "        loss_real = criterion_GAN(discriminator(imgs_hr), valid)\n",
        "        loss_fake = criterion_GAN(discriminator(gen_hr.detach()), fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        sys.stdout.write(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\\n\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), loss_D.item(), loss_G.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % sample_interval == 0:\n",
        "            # Save image grid with upsampled inputs and SRGAN outputs\n",
        "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
        "            gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\n",
        "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
        "            img_grid = torch.cat((imgs_lr, gen_hr), -1)\n",
        "            save_image(img_grid, \"images/%d.png\" % batches_done, normalize=False)\n",
        "\n",
        "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
        "        # Save model checkpoints\n",
        "        torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n",
        "        torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" % epoch)\n",
        "\n",
        "\"\"\"\n",
        "torch.save(generator.state_dict(), \"saved_models/generator_manual_save.pth\")\n",
        "torch.save(discriminator.state_dict(), \"saved_models/discriminator_manual_save.pth\")\n",
        "\"\"\"\n",
        "\n",
        "if os.path.isfile(\"saved_models/generator_0.pth\"):\n",
        "    print(\"Generator model saved successfully.\")\n",
        "else:\n",
        "    print(\"Generator model not found.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}